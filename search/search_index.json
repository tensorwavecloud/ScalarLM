{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"cray-docs/docs/","text":"Welcome to Craylm Craylm is a fully open source, CC-0 Licensed, integrated LLM inference and training platform. Craylm builds on top of the vLLM inference engine, the Megatron-LM training framework, and the HuggingFace model hub. It unifies the capabilities of these tools into a single platform, enabling users to easily perform LLM inference and training, and build higher lever applications such as Agents with a twist - they can teach themselves new abilities via back propagation. Craylm is designed for high peformance. It inherits the distributed training capabilities of Megatron-LM and the optimized inference engine of vLLM. Cray is also designed to be easy to use. It provides an OpenAI compatible server and a simple command line interface for users to interact with the platform. Craylm is inspired by the work of Seymour Roger Cray (September 28, 1925 \u2013 October 5, 1996), an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades, and founded Cray Research, which built many of these machines. Called \"the father of supercomputing\", Cray has been credited with creating the supercomputer industry. Learn more about Craylm at our Blog and GitHub . Get in Touch","title":"Welcome to Craylm"},{"location":"cray-docs/docs/#welcome-to-craylm","text":"Craylm is a fully open source, CC-0 Licensed, integrated LLM inference and training platform. Craylm builds on top of the vLLM inference engine, the Megatron-LM training framework, and the HuggingFace model hub. It unifies the capabilities of these tools into a single platform, enabling users to easily perform LLM inference and training, and build higher lever applications such as Agents with a twist - they can teach themselves new abilities via back propagation. Craylm is designed for high peformance. It inherits the distributed training capabilities of Megatron-LM and the optimized inference engine of vLLM. Cray is also designed to be easy to use. It provides an OpenAI compatible server and a simple command line interface for users to interact with the platform. Craylm is inspired by the work of Seymour Roger Cray (September 28, 1925 \u2013 October 5, 1996), an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades, and founded Cray Research, which built many of these machines. Called \"the father of supercomputing\", Cray has been credited with creating the supercomputer industry. Learn more about Craylm at our Blog and GitHub . Get in Touch","title":"Welcome to Craylm"},{"location":"cray-docs/docs/arch/","text":"Craylm Craylm has three high level APIs: completions provides OpenAI client compatibility generate provides a simple interface for generating text train provides a simple interface for submitting training jobs Inference is performed by vLLM workers that are orchestrated by pulling requests from a queue. Training is performed by Megatron-LM workers that are orchestrated by SLURM. Trained models are automatically registered with the inference workers.","title":"Craylm"},{"location":"cray-docs/docs/arch/#craylm","text":"Craylm has three high level APIs: completions provides OpenAI client compatibility generate provides a simple interface for generating text train provides a simple interface for submitting training jobs Inference is performed by vLLM workers that are orchestrated by pulling requests from a queue. Training is performed by Megatron-LM workers that are orchestrated by SLURM. Trained models are automatically registered with the inference workers.","title":"Craylm"},{"location":"cray-docs/docs/contact/","text":"Contact Us Project Craylm is developed by an Artificial Intelligence engineering consortium, built on a philosophy of open collaboration to improve AI systems. Through our collective engineering efforts with industry and academia we continually integrate and improve the accuracy, safety, speed, and efficiency of AI technologies\u2013helping companies and universities around the world build better AI systems that will benefit society. Get in Touch Greg Diamos Naila Farooqui Sudnya Diamos Suhabe Bugrara We accept community contributions and are always looking for new collaborators. If you are interested in contributing to Project Craylm, please reach out to us at Get in Touch .","title":"Contact Us"},{"location":"cray-docs/docs/contact/#contact-us","text":"Project Craylm is developed by an Artificial Intelligence engineering consortium, built on a philosophy of open collaboration to improve AI systems. Through our collective engineering efforts with industry and academia we continually integrate and improve the accuracy, safety, speed, and efficiency of AI technologies\u2013helping companies and universities around the world build better AI systems that will benefit society. Get in Touch Greg Diamos Naila Farooqui Sudnya Diamos Suhabe Bugrara We accept community contributions and are always looking for new collaborators. If you are interested in contributing to Project Craylm, please reach out to us at Get in Touch .","title":"Contact Us"},{"location":"cray-docs/docs/inference/","text":"Inference OpenAI Compatible Server curl https://meta-llama--llama-3-2-3b-instruct.cray-lm.com/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-3B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }' Using the Python client You can also use the Python client to interact with the Craylm server. import masint masint.api_url = \"https://meta-llama--llama-3-2-3b-instruct.cray-lm.com\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Inference"},{"location":"cray-docs/docs/inference/#inference","text":"","title":"Inference"},{"location":"cray-docs/docs/inference/#openai-compatible-server","text":"curl https://meta-llama--llama-3-2-3b-instruct.cray-lm.com/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-3B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"OpenAI Compatible Server"},{"location":"cray-docs/docs/inference/#using-the-python-client","text":"You can also use the Python client to interact with the Craylm server. import masint masint.api_url = \"https://meta-llama--llama-3-2-3b-instruct.cray-lm.com\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Using the Python client"},{"location":"cray-docs/docs/quickstart/","text":"Let's start by submitting your first request to Craylm. Setup Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up This will bring up the Craylm development server on localhost:8000 , which includes an OpenAI compatible API. Your first request curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"masint/tiny-random-llama\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }' Using the Python client You can also use the Python client to interact with the local Craylm server. import masint # Make sure to set the API URL to the local Craylm server masint.api_url = \"http://localhost:8000\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results) Loading a different model Edit the file cray-lm/infra/cray_infra/util/default_config.py and change the model field to the desired model. model = \"meta-llama/Llama-3.2-1B-Instruct\" Then restart the server. ./cray up Submitting a request to the new model curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-1B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Quickstart"},{"location":"cray-docs/docs/quickstart/#setup","text":"Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up This will bring up the Craylm development server on localhost:8000 , which includes an OpenAI compatible API.","title":"Setup"},{"location":"cray-docs/docs/quickstart/#your-first-request","text":"curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"masint/tiny-random-llama\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Your first request"},{"location":"cray-docs/docs/quickstart/#using-the-python-client","text":"You can also use the Python client to interact with the local Craylm server. import masint # Make sure to set the API URL to the local Craylm server masint.api_url = \"http://localhost:8000\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Using the Python client"},{"location":"cray-docs/docs/quickstart/#loading-a-different-model","text":"Edit the file cray-lm/infra/cray_infra/util/default_config.py and change the model field to the desired model. model = \"meta-llama/Llama-3.2-1B-Instruct\" Then restart the server. ./cray up","title":"Loading a different model"},{"location":"cray-docs/docs/quickstart/#submitting-a-request-to-the-new-model","text":"curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-1B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Submitting a request to the new model"},{"location":"cray-docs/docs/training/","text":"Training Training jobs You can also use the Python client to submit training jobs to the Craylm server. import masint def get_dataset(): dataset = [] count = 5 for i in range(count): dataset.append( {\"input\": f\"What is {i} + {i}?\", \"output\": str(i + i)} ) return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() status = llm.train(dataset, train_args={\"max_steps\": 200, \"learning_rate\": 3e-3}) print(status) You get a command line output like this: (environment) gregorydiamos@Air-Gregory cray % python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': 'dataset', 'job_directory': '/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e', 'model_name': '69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e'}","title":"Training"},{"location":"cray-docs/docs/training/#training","text":"","title":"Training"},{"location":"cray-docs/docs/training/#training-jobs","text":"You can also use the Python client to submit training jobs to the Craylm server. import masint def get_dataset(): dataset = [] count = 5 for i in range(count): dataset.append( {\"input\": f\"What is {i} + {i}?\", \"output\": str(i + i)} ) return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() status = llm.train(dataset, train_args={\"max_steps\": 200, \"learning_rate\": 3e-3}) print(status) You get a command line output like this: (environment) gregorydiamos@Air-Gregory cray % python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': 'dataset', 'job_directory': '/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e', 'model_name': '69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e'}","title":"Training jobs"},{"location":"cray-docs/docs/cli/cli/","text":"Command Line Interface The Craylm CLI is used to inspect and monitor training jobs, as well as to manage the Cray-LM platform. cray - Craylm CLI Usage: cray COMMAND cray [COMMAND] --help | -h cray --version | -v Commands: build-image Build image from dockerfile depot-build Build image from dockerfile and push to depot up Start the container test Run tests in the container deploy Deploy the cray platform to modal serve Serve the cray platform using modal llm Invoke the LLM tool diffusion Evaluate a diffusion model Options: --help, -h Show this help --version, -v Show version number Installation Clone the Craylm repository and run the cray command to try out the CLI. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray Python package The Craylm CLI is also available as a Python package. You can install it using pip: pip install cray-lm After installing the package, you can use the cray-lm command in your terminal. (environment) gregorydiamos@MacBook-Air-Gregory cray % cray-lm usage: cray-lm [-h] {logs,plot,ls,squeue} ... The command line interface for MasInt positional arguments: {logs,plot,ls,squeue} logs View logs plot Plot the results of a model ls List models squeue View the squeue options: -h, --help show this help message and exit The python package includes is a client for the Craylm platform, and can be used to interact with the Craylm server.","title":"Command Line Interface"},{"location":"cray-docs/docs/cli/cli/#command-line-interface","text":"The Craylm CLI is used to inspect and monitor training jobs, as well as to manage the Cray-LM platform. cray - Craylm CLI Usage: cray COMMAND cray [COMMAND] --help | -h cray --version | -v Commands: build-image Build image from dockerfile depot-build Build image from dockerfile and push to depot up Start the container test Run tests in the container deploy Deploy the cray platform to modal serve Serve the cray platform using modal llm Invoke the LLM tool diffusion Evaluate a diffusion model Options: --help, -h Show this help --version, -v Show version number","title":"Command Line Interface"},{"location":"cray-docs/docs/cli/cli/#installation","text":"Clone the Craylm repository and run the cray command to try out the CLI. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray","title":"Installation"},{"location":"cray-docs/docs/cli/cli/#python-package","text":"The Craylm CLI is also available as a Python package. You can install it using pip: pip install cray-lm After installing the package, you can use the cray-lm command in your terminal. (environment) gregorydiamos@MacBook-Air-Gregory cray % cray-lm usage: cray-lm [-h] {logs,plot,ls,squeue} ... The command line interface for MasInt positional arguments: {logs,plot,ls,squeue} logs View logs plot Plot the results of a model ls List models squeue View the squeue options: -h, --help show this help message and exit The python package includes is a client for the Craylm platform, and can be used to interact with the Craylm server.","title":"Python package"},{"location":"cray-docs/docs/cli/list-models/","text":"List Models ./cray llm ls This command lists all of the models that have been trained on the Craylm server. 69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e Craylm names models with a unique identifier based on the input data and training parameters.","title":"List Models"},{"location":"cray-docs/docs/cli/list-models/#list-models","text":"./cray llm ls This command lists all of the models that have been trained on the Craylm server. 69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e Craylm names models with a unique identifier based on the input data and training parameters.","title":"List Models"},{"location":"cray-docs/docs/cli/plot/","text":"Plot ./cray llm plot This command plots the training loss of a specified model. If no model is specified, the command will plot the training loss of the most recently trained model.","title":"Plot"},{"location":"cray-docs/docs/cli/plot/#plot","text":"./cray llm plot This command plots the training loss of a specified model. If no model is specified, the command will plot the training loss of the most recently trained model.","title":"Plot"},{"location":"cray-docs/docs/cli/squeue/","text":"squeue ./cray llm squeue This command is a wrapper around the squeue command. It is used to display the status of jobs in the training queue. The output is similar to the squeue command, but with some additional formatting. JOBID PARTITION NAME USER STATE TIME TIME_LIMI NODES NODELIST(REASON) 8 short 00f186ab039b root PENDING 0:00 20:00 1 (Priority) 7 short f1ba9c0eb11b root PENDING 0:00 20:00 1 (Priority) 6 short 0746261fd1db root PENDING 0:00 20:00 1 (Priority) 5 short ae55dedbb496 root PENDING 0:00 20:00 1 (Priority) 4 short d2bc30a36081 root PENDING 0:00 20:00 1 (Priority) 3 short bce8e63a7bef root PENDING 0:00 20:00 1 (Resources) 2 short c42b59ab0fb1 root RUNNING 0:34 20:00 1 df294b9206ff","title":"squeue"},{"location":"cray-docs/docs/cli/squeue/#squeue","text":"./cray llm squeue This command is a wrapper around the squeue command. It is used to display the status of jobs in the training queue. The output is similar to the squeue command, but with some additional formatting. JOBID PARTITION NAME USER STATE TIME TIME_LIMI NODES NODELIST(REASON) 8 short 00f186ab039b root PENDING 0:00 20:00 1 (Priority) 7 short f1ba9c0eb11b root PENDING 0:00 20:00 1 (Priority) 6 short 0746261fd1db root PENDING 0:00 20:00 1 (Priority) 5 short ae55dedbb496 root PENDING 0:00 20:00 1 (Priority) 4 short d2bc30a36081 root PENDING 0:00 20:00 1 (Priority) 3 short bce8e63a7bef root PENDING 0:00 20:00 1 (Resources) 2 short c42b59ab0fb1 root RUNNING 0:34 20:00 1 df294b9206ff","title":"squeue"},{"location":"cray-docs/docs/cli/training-logs/","text":"Training Logs ./cray llm logs -f This command streams the training logs for the model with the specified identifier. The logs include information about the training process, such as the loss and accuracy of the model at each epoch. If no identifiers are provided, the command will list the most recent model. 0 + export CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 1 + CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 2 +++ dirname /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 3 ++ cd /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 4 ++ pwd 5 + LOCAL_DIRECTORY=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 6 + export PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 7 + PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 8 + mpirun --allow-run-as-root python /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml/cray_megatron/main.py 9 INFO:cray_infra.training.print_logo: 10 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u28a0\u2880\u2850\u2884\u28a2\u2850\u28a2\u2881\u2802\u2804\u2820\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 11 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2844\u28cc\u2830\u28d8\u28c6\u28a7\u285c\u28ee\u28f1\u28ce\u2837\u28cc\u285e\u28cc\u2852\u2824\u28c8\u2820\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 12 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2812\u280a\u2800\u2800\u2800\u2800\u2880\u2822\u2831\u285c\u28de\u28f3\u281d\u28d8\u28ed\u28fc\u28fe\u28f7\u28f6\u28f6\u28ee\u28ec\u28e5\u28d9\u2832\u28a1\u2882\u2821\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 13 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2803\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2822\u28d1\u28a3\u281d\u28ea\u28f5\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f6\u28ef\u28fb\u28a6\u28cd\u2822\u2885\u2882\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 14 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2886\u2871\u280c\u28e1\u289e\u28f5\u28ff\u28ff\u28ff\u283f\u281b\u281b\u2809\u2809\u281b\u281b\u283f\u28b7\u28fd\u28fb\u28e6\u28ce\u28b3\u28cc\u2806\u2871\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 15 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2802\u2820\u280c\u28a2\u2883\u287e\u28f1\u28ff\u28bf\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28bb\u28cf\u283b\u28f7\u28ec\u2873\u28e4\u2842\u281c\u28a0\u2840\u28c0\u2800\u2800\u2840\u2800\u2800\u2800\u2800\u2800\u2800 16 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2880\u2802\u28cc\u2883\u287e\u28a1\u28ff\u28a3\u284f\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b9\u2847\u284a\u28ff\u28ff\u28fe\u28fd\u28db\u2836\u28f6\u28ec\u28ed\u28e5\u28d9\u28da\u28b7\u28f6\u2826\u2864\u2880 17 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2881\u2802\u2830\u284c\u287c\u2821\u28fc\u2883\u287f\u2800\u2800\u2800\u2800MasInt\u2800\u2800\u2800\u2800\u2800\u2800\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28fe\u287f\u283f\u28db\u28ef\u2874\u288f\u2833\u2801\u2800 18 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2811\u284c\u2800\u28c9\u28fe\u28e9\u28fc\u28ff\u28fe\u2847\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u28c0\u28e0\u28e4\u28e4\u28ff\u28ff\u28ff\u28ff\u287f\u289b\u28db\u28ef\u28ed\u2836\u28de\u283b\u28c9\u2812\u2800\u2802\u2800\u2800\u2800 19 \u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u2876\u289d\u28e2\u28fe\u28ff\u28fc\u28ff\u28ff\u28ff\u28ff\u28ff\u28c0\u28fc\u28c0\u28c0\u28c0\u28e4\u28f4\u28f6\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u283f\u28ff\u283f\u285b\u280f\u280d\u2802\u2801\u28a0\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800 20 \u2800\u2820\u2880\u28a5\u28f0\u28fe\u28ff\u28ef\u28f6\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u281f\u28fd\u281f\u28ff\u2810\u2828\u2811\u2840\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 21 \u2850\u28a2\u28df\u28fe\u28ff\u28ff\u28df\u28db\u28ff\u28ff\u28ff\u28ff\u28bf\u28dd\u283b\u283f\u28bf\u28ef\u28db\u28bf\u28ff\u28ff\u28ff\u285b\u283b\u283f\u28db\u283b\u281b\u285b\u2829\u2881\u28f4\u287e\u2883\u28fe\u2807\u2880\u2821\u2802\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 22 \u2808\u2801\u280a\u2819\u2809\u2829\u280c\u2809\u2822\u2809\u2810\u2808\u2802\u2808\u2801\u2809\u2802\u2810\u2809\u28fb\u28f7\u28ed\u281b\u283f\u28f6\u28e6\u28e4\u28e4\u28f4\u28f4\u287e\u281f\u28eb\u28fe\u28ff\u284f\u2800\u2802\u2810\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 23 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2819\u28bb\u28bf\u28b6\u28e4\u28ec\u28c9\u28c9\u28ed\u28e4\u28f4\u28ff\u28ff\u287f\u2803\u2804\u2848\u2801\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 24 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2801\u2818\u288a\u2833\u282d\u287d\u28ff\u283f\u283f\u281f\u281b\u2809\u2800\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 25 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2800\u2801\u2808\u2810\u2800\u2818\u2800\u2808\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 26 27 DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443 28 DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /NousResearch/Llama-3.2-1B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0 29 `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`. 30 INFO:cray_megatron.megatron.training_loop:Training step 0 - epoch 0 - loss 11.851648330688477- learning rate 0.003 31 INFO:cray_megatron.megatron.training_loop:Training step 1 - epoch 0 - loss 11.491947174072266- learning rate 0.0029850000000000002 32 INFO:cray_megatron.megatron.training_loop:Training step 2 - epoch 1 - loss 11.067758560180664- learning rate 0.00297 33 INFO:cray_megatron.megatron.training_loop:Training step 3 - epoch 2 - loss 10.38668155670166- learning rate 0.0029549999999999997 34 INFO:cray_megatron.megatron.training_loop:Training step 4 - epoch 3 - loss 10.309948921203613- learning rate 0.0029399999999999995 35 INFO:cray_megatron.megatron.training_loop:Training step 5 - epoch 4 - loss 10.753833770751953- learning rate 0.0029249999999999996 36 INFO:cray_megatron.megatron.training_loop:Training step 6 - epoch 5 - loss 11.955288887023926- learning rate 0.00291 37 INFO:cray_megatron.megatron.training_loop:Training step 7 - epoch 6 - loss 10.206552505493164- learning rate 0.002895 38 INFO:cray_megatron.megatron.training_loop:Training step 8 - epoch 7 - loss 11.689804077148438- learning rate 0.0028799999999999997 39 INFO:cray_megatron.megatron.training_loop:Training step 9 - epoch 8 - loss 11.29571533203125- learning rate 0.0028649999999999995 40 INFO:cray_megatron.megatron.training_loop:Training step 10 - epoch 9 - loss 9.205053329467773- learning rate 0.0028499999999999997 41 INFO:cray_megatron.megatron.training_loop:Training step 11 - epoch 10 - loss 11.743261337280273- learning rate 0.0028349999999999994 42 INFO:cray_megatron.megatron.training_loop:Training step 12 - epoch 11 - loss 8.788749694824219- learning rate 0.002819999999999999 43 INFO:cray_megatron.megatron.training_loop:Training step 13 - epoch 12 - loss 9.033876419067383- learning rate 0.002804999999999999 44 INFO:cray_megatron.megatron.training_loop:Training step 14 - epoch 13 - loss 11.744029998779297- learning rate 0.0027899999999999986 45 INFO:cray_megatron.megatron.training_loop:Training step 15 - epoch 14 - loss 8.629796981811523- learning rate 0.002774999999999999 46 INFO:cray_megatron.megatron.training_loop:Training step 16 - epoch 15 - loss 8.350188255310059- learning rate 0.002759999999999999 47 INFO:cray_megatron.megatron.training_loop:Training step 17 - epoch 16 - loss 8.093982696533203- learning rate 0.0027449999999999987 48 INFO:cray_megatron.megatron.training_loop:Training step 18 - epoch 17 - loss 7.8525495529174805- learning rate 0.002729999999999999 49 INFO:cray_megatron.megatron.training_loop:Training step 19 - epoch 18 - loss 11.577287673950195- learning rate 0.002714999999999999 50 INFO:cray_megatron.megatron.training_loop:Training step 20 - epoch 19 - loss 7.367895126342773- learning rate 0.0026999999999999993 51 INFO:cray_megatron.megatron.training_loop:Training step 21 - epoch 20 - loss 11.79365348815918- learning rate 0.0026849999999999995 52 INFO:cray_megatron.megatron.training_loop:Training step 22 - epoch 21 - loss 6.936058044433594- learning rate 0.002669999999999999 53 INFO:cray_megatron.megatron.training_loop:Training step 23 - epoch 22 - loss 10.056737899780273- learning rate 0.0026549999999999994 54 INFO:cray_megatron.megatron.training_loop:Training step 24 - epoch 23 - loss 9.305437088012695- learning rate 0.0026399999999999996 55 INFO:cray_megatron.megatron.training_loop:Training step 25 - epoch 24 - loss 6.2938947677612305- learning rate 0.0026249999999999993 56 INFO:cray_megatron.megatron.training_loop:Training step 26 - epoch 25 - loss 6.068697929382324- learning rate 0.0026099999999999995 57 INFO:cray_megatron.megatron.training_loop:Training step 27 - epoch 26 - loss 5.812913417816162- learning rate 0.0025949999999999992 58 INFO:cray_megatron.megatron.training_loop:Training step 28 - epoch 27 - loss 10.825139999389648- learning rate 0.002579999999999999 59 INFO:cray_megatron.megatron.training_loop:Training step 29 - epoch 28 - loss 9.760759353637695- learning rate 0.002564999999999999 60 INFO:cray_megatron.megatron.training_loop:Training step 30 - epoch 29 - loss 10.444537162780762- learning rate 0.0025499999999999993 61 INFO:cray_megatron.megatron.training_loop:Training step 31 - epoch 30 - loss 9.888254165649414- learning rate 0.0025349999999999995 62 INFO:cray_megatron.megatron.training_loop:Training step 32 - epoch 31 - loss 4.675031661987305- learning rate 0.0025199999999999992 63 INFO:cray_megatron.megatron.training_loop:Training step 33 - epoch 32 - loss 4.461902618408203- learning rate 0.0025049999999999994 64 INFO:cray_megatron.megatron.training_loop:Training step 34 - epoch 33 - loss 4.232550621032715- learning rate 0.002489999999999999 65 INFO:cray_megatron.megatron.training_loop:Training step 35 - epoch 34 - loss 9.657859802246094- learning rate 0.0024749999999999993 66 INFO:cray_megatron.megatron.training_loop:Training step 36 - epoch 35 - loss 5.435771942138672- learning rate 0.002459999999999999 67 INFO:cray_megatron.megatron.training_loop:Training step 37 - epoch 36 - loss 4.934456825256348- learning rate 0.0024449999999999993 68 INFO:cray_megatron.megatron.training_loop:Training step 38 - epoch 37 - loss 3.3201217651367188- learning rate 0.0024299999999999994 69 INFO:cray_megatron.megatron.training_loop:Training step 39 - epoch 38 - loss 3.090512990951538- learning rate 0.002414999999999999 70 INFO:cray_megatron.megatron.training_loop:Training step 40 - epoch 39 - loss 2.8569488525390625- learning rate 0.0023999999999999994 71 INFO:cray_megatron.megatron.training_loop:Training step 41 - epoch 40 - loss 2.6222681999206543- learning rate 0.0023849999999999995 72 INFO:cray_megatron.megatron.training_loop:Training step 42 - epoch 41 - loss 2.3898932933807373- learning rate 0.0023699999999999997 73 INFO:cray_megatron.megatron.training_loop:Training step 43 - epoch 42 - loss 2.449845314025879- learning rate 0.0023549999999999995 74 INFO:cray_megatron.megatron.training_loop:Training step 44 - epoch 43 - loss 1.9457842111587524- learning rate 0.0023399999999999996 75 INFO:cray_megatron.megatron.training_loop:Training step 45 - epoch 44 - loss 3.3052239418029785- learning rate 0.002325 76 INFO:cray_megatron.megatron.training_loop:Training step 46 - epoch 45 - loss 1.5511304140090942- learning rate 0.00231 77 INFO:cray_megatron.megatron.training_loop:Training step 47 - epoch 46 - loss 1.381464958190918- learning rate 0.002295 78 INFO:cray_megatron.megatron.training_loop:Training step 48 - epoch 47 - loss 1.8805816173553467- learning rate 0.0022800000000000003 79 INFO:cray_megatron.megatron.training_loop:Training step 49 - epoch 48 - loss 1.6158814430236816- learning rate 0.0022650000000000005 80 INFO:cray_megatron.megatron.training_loop:Training step 50 - epoch 49 - loss 0.9921494722366333- learning rate 0.0022500000000000003 81 INFO:cray_megatron.megatron.training_loop:Training step 51 - epoch 50 - loss 0.9002286791801453- learning rate 0.002235 82 INFO:cray_megatron.megatron.training_loop:Training step 52 - epoch 51 - loss 1.0186548233032227- learning rate 0.00222 83 INFO:cray_megatron.megatron.training_loop:Training step 53 - epoch 52 - loss 0.7658149003982544- learning rate 0.002205 84 INFO:cray_megatron.megatron.training_loop:Training step 54 - epoch 53 - loss 0.7076711654663086- learning rate 0.00219 85 INFO:cray_megatron.megatron.training_loop:Training step 55 - epoch 54 - loss 0.9462921619415283- learning rate 0.002175 86 INFO:cray_megatron.megatron.training_loop:Training step 56 - epoch 55 - loss 0.6228013038635254- learning rate 0.00216 87 INFO:cray_megatron.megatron.training_loop:Training step 57 - epoch 56 - loss 0.5883803367614746- learning rate 0.002145 88 INFO:cray_megatron.megatron.training_loop:Training step 58 - epoch 57 - loss 0.7707682251930237- learning rate 0.0021300000000000004 89 INFO:cray_megatron.megatron.training_loop:Training step 59 - epoch 58 - loss 0.758730411529541- learning rate 0.0021150000000000006 90 INFO:cray_megatron.megatron.training_loop:Training step 60 - epoch 59 - loss 0.506292462348938- learning rate 0.0021000000000000007 91 INFO:cray_megatron.megatron.training_loop:Training step 61 - epoch 60 - loss 0.4830833673477173- learning rate 0.002085000000000001 92 INFO:cray_megatron.megatron.training_loop:Training step 62 - epoch 61 - loss 0.7608119249343872- learning rate 0.002070000000000001 93 INFO:cray_megatron.megatron.training_loop:Training step 63 - epoch 62 - loss 0.43636059761047363- learning rate 0.002055000000000001 94 INFO:cray_megatron.megatron.training_loop:Training step 64 - epoch 63 - loss 0.748888373374939- learning rate 0.002040000000000001 95 INFO:cray_megatron.megatron.training_loop:Training step 65 - epoch 64 - loss 0.3981848359107971- learning rate 0.002025000000000001 96 INFO:cray_megatron.megatron.training_loop:Training step 66 - epoch 65 - loss 0.38111788034439087- learning rate 0.0020100000000000014 97 INFO:cray_megatron.megatron.training_loop:Training step 67 - epoch 66 - loss 0.6918612718582153- learning rate 0.001995000000000001 98 INFO:cray_megatron.megatron.training_loop:Training step 68 - epoch 67 - loss 0.3478345274925232- learning rate 0.001980000000000001 99 INFO:cray_megatron.megatron.training_loop:Training step 69 - epoch 68 - loss 0.7505407333374023- learning rate 0.001965000000000001 100 INFO:cray_megatron.megatron.training_loop:Training step 70 - epoch 69 - loss 0.7745790481567383- learning rate 0.001950000000000001 101 INFO:cray_megatron.megatron.training_loop:Training step 71 - epoch 70 - loss 0.7360649704933167- learning rate 0.001935000000000001 102 INFO:cray_megatron.megatron.training_loop:Training step 72 - epoch 71 - loss 0.6509546637535095- learning rate 0.001920000000000001 103 INFO:cray_megatron.megatron.training_loop:Training step 73 - epoch 72 - loss 0.3059840202331543- learning rate 0.0019050000000000009 104 INFO:cray_megatron.megatron.training_loop:Training step 74 - epoch 73 - loss 0.29385578632354736- learning rate 0.0018900000000000008 105 INFO:cray_megatron.megatron.training_loop:Training step 75 - epoch 74 - loss 0.2902987003326416- learning rate 0.0018750000000000008 106 INFO:cray_megatron.megatron.training_loop:Training step 76 - epoch 75 - loss 0.7161434888839722- learning rate 0.0018600000000000008 107 INFO:cray_megatron.megatron.training_loop:Training step 77 - epoch 76 - loss 0.2615271806716919- learning rate 0.0018450000000000007 108 INFO:cray_megatron.megatron.training_loop:Training step 78 - epoch 77 - loss 0.8070529699325562- learning rate 0.0018300000000000007 109 INFO:cray_megatron.megatron.training_loop:Training step 79 - epoch 78 - loss 0.7276452779769897- learning rate 0.0018150000000000006 110 INFO:cray_megatron.megatron.training_loop:Training step 80 - epoch 79 - loss 0.8069541454315186- learning rate 0.0018000000000000006 111 INFO:cray_megatron.megatron.training_loop:Training step 81 - epoch 80 - loss 0.6734392642974854- learning rate 0.0017850000000000006 112 INFO:cray_megatron.megatron.training_loop:Training step 82 - epoch 81 - loss 0.6499148607254028- learning rate 0.0017700000000000005 113 INFO:cray_megatron.megatron.training_loop:Training step 83 - epoch 82 - loss 0.7235682010650635- learning rate 0.0017550000000000005 114 INFO:cray_megatron.megatron.training_loop:Training step 84 - epoch 83 - loss 0.788324236869812- learning rate 0.0017400000000000004 115 INFO:cray_megatron.megatron.training_loop:Training step 85 - epoch 84 - loss 0.7486412525177002- learning rate 0.0017250000000000004 116 INFO:cray_megatron.megatron.training_loop:Training step 86 - epoch 85 - loss 0.6475511193275452- learning rate 0.0017100000000000006 117 INFO:cray_megatron.megatron.training_loop:Training step 87 - epoch 86 - loss 0.23438769578933716- learning rate 0.0016950000000000005 118 INFO:cray_megatron.megatron.training_loop:Training step 88 - epoch 87 - loss 0.69432532787323- learning rate 0.0016800000000000005 119 INFO:cray_megatron.megatron.training_loop:Training step 89 - epoch 88 - loss 0.701191782951355- learning rate 0.0016650000000000005 120 INFO:cray_megatron.megatron.training_loop:Training step 90 - epoch 89 - loss 0.8208021521568298- learning rate 0.0016500000000000004 121 INFO:cray_megatron.megatron.training_loop:Training step 91 - epoch 90 - loss 0.7423532009124756- learning rate 0.0016350000000000006 122 INFO:cray_megatron.megatron.training_loop:Training step 92 - epoch 91 - loss 0.22764872014522552- learning rate 0.0016200000000000008 123 INFO:cray_megatron.megatron.training_loop:Training step 93 - epoch 92 - loss 0.6770063042640686- learning rate 0.0016050000000000007 124 INFO:cray_megatron.megatron.training_loop:Training step 94 - epoch 93 - loss 0.2195751667022705- learning rate 0.0015900000000000007 125 INFO:cray_megatron.megatron.training_loop:Training step 95 - epoch 94 - loss 0.21528244018554688- learning rate 0.0015750000000000007 126 INFO:cray_megatron.megatron.training_loop:Training step 96 - epoch 95 - loss 0.2105533480644226- learning rate 0.0015600000000000006 127 INFO:cray_megatron.megatron.training_loop:Training step 97 - epoch 96 - loss 0.20401671528816223- learning rate 0.0015450000000000006 128 INFO:cray_megatron.megatron.training_loop:Training step 98 - epoch 97 - loss 0.19684851169586182- learning rate 0.0015300000000000005 129 INFO:cray_megatron.megatron.training_loop:Training step 99 - epoch 98 - loss 0.18342770636081696- learning rate 0.0015150000000000005 130 INFO:cray_megatron.megatron.training_loop:Training step 100 - epoch 99 - loss 0.17346294224262238- learning rate 0.0015000000000000005 131 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_100.pt 132 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model 133 INFO:cray_megatron.megatron.training_loop:Checkpoint on step 100 took 0.748274564743042 seconds 134 INFO:cray_megatron.megatron.training_loop:Training step 101 - epoch 100 - loss 0.16589578986167908- learning rate 0.0014850000000000004 135 INFO:cray_megatron.megatron.training_loop:Training step 102 - epoch 101 - loss 0.7842352986335754- learning rate 0.0014700000000000004 136 INFO:cray_megatron.megatron.training_loop:Training step 103 - epoch 102 - loss 0.8229332566261292- learning rate 0.0014550000000000003 137 INFO:cray_megatron.megatron.training_loop:Training step 104 - epoch 103 - loss 0.749505877494812- learning rate 0.0014400000000000003 138 INFO:cray_megatron.megatron.training_loop:Training step 105 - epoch 104 - loss 0.1399921178817749- learning rate 0.0014250000000000003 139 INFO:cray_megatron.megatron.training_loop:Training step 106 - epoch 105 - loss 0.13615575432777405- learning rate 0.0014100000000000002 140 INFO:cray_megatron.megatron.training_loop:Training step 107 - epoch 106 - loss 0.1328878551721573- learning rate 0.0013950000000000002 141 INFO:cray_megatron.megatron.training_loop:Training step 108 - epoch 107 - loss 0.1299896240234375- learning rate 0.0013800000000000002 142 INFO:cray_megatron.megatron.training_loop:Training step 109 - epoch 108 - loss 0.12737448513507843- learning rate 0.0013650000000000001 143 INFO:cray_megatron.megatron.training_loop:Training step 110 - epoch 109 - loss 0.8569282293319702- learning rate 0.00135 144 INFO:cray_megatron.megatron.training_loop:Training step 111 - epoch 110 - loss 0.8064426183700562- learning rate 0.001335 145 INFO:cray_megatron.megatron.training_loop:Training step 112 - epoch 111 - loss 0.12294523417949677- learning rate 0.00132 146 INFO:cray_megatron.megatron.training_loop:Training step 113 - epoch 112 - loss 0.7471427917480469- learning rate 0.001305 147 INFO:cray_megatron.megatron.training_loop:Training step 114 - epoch 113 - loss 0.12056495994329453- learning rate 0.00129 148 INFO:cray_megatron.megatron.training_loop:Training step 115 - epoch 114 - loss 0.11913363635540009- learning rate 0.0012749999999999999 149 INFO:cray_megatron.megatron.training_loop:Training step 116 - epoch 115 - loss 0.11778314411640167- learning rate 0.0012599999999999998 150 INFO:cray_megatron.megatron.training_loop:Training step 117 - epoch 116 - loss 0.11592821776866913- learning rate 0.0012449999999999998 151 INFO:cray_megatron.megatron.training_loop:Training step 118 - epoch 117 - loss 0.747460126876831- learning rate 0.0012299999999999998 152 INFO:cray_megatron.megatron.training_loop:Training step 119 - epoch 118 - loss 0.11181403696537018- learning rate 0.0012149999999999997 153 INFO:cray_megatron.megatron.training_loop:Training step 120 - epoch 119 - loss 0.11106443405151367- learning rate 0.0011999999999999997 154 INFO:cray_megatron.megatron.training_loop:Training step 121 - epoch 120 - loss 0.7953877449035645- learning rate 0.0011849999999999996 155 INFO:cray_megatron.megatron.training_loop:Training step 122 - epoch 121 - loss 0.7007923126220703- learning rate 0.0011699999999999996 156 INFO:cray_megatron.megatron.training_loop:Training step 123 - epoch 122 - loss 0.5777735710144043- learning rate 0.0011549999999999996 157 INFO:cray_megatron.megatron.training_loop:Training step 124 - epoch 123 - loss 0.10659528523683548- learning rate 0.0011399999999999995 158 INFO:cray_megatron.megatron.training_loop:Training step 125 - epoch 124 - loss 0.6686602830886841- learning rate 0.0011249999999999995 159 INFO:cray_megatron.megatron.training_loop:Training step 126 - epoch 125 - loss 0.7213398218154907- learning rate 0.0011099999999999994 160 INFO:cray_megatron.megatron.training_loop:Training step 127 - epoch 126 - loss 0.10370150953531265- learning rate 0.0010949999999999994 161 INFO:cray_megatron.megatron.training_loop:Training step 128 - epoch 127 - loss 0.715872585773468- learning rate 0.0010799999999999994 162 INFO:cray_megatron.megatron.training_loop:Training step 129 - epoch 128 - loss 0.6672084331512451- learning rate 0.0010649999999999993 163 INFO:cray_megatron.megatron.training_loop:Training step 130 - epoch 129 - loss 0.6094690561294556- learning rate 0.0010499999999999993 164 INFO:cray_megatron.megatron.training_loop:Training step 131 - epoch 130 - loss 0.09981067478656769- learning rate 0.0010349999999999992 165 INFO:cray_megatron.megatron.training_loop:Training step 132 - epoch 131 - loss 0.09831465780735016- learning rate 0.0010199999999999992 166 INFO:cray_megatron.megatron.training_loop:Training step 133 - epoch 132 - loss 0.8732300996780396- learning rate 0.0010049999999999992 167 INFO:cray_megatron.megatron.training_loop:Training step 134 - epoch 133 - loss 0.09659353643655777- learning rate 0.0009899999999999991 168 INFO:cray_megatron.megatron.training_loop:Training step 135 - epoch 134 - loss 0.0957847312092781- learning rate 0.0009749999999999992 169 INFO:cray_megatron.megatron.training_loop:Training step 136 - epoch 135 - loss 0.09486415982246399- learning rate 0.0009599999999999993 170 INFO:cray_megatron.megatron.training_loop:Training step 137 - epoch 136 - loss 0.687118411064148- learning rate 0.0009449999999999992 171 INFO:cray_megatron.megatron.training_loop:Training step 138 - epoch 137 - loss 0.7465814352035522- learning rate 0.0009299999999999993 172 INFO:cray_megatron.megatron.training_loop:Training step 139 - epoch 138 - loss 0.09353536367416382- learning rate 0.0009149999999999994 173 INFO:cray_megatron.megatron.training_loop:Training step 140 - epoch 139 - loss 0.6857355833053589- learning rate 0.0008999999999999993 174 INFO:cray_megatron.megatron.training_loop:Training step 141 - epoch 140 - loss 0.8234232068061829- learning rate 0.0008849999999999993 175 INFO:cray_megatron.megatron.training_loop:Training step 142 - epoch 141 - loss 0.09200795739889145- learning rate 0.0008699999999999994 176 INFO:cray_megatron.megatron.training_loop:Training step 143 - epoch 142 - loss 0.6732250452041626- learning rate 0.0008549999999999993 177 INFO:cray_megatron.megatron.training_loop:Training step 144 - epoch 143 - loss 0.08996626734733582- learning rate 0.0008399999999999993 178 INFO:cray_megatron.megatron.training_loop:Training step 145 - epoch 144 - loss 0.5915161371231079- learning rate 0.0008249999999999992 179 INFO:cray_megatron.megatron.training_loop:Training step 146 - epoch 145 - loss 0.08881303668022156- learning rate 0.0008099999999999992 180 INFO:cray_megatron.megatron.training_loop:Training step 147 - epoch 146 - loss 0.7250931262969971- learning rate 0.0007949999999999993 181 INFO:cray_megatron.megatron.training_loop:Training step 148 - epoch 147 - loss 0.6727677583694458- learning rate 0.0007799999999999993 182 INFO:cray_megatron.megatron.training_loop:Training step 149 - epoch 148 - loss 0.2871503531932831- learning rate 0.0007649999999999993 183 INFO:cray_megatron.megatron.training_loop:Training step 150 - epoch 149 - loss 0.08630774915218353- learning rate 0.0007499999999999993 184 INFO:cray_megatron.megatron.training_loop:Training step 151 - epoch 150 - loss 0.6593747138977051- learning rate 0.0007349999999999992 185 INFO:cray_megatron.megatron.training_loop:Training step 152 - epoch 151 - loss 0.6607116460800171- learning rate 0.0007199999999999992 186 INFO:cray_megatron.megatron.training_loop:Training step 153 - epoch 152 - loss 0.08505091071128845- learning rate 0.0007049999999999991 187 INFO:cray_megatron.megatron.training_loop:Training step 154 - epoch 153 - loss 0.7495298385620117- learning rate 0.0006899999999999991 188 INFO:cray_megatron.megatron.training_loop:Training step 155 - epoch 154 - loss 0.0840618759393692- learning rate 0.0006749999999999992 189 INFO:cray_megatron.megatron.training_loop:Training step 156 - epoch 155 - loss 0.6931415796279907- learning rate 0.0006599999999999991 190 INFO:cray_megatron.megatron.training_loop:Training step 157 - epoch 156 - loss 0.6979023218154907- learning rate 0.0006449999999999992 191 INFO:cray_megatron.megatron.training_loop:Training step 158 - epoch 157 - loss 0.08278802037239075- learning rate 0.0006299999999999992 192 INFO:cray_megatron.megatron.training_loop:Training step 159 - epoch 158 - loss 0.0822552889585495- learning rate 0.0006149999999999991 193 INFO:cray_megatron.megatron.training_loop:Training step 160 - epoch 159 - loss 0.6657384037971497- learning rate 0.0005999999999999991 194 INFO:cray_megatron.megatron.training_loop:Training step 161 - epoch 160 - loss 0.0813547819852829- learning rate 0.000584999999999999 195 INFO:cray_megatron.megatron.training_loop:Training step 162 - epoch 161 - loss 0.6767227649688721- learning rate 0.000569999999999999 196 INFO:cray_megatron.megatron.training_loop:Training step 163 - epoch 162 - loss 0.08070477843284607- learning rate 0.0005549999999999991 197 INFO:cray_megatron.megatron.training_loop:Training step 164 - epoch 163 - loss 0.6971059441566467- learning rate 0.0005399999999999991 198 INFO:cray_megatron.megatron.training_loop:Training step 165 - epoch 164 - loss 0.08001180738210678- learning rate 0.0005249999999999992 199 INFO:cray_megatron.megatron.training_loop:Training step 166 - epoch 165 - loss 0.6862263083457947- learning rate 0.0005099999999999993 200 INFO:cray_megatron.megatron.training_loop:Training step 167 - epoch 166 - loss 0.7431939840316772- learning rate 0.0004949999999999993 201 INFO:cray_megatron.megatron.training_loop:Training step 168 - epoch 167 - loss 0.5616518259048462- learning rate 0.00047999999999999936 202 INFO:cray_megatron.megatron.training_loop:Training step 169 - epoch 168 - loss 0.6773163676261902- learning rate 0.0004649999999999994 203 INFO:cray_megatron.megatron.training_loop:Training step 170 - epoch 169 - loss 0.6207675337791443- learning rate 0.0004499999999999994 204 INFO:cray_megatron.megatron.training_loop:Training step 171 - epoch 170 - loss 0.07802726328372955- learning rate 0.0004349999999999994 205 INFO:cray_megatron.megatron.training_loop:Training step 172 - epoch 171 - loss 0.07783862948417664- learning rate 0.0004199999999999994 206 INFO:cray_megatron.megatron.training_loop:Training step 173 - epoch 172 - loss 0.0776292234659195- learning rate 0.00040499999999999944 207 INFO:cray_megatron.megatron.training_loop:Training step 174 - epoch 173 - loss 0.07749556005001068- learning rate 0.0003899999999999995 208 INFO:cray_megatron.megatron.training_loop:Training step 175 - epoch 174 - loss 0.07696105539798737- learning rate 0.0003749999999999995 209 INFO:cray_megatron.megatron.training_loop:Training step 176 - epoch 175 - loss 0.7952118515968323- learning rate 0.00035999999999999953 210 INFO:cray_megatron.megatron.training_loop:Training step 177 - epoch 176 - loss 0.07636845856904984- learning rate 0.00034499999999999955 211 INFO:cray_megatron.megatron.training_loop:Training step 178 - epoch 177 - loss 0.7084242701530457- learning rate 0.00032999999999999956 212 INFO:cray_megatron.megatron.training_loop:Training step 179 - epoch 178 - loss 0.6410847902297974- learning rate 0.0003149999999999996 213 INFO:cray_megatron.megatron.training_loop:Training step 180 - epoch 179 - loss 0.07575994729995728- learning rate 0.0002999999999999996 214 INFO:cray_megatron.megatron.training_loop:Training step 181 - epoch 180 - loss 0.5927628874778748- learning rate 0.0002849999999999996 215 INFO:cray_megatron.megatron.training_loop:Training step 182 - epoch 181 - loss 0.07534792274236679- learning rate 0.0002699999999999996 216 INFO:cray_megatron.megatron.training_loop:Training step 183 - epoch 182 - loss 0.9427987337112427- learning rate 0.00025499999999999964 217 INFO:cray_megatron.megatron.training_loop:Training step 184 - epoch 183 - loss 0.07497585564851761- learning rate 0.00023999999999999965 218 INFO:cray_megatron.megatron.training_loop:Training step 185 - epoch 184 - loss 0.07496164739131927- learning rate 0.00022499999999999967 219 INFO:cray_megatron.megatron.training_loop:Training step 186 - epoch 185 - loss 0.6813051700592041- learning rate 0.00020999999999999968 220 INFO:cray_megatron.megatron.training_loop:Training step 187 - epoch 186 - loss 0.8017317056655884- learning rate 0.00019499999999999973 221 INFO:cray_megatron.megatron.training_loop:Training step 188 - epoch 187 - loss 0.6315902471542358- learning rate 0.00017999999999999977 222 INFO:cray_megatron.megatron.training_loop:Training step 189 - epoch 188 - loss 0.07442592084407806- learning rate 0.00016499999999999978 223 INFO:cray_megatron.megatron.training_loop:Training step 190 - epoch 189 - loss 0.6251041889190674- learning rate 0.0001499999999999998 224 INFO:cray_megatron.megatron.training_loop:Training step 191 - epoch 190 - loss 0.8014819622039795- learning rate 0.0001349999999999998 225 INFO:cray_megatron.megatron.training_loop:Training step 192 - epoch 191 - loss 0.8565230369567871- learning rate 0.00011999999999999983 226 INFO:cray_megatron.megatron.training_loop:Training step 193 - epoch 192 - loss 0.6923254728317261- learning rate 0.00010499999999999984 227 INFO:cray_megatron.megatron.training_loop:Training step 194 - epoch 193 - loss 0.8134770393371582- learning rate 8.999999999999987e-05 228 INFO:cray_megatron.megatron.training_loop:Training step 195 - epoch 194 - loss 0.8165243864059448- learning rate 7.49999999999999e-05 229 INFO:cray_megatron.megatron.training_loop:Training step 196 - epoch 195 - loss 0.6490029096603394- learning rate 5.999999999999992e-05 230 INFO:cray_megatron.megatron.training_loop:Training step 197 - epoch 196 - loss 0.6595770716667175- learning rate 4.499999999999994e-05 231 INFO:cray_megatron.megatron.training_loop:Training step 198 - epoch 197 - loss 0.07445919513702393- learning rate 2.9999999999999963e-05 232 INFO:cray_megatron.megatron.training_loop:Training step 199 - epoch 198 - loss 0.795946478843689- learning rate 1.4999999999999982e-05 233 INFO:cray_megatron.megatron.training_loop:Training finished successfully after 30.568594932556152 seconds 234 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_199.pt 235 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model","title":"Training Logs"},{"location":"cray-docs/docs/cli/training-logs/#training-logs","text":"./cray llm logs -f This command streams the training logs for the model with the specified identifier. The logs include information about the training process, such as the loss and accuracy of the model at each epoch. If no identifiers are provided, the command will list the most recent model. 0 + export CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 1 + CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 2 +++ dirname /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 3 ++ cd /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 4 ++ pwd 5 + LOCAL_DIRECTORY=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 6 + export PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 7 + PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 8 + mpirun --allow-run-as-root python /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml/cray_megatron/main.py 9 INFO:cray_infra.training.print_logo: 10 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u28a0\u2880\u2850\u2884\u28a2\u2850\u28a2\u2881\u2802\u2804\u2820\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 11 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2844\u28cc\u2830\u28d8\u28c6\u28a7\u285c\u28ee\u28f1\u28ce\u2837\u28cc\u285e\u28cc\u2852\u2824\u28c8\u2820\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 12 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2812\u280a\u2800\u2800\u2800\u2800\u2880\u2822\u2831\u285c\u28de\u28f3\u281d\u28d8\u28ed\u28fc\u28fe\u28f7\u28f6\u28f6\u28ee\u28ec\u28e5\u28d9\u2832\u28a1\u2882\u2821\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 13 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2803\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2822\u28d1\u28a3\u281d\u28ea\u28f5\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f6\u28ef\u28fb\u28a6\u28cd\u2822\u2885\u2882\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 14 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2886\u2871\u280c\u28e1\u289e\u28f5\u28ff\u28ff\u28ff\u283f\u281b\u281b\u2809\u2809\u281b\u281b\u283f\u28b7\u28fd\u28fb\u28e6\u28ce\u28b3\u28cc\u2806\u2871\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 15 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2802\u2820\u280c\u28a2\u2883\u287e\u28f1\u28ff\u28bf\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28bb\u28cf\u283b\u28f7\u28ec\u2873\u28e4\u2842\u281c\u28a0\u2840\u28c0\u2800\u2800\u2840\u2800\u2800\u2800\u2800\u2800\u2800 16 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2880\u2802\u28cc\u2883\u287e\u28a1\u28ff\u28a3\u284f\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b9\u2847\u284a\u28ff\u28ff\u28fe\u28fd\u28db\u2836\u28f6\u28ec\u28ed\u28e5\u28d9\u28da\u28b7\u28f6\u2826\u2864\u2880 17 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2881\u2802\u2830\u284c\u287c\u2821\u28fc\u2883\u287f\u2800\u2800\u2800\u2800MasInt\u2800\u2800\u2800\u2800\u2800\u2800\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28fe\u287f\u283f\u28db\u28ef\u2874\u288f\u2833\u2801\u2800 18 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2811\u284c\u2800\u28c9\u28fe\u28e9\u28fc\u28ff\u28fe\u2847\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u28c0\u28e0\u28e4\u28e4\u28ff\u28ff\u28ff\u28ff\u287f\u289b\u28db\u28ef\u28ed\u2836\u28de\u283b\u28c9\u2812\u2800\u2802\u2800\u2800\u2800 19 \u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u2876\u289d\u28e2\u28fe\u28ff\u28fc\u28ff\u28ff\u28ff\u28ff\u28ff\u28c0\u28fc\u28c0\u28c0\u28c0\u28e4\u28f4\u28f6\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u283f\u28ff\u283f\u285b\u280f\u280d\u2802\u2801\u28a0\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800 20 \u2800\u2820\u2880\u28a5\u28f0\u28fe\u28ff\u28ef\u28f6\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u281f\u28fd\u281f\u28ff\u2810\u2828\u2811\u2840\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 21 \u2850\u28a2\u28df\u28fe\u28ff\u28ff\u28df\u28db\u28ff\u28ff\u28ff\u28ff\u28bf\u28dd\u283b\u283f\u28bf\u28ef\u28db\u28bf\u28ff\u28ff\u28ff\u285b\u283b\u283f\u28db\u283b\u281b\u285b\u2829\u2881\u28f4\u287e\u2883\u28fe\u2807\u2880\u2821\u2802\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 22 \u2808\u2801\u280a\u2819\u2809\u2829\u280c\u2809\u2822\u2809\u2810\u2808\u2802\u2808\u2801\u2809\u2802\u2810\u2809\u28fb\u28f7\u28ed\u281b\u283f\u28f6\u28e6\u28e4\u28e4\u28f4\u28f4\u287e\u281f\u28eb\u28fe\u28ff\u284f\u2800\u2802\u2810\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 23 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2819\u28bb\u28bf\u28b6\u28e4\u28ec\u28c9\u28c9\u28ed\u28e4\u28f4\u28ff\u28ff\u287f\u2803\u2804\u2848\u2801\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 24 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2801\u2818\u288a\u2833\u282d\u287d\u28ff\u283f\u283f\u281f\u281b\u2809\u2800\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 25 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2800\u2801\u2808\u2810\u2800\u2818\u2800\u2808\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 26 27 DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443 28 DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /NousResearch/Llama-3.2-1B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0 29 `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`. 30 INFO:cray_megatron.megatron.training_loop:Training step 0 - epoch 0 - loss 11.851648330688477- learning rate 0.003 31 INFO:cray_megatron.megatron.training_loop:Training step 1 - epoch 0 - loss 11.491947174072266- learning rate 0.0029850000000000002 32 INFO:cray_megatron.megatron.training_loop:Training step 2 - epoch 1 - loss 11.067758560180664- learning rate 0.00297 33 INFO:cray_megatron.megatron.training_loop:Training step 3 - epoch 2 - loss 10.38668155670166- learning rate 0.0029549999999999997 34 INFO:cray_megatron.megatron.training_loop:Training step 4 - epoch 3 - loss 10.309948921203613- learning rate 0.0029399999999999995 35 INFO:cray_megatron.megatron.training_loop:Training step 5 - epoch 4 - loss 10.753833770751953- learning rate 0.0029249999999999996 36 INFO:cray_megatron.megatron.training_loop:Training step 6 - epoch 5 - loss 11.955288887023926- learning rate 0.00291 37 INFO:cray_megatron.megatron.training_loop:Training step 7 - epoch 6 - loss 10.206552505493164- learning rate 0.002895 38 INFO:cray_megatron.megatron.training_loop:Training step 8 - epoch 7 - loss 11.689804077148438- learning rate 0.0028799999999999997 39 INFO:cray_megatron.megatron.training_loop:Training step 9 - epoch 8 - loss 11.29571533203125- learning rate 0.0028649999999999995 40 INFO:cray_megatron.megatron.training_loop:Training step 10 - epoch 9 - loss 9.205053329467773- learning rate 0.0028499999999999997 41 INFO:cray_megatron.megatron.training_loop:Training step 11 - epoch 10 - loss 11.743261337280273- learning rate 0.0028349999999999994 42 INFO:cray_megatron.megatron.training_loop:Training step 12 - epoch 11 - loss 8.788749694824219- learning rate 0.002819999999999999 43 INFO:cray_megatron.megatron.training_loop:Training step 13 - epoch 12 - loss 9.033876419067383- learning rate 0.002804999999999999 44 INFO:cray_megatron.megatron.training_loop:Training step 14 - epoch 13 - loss 11.744029998779297- learning rate 0.0027899999999999986 45 INFO:cray_megatron.megatron.training_loop:Training step 15 - epoch 14 - loss 8.629796981811523- learning rate 0.002774999999999999 46 INFO:cray_megatron.megatron.training_loop:Training step 16 - epoch 15 - loss 8.350188255310059- learning rate 0.002759999999999999 47 INFO:cray_megatron.megatron.training_loop:Training step 17 - epoch 16 - loss 8.093982696533203- learning rate 0.0027449999999999987 48 INFO:cray_megatron.megatron.training_loop:Training step 18 - epoch 17 - loss 7.8525495529174805- learning rate 0.002729999999999999 49 INFO:cray_megatron.megatron.training_loop:Training step 19 - epoch 18 - loss 11.577287673950195- learning rate 0.002714999999999999 50 INFO:cray_megatron.megatron.training_loop:Training step 20 - epoch 19 - loss 7.367895126342773- learning rate 0.0026999999999999993 51 INFO:cray_megatron.megatron.training_loop:Training step 21 - epoch 20 - loss 11.79365348815918- learning rate 0.0026849999999999995 52 INFO:cray_megatron.megatron.training_loop:Training step 22 - epoch 21 - loss 6.936058044433594- learning rate 0.002669999999999999 53 INFO:cray_megatron.megatron.training_loop:Training step 23 - epoch 22 - loss 10.056737899780273- learning rate 0.0026549999999999994 54 INFO:cray_megatron.megatron.training_loop:Training step 24 - epoch 23 - loss 9.305437088012695- learning rate 0.0026399999999999996 55 INFO:cray_megatron.megatron.training_loop:Training step 25 - epoch 24 - loss 6.2938947677612305- learning rate 0.0026249999999999993 56 INFO:cray_megatron.megatron.training_loop:Training step 26 - epoch 25 - loss 6.068697929382324- learning rate 0.0026099999999999995 57 INFO:cray_megatron.megatron.training_loop:Training step 27 - epoch 26 - loss 5.812913417816162- learning rate 0.0025949999999999992 58 INFO:cray_megatron.megatron.training_loop:Training step 28 - epoch 27 - loss 10.825139999389648- learning rate 0.002579999999999999 59 INFO:cray_megatron.megatron.training_loop:Training step 29 - epoch 28 - loss 9.760759353637695- learning rate 0.002564999999999999 60 INFO:cray_megatron.megatron.training_loop:Training step 30 - epoch 29 - loss 10.444537162780762- learning rate 0.0025499999999999993 61 INFO:cray_megatron.megatron.training_loop:Training step 31 - epoch 30 - loss 9.888254165649414- learning rate 0.0025349999999999995 62 INFO:cray_megatron.megatron.training_loop:Training step 32 - epoch 31 - loss 4.675031661987305- learning rate 0.0025199999999999992 63 INFO:cray_megatron.megatron.training_loop:Training step 33 - epoch 32 - loss 4.461902618408203- learning rate 0.0025049999999999994 64 INFO:cray_megatron.megatron.training_loop:Training step 34 - epoch 33 - loss 4.232550621032715- learning rate 0.002489999999999999 65 INFO:cray_megatron.megatron.training_loop:Training step 35 - epoch 34 - loss 9.657859802246094- learning rate 0.0024749999999999993 66 INFO:cray_megatron.megatron.training_loop:Training step 36 - epoch 35 - loss 5.435771942138672- learning rate 0.002459999999999999 67 INFO:cray_megatron.megatron.training_loop:Training step 37 - epoch 36 - loss 4.934456825256348- learning rate 0.0024449999999999993 68 INFO:cray_megatron.megatron.training_loop:Training step 38 - epoch 37 - loss 3.3201217651367188- learning rate 0.0024299999999999994 69 INFO:cray_megatron.megatron.training_loop:Training step 39 - epoch 38 - loss 3.090512990951538- learning rate 0.002414999999999999 70 INFO:cray_megatron.megatron.training_loop:Training step 40 - epoch 39 - loss 2.8569488525390625- learning rate 0.0023999999999999994 71 INFO:cray_megatron.megatron.training_loop:Training step 41 - epoch 40 - loss 2.6222681999206543- learning rate 0.0023849999999999995 72 INFO:cray_megatron.megatron.training_loop:Training step 42 - epoch 41 - loss 2.3898932933807373- learning rate 0.0023699999999999997 73 INFO:cray_megatron.megatron.training_loop:Training step 43 - epoch 42 - loss 2.449845314025879- learning rate 0.0023549999999999995 74 INFO:cray_megatron.megatron.training_loop:Training step 44 - epoch 43 - loss 1.9457842111587524- learning rate 0.0023399999999999996 75 INFO:cray_megatron.megatron.training_loop:Training step 45 - epoch 44 - loss 3.3052239418029785- learning rate 0.002325 76 INFO:cray_megatron.megatron.training_loop:Training step 46 - epoch 45 - loss 1.5511304140090942- learning rate 0.00231 77 INFO:cray_megatron.megatron.training_loop:Training step 47 - epoch 46 - loss 1.381464958190918- learning rate 0.002295 78 INFO:cray_megatron.megatron.training_loop:Training step 48 - epoch 47 - loss 1.8805816173553467- learning rate 0.0022800000000000003 79 INFO:cray_megatron.megatron.training_loop:Training step 49 - epoch 48 - loss 1.6158814430236816- learning rate 0.0022650000000000005 80 INFO:cray_megatron.megatron.training_loop:Training step 50 - epoch 49 - loss 0.9921494722366333- learning rate 0.0022500000000000003 81 INFO:cray_megatron.megatron.training_loop:Training step 51 - epoch 50 - loss 0.9002286791801453- learning rate 0.002235 82 INFO:cray_megatron.megatron.training_loop:Training step 52 - epoch 51 - loss 1.0186548233032227- learning rate 0.00222 83 INFO:cray_megatron.megatron.training_loop:Training step 53 - epoch 52 - loss 0.7658149003982544- learning rate 0.002205 84 INFO:cray_megatron.megatron.training_loop:Training step 54 - epoch 53 - loss 0.7076711654663086- learning rate 0.00219 85 INFO:cray_megatron.megatron.training_loop:Training step 55 - epoch 54 - loss 0.9462921619415283- learning rate 0.002175 86 INFO:cray_megatron.megatron.training_loop:Training step 56 - epoch 55 - loss 0.6228013038635254- learning rate 0.00216 87 INFO:cray_megatron.megatron.training_loop:Training step 57 - epoch 56 - loss 0.5883803367614746- learning rate 0.002145 88 INFO:cray_megatron.megatron.training_loop:Training step 58 - epoch 57 - loss 0.7707682251930237- learning rate 0.0021300000000000004 89 INFO:cray_megatron.megatron.training_loop:Training step 59 - epoch 58 - loss 0.758730411529541- learning rate 0.0021150000000000006 90 INFO:cray_megatron.megatron.training_loop:Training step 60 - epoch 59 - loss 0.506292462348938- learning rate 0.0021000000000000007 91 INFO:cray_megatron.megatron.training_loop:Training step 61 - epoch 60 - loss 0.4830833673477173- learning rate 0.002085000000000001 92 INFO:cray_megatron.megatron.training_loop:Training step 62 - epoch 61 - loss 0.7608119249343872- learning rate 0.002070000000000001 93 INFO:cray_megatron.megatron.training_loop:Training step 63 - epoch 62 - loss 0.43636059761047363- learning rate 0.002055000000000001 94 INFO:cray_megatron.megatron.training_loop:Training step 64 - epoch 63 - loss 0.748888373374939- learning rate 0.002040000000000001 95 INFO:cray_megatron.megatron.training_loop:Training step 65 - epoch 64 - loss 0.3981848359107971- learning rate 0.002025000000000001 96 INFO:cray_megatron.megatron.training_loop:Training step 66 - epoch 65 - loss 0.38111788034439087- learning rate 0.0020100000000000014 97 INFO:cray_megatron.megatron.training_loop:Training step 67 - epoch 66 - loss 0.6918612718582153- learning rate 0.001995000000000001 98 INFO:cray_megatron.megatron.training_loop:Training step 68 - epoch 67 - loss 0.3478345274925232- learning rate 0.001980000000000001 99 INFO:cray_megatron.megatron.training_loop:Training step 69 - epoch 68 - loss 0.7505407333374023- learning rate 0.001965000000000001 100 INFO:cray_megatron.megatron.training_loop:Training step 70 - epoch 69 - loss 0.7745790481567383- learning rate 0.001950000000000001 101 INFO:cray_megatron.megatron.training_loop:Training step 71 - epoch 70 - loss 0.7360649704933167- learning rate 0.001935000000000001 102 INFO:cray_megatron.megatron.training_loop:Training step 72 - epoch 71 - loss 0.6509546637535095- learning rate 0.001920000000000001 103 INFO:cray_megatron.megatron.training_loop:Training step 73 - epoch 72 - loss 0.3059840202331543- learning rate 0.0019050000000000009 104 INFO:cray_megatron.megatron.training_loop:Training step 74 - epoch 73 - loss 0.29385578632354736- learning rate 0.0018900000000000008 105 INFO:cray_megatron.megatron.training_loop:Training step 75 - epoch 74 - loss 0.2902987003326416- learning rate 0.0018750000000000008 106 INFO:cray_megatron.megatron.training_loop:Training step 76 - epoch 75 - loss 0.7161434888839722- learning rate 0.0018600000000000008 107 INFO:cray_megatron.megatron.training_loop:Training step 77 - epoch 76 - loss 0.2615271806716919- learning rate 0.0018450000000000007 108 INFO:cray_megatron.megatron.training_loop:Training step 78 - epoch 77 - loss 0.8070529699325562- learning rate 0.0018300000000000007 109 INFO:cray_megatron.megatron.training_loop:Training step 79 - epoch 78 - loss 0.7276452779769897- learning rate 0.0018150000000000006 110 INFO:cray_megatron.megatron.training_loop:Training step 80 - epoch 79 - loss 0.8069541454315186- learning rate 0.0018000000000000006 111 INFO:cray_megatron.megatron.training_loop:Training step 81 - epoch 80 - loss 0.6734392642974854- learning rate 0.0017850000000000006 112 INFO:cray_megatron.megatron.training_loop:Training step 82 - epoch 81 - loss 0.6499148607254028- learning rate 0.0017700000000000005 113 INFO:cray_megatron.megatron.training_loop:Training step 83 - epoch 82 - loss 0.7235682010650635- learning rate 0.0017550000000000005 114 INFO:cray_megatron.megatron.training_loop:Training step 84 - epoch 83 - loss 0.788324236869812- learning rate 0.0017400000000000004 115 INFO:cray_megatron.megatron.training_loop:Training step 85 - epoch 84 - loss 0.7486412525177002- learning rate 0.0017250000000000004 116 INFO:cray_megatron.megatron.training_loop:Training step 86 - epoch 85 - loss 0.6475511193275452- learning rate 0.0017100000000000006 117 INFO:cray_megatron.megatron.training_loop:Training step 87 - epoch 86 - loss 0.23438769578933716- learning rate 0.0016950000000000005 118 INFO:cray_megatron.megatron.training_loop:Training step 88 - epoch 87 - loss 0.69432532787323- learning rate 0.0016800000000000005 119 INFO:cray_megatron.megatron.training_loop:Training step 89 - epoch 88 - loss 0.701191782951355- learning rate 0.0016650000000000005 120 INFO:cray_megatron.megatron.training_loop:Training step 90 - epoch 89 - loss 0.8208021521568298- learning rate 0.0016500000000000004 121 INFO:cray_megatron.megatron.training_loop:Training step 91 - epoch 90 - loss 0.7423532009124756- learning rate 0.0016350000000000006 122 INFO:cray_megatron.megatron.training_loop:Training step 92 - epoch 91 - loss 0.22764872014522552- learning rate 0.0016200000000000008 123 INFO:cray_megatron.megatron.training_loop:Training step 93 - epoch 92 - loss 0.6770063042640686- learning rate 0.0016050000000000007 124 INFO:cray_megatron.megatron.training_loop:Training step 94 - epoch 93 - loss 0.2195751667022705- learning rate 0.0015900000000000007 125 INFO:cray_megatron.megatron.training_loop:Training step 95 - epoch 94 - loss 0.21528244018554688- learning rate 0.0015750000000000007 126 INFO:cray_megatron.megatron.training_loop:Training step 96 - epoch 95 - loss 0.2105533480644226- learning rate 0.0015600000000000006 127 INFO:cray_megatron.megatron.training_loop:Training step 97 - epoch 96 - loss 0.20401671528816223- learning rate 0.0015450000000000006 128 INFO:cray_megatron.megatron.training_loop:Training step 98 - epoch 97 - loss 0.19684851169586182- learning rate 0.0015300000000000005 129 INFO:cray_megatron.megatron.training_loop:Training step 99 - epoch 98 - loss 0.18342770636081696- learning rate 0.0015150000000000005 130 INFO:cray_megatron.megatron.training_loop:Training step 100 - epoch 99 - loss 0.17346294224262238- learning rate 0.0015000000000000005 131 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_100.pt 132 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model 133 INFO:cray_megatron.megatron.training_loop:Checkpoint on step 100 took 0.748274564743042 seconds 134 INFO:cray_megatron.megatron.training_loop:Training step 101 - epoch 100 - loss 0.16589578986167908- learning rate 0.0014850000000000004 135 INFO:cray_megatron.megatron.training_loop:Training step 102 - epoch 101 - loss 0.7842352986335754- learning rate 0.0014700000000000004 136 INFO:cray_megatron.megatron.training_loop:Training step 103 - epoch 102 - loss 0.8229332566261292- learning rate 0.0014550000000000003 137 INFO:cray_megatron.megatron.training_loop:Training step 104 - epoch 103 - loss 0.749505877494812- learning rate 0.0014400000000000003 138 INFO:cray_megatron.megatron.training_loop:Training step 105 - epoch 104 - loss 0.1399921178817749- learning rate 0.0014250000000000003 139 INFO:cray_megatron.megatron.training_loop:Training step 106 - epoch 105 - loss 0.13615575432777405- learning rate 0.0014100000000000002 140 INFO:cray_megatron.megatron.training_loop:Training step 107 - epoch 106 - loss 0.1328878551721573- learning rate 0.0013950000000000002 141 INFO:cray_megatron.megatron.training_loop:Training step 108 - epoch 107 - loss 0.1299896240234375- learning rate 0.0013800000000000002 142 INFO:cray_megatron.megatron.training_loop:Training step 109 - epoch 108 - loss 0.12737448513507843- learning rate 0.0013650000000000001 143 INFO:cray_megatron.megatron.training_loop:Training step 110 - epoch 109 - loss 0.8569282293319702- learning rate 0.00135 144 INFO:cray_megatron.megatron.training_loop:Training step 111 - epoch 110 - loss 0.8064426183700562- learning rate 0.001335 145 INFO:cray_megatron.megatron.training_loop:Training step 112 - epoch 111 - loss 0.12294523417949677- learning rate 0.00132 146 INFO:cray_megatron.megatron.training_loop:Training step 113 - epoch 112 - loss 0.7471427917480469- learning rate 0.001305 147 INFO:cray_megatron.megatron.training_loop:Training step 114 - epoch 113 - loss 0.12056495994329453- learning rate 0.00129 148 INFO:cray_megatron.megatron.training_loop:Training step 115 - epoch 114 - loss 0.11913363635540009- learning rate 0.0012749999999999999 149 INFO:cray_megatron.megatron.training_loop:Training step 116 - epoch 115 - loss 0.11778314411640167- learning rate 0.0012599999999999998 150 INFO:cray_megatron.megatron.training_loop:Training step 117 - epoch 116 - loss 0.11592821776866913- learning rate 0.0012449999999999998 151 INFO:cray_megatron.megatron.training_loop:Training step 118 - epoch 117 - loss 0.747460126876831- learning rate 0.0012299999999999998 152 INFO:cray_megatron.megatron.training_loop:Training step 119 - epoch 118 - loss 0.11181403696537018- learning rate 0.0012149999999999997 153 INFO:cray_megatron.megatron.training_loop:Training step 120 - epoch 119 - loss 0.11106443405151367- learning rate 0.0011999999999999997 154 INFO:cray_megatron.megatron.training_loop:Training step 121 - epoch 120 - loss 0.7953877449035645- learning rate 0.0011849999999999996 155 INFO:cray_megatron.megatron.training_loop:Training step 122 - epoch 121 - loss 0.7007923126220703- learning rate 0.0011699999999999996 156 INFO:cray_megatron.megatron.training_loop:Training step 123 - epoch 122 - loss 0.5777735710144043- learning rate 0.0011549999999999996 157 INFO:cray_megatron.megatron.training_loop:Training step 124 - epoch 123 - loss 0.10659528523683548- learning rate 0.0011399999999999995 158 INFO:cray_megatron.megatron.training_loop:Training step 125 - epoch 124 - loss 0.6686602830886841- learning rate 0.0011249999999999995 159 INFO:cray_megatron.megatron.training_loop:Training step 126 - epoch 125 - loss 0.7213398218154907- learning rate 0.0011099999999999994 160 INFO:cray_megatron.megatron.training_loop:Training step 127 - epoch 126 - loss 0.10370150953531265- learning rate 0.0010949999999999994 161 INFO:cray_megatron.megatron.training_loop:Training step 128 - epoch 127 - loss 0.715872585773468- learning rate 0.0010799999999999994 162 INFO:cray_megatron.megatron.training_loop:Training step 129 - epoch 128 - loss 0.6672084331512451- learning rate 0.0010649999999999993 163 INFO:cray_megatron.megatron.training_loop:Training step 130 - epoch 129 - loss 0.6094690561294556- learning rate 0.0010499999999999993 164 INFO:cray_megatron.megatron.training_loop:Training step 131 - epoch 130 - loss 0.09981067478656769- learning rate 0.0010349999999999992 165 INFO:cray_megatron.megatron.training_loop:Training step 132 - epoch 131 - loss 0.09831465780735016- learning rate 0.0010199999999999992 166 INFO:cray_megatron.megatron.training_loop:Training step 133 - epoch 132 - loss 0.8732300996780396- learning rate 0.0010049999999999992 167 INFO:cray_megatron.megatron.training_loop:Training step 134 - epoch 133 - loss 0.09659353643655777- learning rate 0.0009899999999999991 168 INFO:cray_megatron.megatron.training_loop:Training step 135 - epoch 134 - loss 0.0957847312092781- learning rate 0.0009749999999999992 169 INFO:cray_megatron.megatron.training_loop:Training step 136 - epoch 135 - loss 0.09486415982246399- learning rate 0.0009599999999999993 170 INFO:cray_megatron.megatron.training_loop:Training step 137 - epoch 136 - loss 0.687118411064148- learning rate 0.0009449999999999992 171 INFO:cray_megatron.megatron.training_loop:Training step 138 - epoch 137 - loss 0.7465814352035522- learning rate 0.0009299999999999993 172 INFO:cray_megatron.megatron.training_loop:Training step 139 - epoch 138 - loss 0.09353536367416382- learning rate 0.0009149999999999994 173 INFO:cray_megatron.megatron.training_loop:Training step 140 - epoch 139 - loss 0.6857355833053589- learning rate 0.0008999999999999993 174 INFO:cray_megatron.megatron.training_loop:Training step 141 - epoch 140 - loss 0.8234232068061829- learning rate 0.0008849999999999993 175 INFO:cray_megatron.megatron.training_loop:Training step 142 - epoch 141 - loss 0.09200795739889145- learning rate 0.0008699999999999994 176 INFO:cray_megatron.megatron.training_loop:Training step 143 - epoch 142 - loss 0.6732250452041626- learning rate 0.0008549999999999993 177 INFO:cray_megatron.megatron.training_loop:Training step 144 - epoch 143 - loss 0.08996626734733582- learning rate 0.0008399999999999993 178 INFO:cray_megatron.megatron.training_loop:Training step 145 - epoch 144 - loss 0.5915161371231079- learning rate 0.0008249999999999992 179 INFO:cray_megatron.megatron.training_loop:Training step 146 - epoch 145 - loss 0.08881303668022156- learning rate 0.0008099999999999992 180 INFO:cray_megatron.megatron.training_loop:Training step 147 - epoch 146 - loss 0.7250931262969971- learning rate 0.0007949999999999993 181 INFO:cray_megatron.megatron.training_loop:Training step 148 - epoch 147 - loss 0.6727677583694458- learning rate 0.0007799999999999993 182 INFO:cray_megatron.megatron.training_loop:Training step 149 - epoch 148 - loss 0.2871503531932831- learning rate 0.0007649999999999993 183 INFO:cray_megatron.megatron.training_loop:Training step 150 - epoch 149 - loss 0.08630774915218353- learning rate 0.0007499999999999993 184 INFO:cray_megatron.megatron.training_loop:Training step 151 - epoch 150 - loss 0.6593747138977051- learning rate 0.0007349999999999992 185 INFO:cray_megatron.megatron.training_loop:Training step 152 - epoch 151 - loss 0.6607116460800171- learning rate 0.0007199999999999992 186 INFO:cray_megatron.megatron.training_loop:Training step 153 - epoch 152 - loss 0.08505091071128845- learning rate 0.0007049999999999991 187 INFO:cray_megatron.megatron.training_loop:Training step 154 - epoch 153 - loss 0.7495298385620117- learning rate 0.0006899999999999991 188 INFO:cray_megatron.megatron.training_loop:Training step 155 - epoch 154 - loss 0.0840618759393692- learning rate 0.0006749999999999992 189 INFO:cray_megatron.megatron.training_loop:Training step 156 - epoch 155 - loss 0.6931415796279907- learning rate 0.0006599999999999991 190 INFO:cray_megatron.megatron.training_loop:Training step 157 - epoch 156 - loss 0.6979023218154907- learning rate 0.0006449999999999992 191 INFO:cray_megatron.megatron.training_loop:Training step 158 - epoch 157 - loss 0.08278802037239075- learning rate 0.0006299999999999992 192 INFO:cray_megatron.megatron.training_loop:Training step 159 - epoch 158 - loss 0.0822552889585495- learning rate 0.0006149999999999991 193 INFO:cray_megatron.megatron.training_loop:Training step 160 - epoch 159 - loss 0.6657384037971497- learning rate 0.0005999999999999991 194 INFO:cray_megatron.megatron.training_loop:Training step 161 - epoch 160 - loss 0.0813547819852829- learning rate 0.000584999999999999 195 INFO:cray_megatron.megatron.training_loop:Training step 162 - epoch 161 - loss 0.6767227649688721- learning rate 0.000569999999999999 196 INFO:cray_megatron.megatron.training_loop:Training step 163 - epoch 162 - loss 0.08070477843284607- learning rate 0.0005549999999999991 197 INFO:cray_megatron.megatron.training_loop:Training step 164 - epoch 163 - loss 0.6971059441566467- learning rate 0.0005399999999999991 198 INFO:cray_megatron.megatron.training_loop:Training step 165 - epoch 164 - loss 0.08001180738210678- learning rate 0.0005249999999999992 199 INFO:cray_megatron.megatron.training_loop:Training step 166 - epoch 165 - loss 0.6862263083457947- learning rate 0.0005099999999999993 200 INFO:cray_megatron.megatron.training_loop:Training step 167 - epoch 166 - loss 0.7431939840316772- learning rate 0.0004949999999999993 201 INFO:cray_megatron.megatron.training_loop:Training step 168 - epoch 167 - loss 0.5616518259048462- learning rate 0.00047999999999999936 202 INFO:cray_megatron.megatron.training_loop:Training step 169 - epoch 168 - loss 0.6773163676261902- learning rate 0.0004649999999999994 203 INFO:cray_megatron.megatron.training_loop:Training step 170 - epoch 169 - loss 0.6207675337791443- learning rate 0.0004499999999999994 204 INFO:cray_megatron.megatron.training_loop:Training step 171 - epoch 170 - loss 0.07802726328372955- learning rate 0.0004349999999999994 205 INFO:cray_megatron.megatron.training_loop:Training step 172 - epoch 171 - loss 0.07783862948417664- learning rate 0.0004199999999999994 206 INFO:cray_megatron.megatron.training_loop:Training step 173 - epoch 172 - loss 0.0776292234659195- learning rate 0.00040499999999999944 207 INFO:cray_megatron.megatron.training_loop:Training step 174 - epoch 173 - loss 0.07749556005001068- learning rate 0.0003899999999999995 208 INFO:cray_megatron.megatron.training_loop:Training step 175 - epoch 174 - loss 0.07696105539798737- learning rate 0.0003749999999999995 209 INFO:cray_megatron.megatron.training_loop:Training step 176 - epoch 175 - loss 0.7952118515968323- learning rate 0.00035999999999999953 210 INFO:cray_megatron.megatron.training_loop:Training step 177 - epoch 176 - loss 0.07636845856904984- learning rate 0.00034499999999999955 211 INFO:cray_megatron.megatron.training_loop:Training step 178 - epoch 177 - loss 0.7084242701530457- learning rate 0.00032999999999999956 212 INFO:cray_megatron.megatron.training_loop:Training step 179 - epoch 178 - loss 0.6410847902297974- learning rate 0.0003149999999999996 213 INFO:cray_megatron.megatron.training_loop:Training step 180 - epoch 179 - loss 0.07575994729995728- learning rate 0.0002999999999999996 214 INFO:cray_megatron.megatron.training_loop:Training step 181 - epoch 180 - loss 0.5927628874778748- learning rate 0.0002849999999999996 215 INFO:cray_megatron.megatron.training_loop:Training step 182 - epoch 181 - loss 0.07534792274236679- learning rate 0.0002699999999999996 216 INFO:cray_megatron.megatron.training_loop:Training step 183 - epoch 182 - loss 0.9427987337112427- learning rate 0.00025499999999999964 217 INFO:cray_megatron.megatron.training_loop:Training step 184 - epoch 183 - loss 0.07497585564851761- learning rate 0.00023999999999999965 218 INFO:cray_megatron.megatron.training_loop:Training step 185 - epoch 184 - loss 0.07496164739131927- learning rate 0.00022499999999999967 219 INFO:cray_megatron.megatron.training_loop:Training step 186 - epoch 185 - loss 0.6813051700592041- learning rate 0.00020999999999999968 220 INFO:cray_megatron.megatron.training_loop:Training step 187 - epoch 186 - loss 0.8017317056655884- learning rate 0.00019499999999999973 221 INFO:cray_megatron.megatron.training_loop:Training step 188 - epoch 187 - loss 0.6315902471542358- learning rate 0.00017999999999999977 222 INFO:cray_megatron.megatron.training_loop:Training step 189 - epoch 188 - loss 0.07442592084407806- learning rate 0.00016499999999999978 223 INFO:cray_megatron.megatron.training_loop:Training step 190 - epoch 189 - loss 0.6251041889190674- learning rate 0.0001499999999999998 224 INFO:cray_megatron.megatron.training_loop:Training step 191 - epoch 190 - loss 0.8014819622039795- learning rate 0.0001349999999999998 225 INFO:cray_megatron.megatron.training_loop:Training step 192 - epoch 191 - loss 0.8565230369567871- learning rate 0.00011999999999999983 226 INFO:cray_megatron.megatron.training_loop:Training step 193 - epoch 192 - loss 0.6923254728317261- learning rate 0.00010499999999999984 227 INFO:cray_megatron.megatron.training_loop:Training step 194 - epoch 193 - loss 0.8134770393371582- learning rate 8.999999999999987e-05 228 INFO:cray_megatron.megatron.training_loop:Training step 195 - epoch 194 - loss 0.8165243864059448- learning rate 7.49999999999999e-05 229 INFO:cray_megatron.megatron.training_loop:Training step 196 - epoch 195 - loss 0.6490029096603394- learning rate 5.999999999999992e-05 230 INFO:cray_megatron.megatron.training_loop:Training step 197 - epoch 196 - loss 0.6595770716667175- learning rate 4.499999999999994e-05 231 INFO:cray_megatron.megatron.training_loop:Training step 198 - epoch 197 - loss 0.07445919513702393- learning rate 2.9999999999999963e-05 232 INFO:cray_megatron.megatron.training_loop:Training step 199 - epoch 198 - loss 0.795946478843689- learning rate 1.4999999999999982e-05 233 INFO:cray_megatron.megatron.training_loop:Training finished successfully after 30.568594932556152 seconds 234 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_199.pt 235 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model","title":"Training Logs"},{"location":"cray-docs/docs/deployment/docker/","text":"Docker builds Check out prebuilt docker containers for different targets: Target Container Latest Release v0.5 NVIDIA gdiamos/cray-nvidia:latest gdiamos/cray-nvidia:v0.5 ARM gdiamos/cray-arm:latest gdiamos/cray-arm:v0.5 AMD gdiamos/cray-amd:latest gdiamos/cray-amd:v0.5 x86 gdiamos/cray-cpu:latest gdiamos/cray-cpu:v0.5 For example, to launch a development server on a modern macbook, e.g. m2 docker run -it -p 8000:8000 --entrypoint /app/cray/scripts/start_one_server.sh gdiamos/cray-arm:v0.5","title":"Docker builds"},{"location":"cray-docs/docs/deployment/docker/#docker-builds","text":"Check out prebuilt docker containers for different targets: Target Container Latest Release v0.5 NVIDIA gdiamos/cray-nvidia:latest gdiamos/cray-nvidia:v0.5 ARM gdiamos/cray-arm:latest gdiamos/cray-arm:v0.5 AMD gdiamos/cray-amd:latest gdiamos/cray-amd:v0.5 x86 gdiamos/cray-cpu:latest gdiamos/cray-cpu:v0.5 For example, to launch a development server on a modern macbook, e.g. m2 docker run -it -p 8000:8000 --entrypoint /app/cray/scripts/start_one_server.sh gdiamos/cray-arm:v0.5","title":"Docker builds"},{"location":"cray-docs/docs/deployment/kubernetes/","text":"Kubernetes Deployment Craylm can be deployed on Kubernetes. This guide will walk you through the steps to deploy Cray on Kubernetes. Prerequisites Make sure you have a kubernetes cluster running. You can set one up yourself or use a managed service like GKE or AKS. You can also use the provided Ansible recipe to install Kubernetes on a Lambda VM running Ubuntu 22.04. The recipe is available at Ansible Kubernetes . If you check out the repository on the server, you can run the playbook with the following command: ansible-playbook -i hosts -v k8.yml The ansible playbook is a list of tasks that will install Kubernetes on the Lambda VM. You can inspect the playbook to see what it does and modify it to suit your needs. It is also possible to run the playbook on a remote server by setting up the SSH connection in the hosts file. [all] lambda ansible_host=... Deploy Craylm To deploy Craylm on Kubernetes, you need to clone the Cray repository and run the following command: git clone git@github.com:cray-lm/cray-lm.git cd cray-lm/deployment/helm/lambda Edit the values.yaml file: set the externalIP address of the Lambda VM, or configure your ingress controller set the model to the huggingface model you want to deploy Then run the following command to deploy Craylm: helm install cray cray Verify the Deployment To verify the deployment, you can run the following command: kubectl get pods You should see the Craylm pod running. You can get the logs of the pod by running: kubectl logs cray-...","title":"Kubernetes Deployment"},{"location":"cray-docs/docs/deployment/kubernetes/#kubernetes-deployment","text":"Craylm can be deployed on Kubernetes. This guide will walk you through the steps to deploy Cray on Kubernetes.","title":"Kubernetes Deployment"},{"location":"cray-docs/docs/deployment/kubernetes/#prerequisites","text":"Make sure you have a kubernetes cluster running. You can set one up yourself or use a managed service like GKE or AKS. You can also use the provided Ansible recipe to install Kubernetes on a Lambda VM running Ubuntu 22.04. The recipe is available at Ansible Kubernetes . If you check out the repository on the server, you can run the playbook with the following command: ansible-playbook -i hosts -v k8.yml The ansible playbook is a list of tasks that will install Kubernetes on the Lambda VM. You can inspect the playbook to see what it does and modify it to suit your needs. It is also possible to run the playbook on a remote server by setting up the SSH connection in the hosts file. [all] lambda ansible_host=...","title":"Prerequisites"},{"location":"cray-docs/docs/deployment/kubernetes/#deploy-craylm","text":"To deploy Craylm on Kubernetes, you need to clone the Cray repository and run the following command: git clone git@github.com:cray-lm/cray-lm.git cd cray-lm/deployment/helm/lambda Edit the values.yaml file: set the externalIP address of the Lambda VM, or configure your ingress controller set the model to the huggingface model you want to deploy Then run the following command to deploy Craylm: helm install cray cray","title":"Deploy Craylm"},{"location":"cray-docs/docs/deployment/kubernetes/#verify-the-deployment","text":"To verify the deployment, you can run the following command: kubectl get pods You should see the Craylm pod running. You can get the logs of the pod by running: kubectl logs cray-...","title":"Verify the Deployment"},{"location":"cray-docs/docs/deployment/laptop/","text":"Laptop Craylm can be run on your laptop for development purposes. It requires Docker. Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up You should see the server come up. (environment) gregorydiamos@Air-Gregory cray % ./cray up +++ dirname ./cray ++ cd . ++ pwd + LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray + /Users/gregorydiamos/checkout/cray/cmd/bashly.sh generate ++++ dirname /Users/gregorydiamos/checkout/cray/cmd/bashly.sh +++ cd /Users/gregorydiamos/checkout/cray/cmd +++ pwd ++ LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray/cmd +++ id -u +++ id -g ++ docker run --rm -it --user 501:20 --volume /Users/gregorydiamos/checkout/cray/cmd:/app/cmd --volume /Users/gregorydiamos/checkout/cray/cmd/../scripts:/app/scripts --volume /Users/gregorydiamos/checkout/cray/cmd/bashly-settings.yml:/app/bashly-settings.yml dannyben/bashly generate creating user files in cmd skipped cmd/build_image_command.sh (exists) skipped cmd/depot_build_command.sh (exists) skipped cmd/up_command.sh (exists) skipped cmd/test_command.sh (exists) skipped cmd/deploy_command.sh (exists) skipped cmd/serve_command.sh (exists) skipped cmd/llm_plot_command.sh (exists) skipped cmd/llm_logs_command.sh (exists) skipped cmd/llm_ls_command.sh (exists) skipped cmd/llm_squeue_command.sh (exists) skipped cmd/diffusion_command.sh (exists) created /app/scripts/cray run /app/scripts/cray --help to test your bash script + /Users/gregorydiamos/checkout/cray/scripts/cray up [+] Running 0/14.2s (10/37) docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s [+] Building 217.0s (39/39) FINISHED docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 4.35kB 0.0s => [vllm internal] load metadata for docker.io/library/ubuntu:24.04 0.3s => [vllm internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => CACHED [vllm cpu 1/6] FROM docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => => resolve docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => [vllm internal] load build context 0.2s => => transferring context: 723.40kB 0.2s => [vllm cpu 2/6] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y python3 python3-pip python3-venv openmpi-bin libopenmpi-dev libpmix-dev 60.7s => [vllm cpu 3/6] RUN python3 -m venv /app/.venv 2.6s => [vllm cpu 4/6] RUN . /app/.venv/bin/activate 0.1s => [vllm cpu 5/6] RUN pip install uv 1.4s => [vllm cpu 6/6] RUN uv pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cpu 6.3s => [vllm vllm 1/17] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y curl ccache git vim numactl gcc-12 g++-12 libomp-dev libnuma-dev && apt-get ins 74.9s => [vllm vllm 2/17] COPY ./requirements.txt /app/cray/requirements.txt 0.1s => [vllm vllm 3/17] COPY ./test/requirements-pytest.txt /app/cray/requirements-pytest.txt 0.0s => [vllm vllm 4/17] COPY ./infra/requirements-vllm-build.txt /app/cray/requirements-vllm-build.txt 0.0s => [vllm vllm 5/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements.txt 8.6s => [vllm vllm 6/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-vllm-build.txt 1.6s => [vllm vllm 7/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-pytest.txt 0.5s => [vllm vllm 8/17] WORKDIR /app/cray 0.0s => [vllm vllm 9/17] COPY ./infra/cray_infra/vllm /app/cray/infra/cray_infra/vllm 0.1s => [vllm vllm 10/17] COPY ./infra/setup.py /app/cray/infra/cray_infra/setup.py 0.0s => [vllm vllm 11/17] COPY ./infra/CMakeLists.txt /app/cray/infra/cray_infra/CMakeLists.txt 0.0s => [vllm vllm 12/17] COPY ./infra/cmake /app/cray/infra/cray_infra/cmake 0.0s => [vllm vllm 13/17] COPY ./infra/csrc /app/cray/infra/cray_infra/csrc 0.0s => [vllm vllm 14/17] COPY ./infra/requirements-vllm.txt /app/cray/infra/cray_infra/requirements.txt 0.0s => [vllm vllm 15/17] WORKDIR /app/cray/infra/cray_infra 0.0s => [vllm vllm 16/17] RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.cache/ccache MAX_JOBS=8 TORCH_CUDA_ARCH_LIST=\"7.5 8.6\" VLLM_TARGET_DEVICE=cpu python 39.0s => [vllm vllm 17/17] WORKDIR /app/cray 0.0s => [vllm infra 1/10] RUN apt-get update -y && apt-get install -y slurm-wlm libslurm-dev build-essential less curl wget net-tools vim iputils-ping && rm -rf /var/lib/apt/lists/* 15.0s => [vllm infra 2/10] COPY ./infra/slurm_src /app/cray/infra/slurm_src 0.0s => [vllm infra 3/10] RUN /app/cray/infra/slurm_src/compile.sh 0.2s => [vllm infra 4/10] RUN mkdir -p /app/cray/jobs 0.1s => [vllm infra 5/10] COPY ./infra /app/cray/infra 0.9s => [vllm infra 6/10] COPY ./sdk /app/cray/sdk 0.0s => [vllm infra 7/10] COPY ./test /app/cray/test 0.0s => [vllm infra 8/10] COPY ./cray /app/cray/cray 0.0s => [vllm infra 9/10] COPY ./ml /app/cray/ml 0.0s => [vllm infra 10/10] COPY ./scripts /app/cray/scripts 0.0s => [vllm] exporting to image 4.0s => => exporting layers 4.0s => => writing image sha256:2e9c8cea0daed2da4c4bd5bec4c875c1e4a773395b95cd4ddbd7823479c4ef83 0.0s [+] Running 2/2o docker.io/library/cray-vllm 0.0s \u2714 Service vllm Built 217.1s \u2714 Container cray-vllm-1 Recreated 0.2s Attaching to vllm-1 vllm-1 | +++ dirname /app/cray/scripts/start_one_server.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + /app/cray/scripts/start_slurm.sh vllm-1 | +++ dirname /app/cray/scripts/start_slurm.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + python /app/cray/scripts/../infra/cray_infra/slurm/discovery/discover_clusters.py vllm-1 | + slurmctld vllm-1 | + slurmd vllm-1 | + python -m cray_infra.one_server.main vllm-1 | INFO 01-09 18:47:16 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | INFO: Will watch for changes in these directories: ['/app/cray/infra/cray_infra'] vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | INFO: Started reloader process [38] using WatchFiles vllm-1 | INFO 01-09 18:47:19 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | DEBUG:asyncio:Using selector: EpollSelector vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting servers: ['api'] vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting API server vllm-1 | INFO:persistqueue.serializers.pickle:Selected pickle protocol: '4' vllm-1 | INFO:persistqueue:DBUtils may not be installed, install via 'pip install persist-queue[extra]' vllm-1 | INFO: Started server process [51] vllm-1 | INFO: Waiting for application startup. vllm-1 | INFO:cray_infra.training.register_megatron_models:Registering Megatron models vllm-1 | INFO: Application startup complete. vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | ERROR:cray_infra.one_server.wait_for_vllm:Error getting health: Cannot connect to host localhost:8001 ssl:default [Connect call failed ('127.0.0.1', 8001)] vllm-1 | INFO:cray_infra.training.register_megatron_models:VLLM is not ready. Skipping model registration vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Restarting Megatron jobs vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Slurm jobs running: [] vllm-1 | DEBUG:persistqueue.sqlbase:Initializing Sqlite3 Queue with path /app/cray/inference_work_queue.sqlite vllm-1 | INFO:cray_infra.generate.clear_acked_requests_from_queue:Cleared 0 acked requests from the queue.","title":"Laptop"},{"location":"cray-docs/docs/deployment/laptop/#laptop","text":"Craylm can be run on your laptop for development purposes. It requires Docker. Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up You should see the server come up. (environment) gregorydiamos@Air-Gregory cray % ./cray up +++ dirname ./cray ++ cd . ++ pwd + LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray + /Users/gregorydiamos/checkout/cray/cmd/bashly.sh generate ++++ dirname /Users/gregorydiamos/checkout/cray/cmd/bashly.sh +++ cd /Users/gregorydiamos/checkout/cray/cmd +++ pwd ++ LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray/cmd +++ id -u +++ id -g ++ docker run --rm -it --user 501:20 --volume /Users/gregorydiamos/checkout/cray/cmd:/app/cmd --volume /Users/gregorydiamos/checkout/cray/cmd/../scripts:/app/scripts --volume /Users/gregorydiamos/checkout/cray/cmd/bashly-settings.yml:/app/bashly-settings.yml dannyben/bashly generate creating user files in cmd skipped cmd/build_image_command.sh (exists) skipped cmd/depot_build_command.sh (exists) skipped cmd/up_command.sh (exists) skipped cmd/test_command.sh (exists) skipped cmd/deploy_command.sh (exists) skipped cmd/serve_command.sh (exists) skipped cmd/llm_plot_command.sh (exists) skipped cmd/llm_logs_command.sh (exists) skipped cmd/llm_ls_command.sh (exists) skipped cmd/llm_squeue_command.sh (exists) skipped cmd/diffusion_command.sh (exists) created /app/scripts/cray run /app/scripts/cray --help to test your bash script + /Users/gregorydiamos/checkout/cray/scripts/cray up [+] Running 0/14.2s (10/37) docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s [+] Building 217.0s (39/39) FINISHED docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 4.35kB 0.0s => [vllm internal] load metadata for docker.io/library/ubuntu:24.04 0.3s => [vllm internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => CACHED [vllm cpu 1/6] FROM docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => => resolve docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => [vllm internal] load build context 0.2s => => transferring context: 723.40kB 0.2s => [vllm cpu 2/6] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y python3 python3-pip python3-venv openmpi-bin libopenmpi-dev libpmix-dev 60.7s => [vllm cpu 3/6] RUN python3 -m venv /app/.venv 2.6s => [vllm cpu 4/6] RUN . /app/.venv/bin/activate 0.1s => [vllm cpu 5/6] RUN pip install uv 1.4s => [vllm cpu 6/6] RUN uv pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cpu 6.3s => [vllm vllm 1/17] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y curl ccache git vim numactl gcc-12 g++-12 libomp-dev libnuma-dev && apt-get ins 74.9s => [vllm vllm 2/17] COPY ./requirements.txt /app/cray/requirements.txt 0.1s => [vllm vllm 3/17] COPY ./test/requirements-pytest.txt /app/cray/requirements-pytest.txt 0.0s => [vllm vllm 4/17] COPY ./infra/requirements-vllm-build.txt /app/cray/requirements-vllm-build.txt 0.0s => [vllm vllm 5/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements.txt 8.6s => [vllm vllm 6/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-vllm-build.txt 1.6s => [vllm vllm 7/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-pytest.txt 0.5s => [vllm vllm 8/17] WORKDIR /app/cray 0.0s => [vllm vllm 9/17] COPY ./infra/cray_infra/vllm /app/cray/infra/cray_infra/vllm 0.1s => [vllm vllm 10/17] COPY ./infra/setup.py /app/cray/infra/cray_infra/setup.py 0.0s => [vllm vllm 11/17] COPY ./infra/CMakeLists.txt /app/cray/infra/cray_infra/CMakeLists.txt 0.0s => [vllm vllm 12/17] COPY ./infra/cmake /app/cray/infra/cray_infra/cmake 0.0s => [vllm vllm 13/17] COPY ./infra/csrc /app/cray/infra/cray_infra/csrc 0.0s => [vllm vllm 14/17] COPY ./infra/requirements-vllm.txt /app/cray/infra/cray_infra/requirements.txt 0.0s => [vllm vllm 15/17] WORKDIR /app/cray/infra/cray_infra 0.0s => [vllm vllm 16/17] RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.cache/ccache MAX_JOBS=8 TORCH_CUDA_ARCH_LIST=\"7.5 8.6\" VLLM_TARGET_DEVICE=cpu python 39.0s => [vllm vllm 17/17] WORKDIR /app/cray 0.0s => [vllm infra 1/10] RUN apt-get update -y && apt-get install -y slurm-wlm libslurm-dev build-essential less curl wget net-tools vim iputils-ping && rm -rf /var/lib/apt/lists/* 15.0s => [vllm infra 2/10] COPY ./infra/slurm_src /app/cray/infra/slurm_src 0.0s => [vllm infra 3/10] RUN /app/cray/infra/slurm_src/compile.sh 0.2s => [vllm infra 4/10] RUN mkdir -p /app/cray/jobs 0.1s => [vllm infra 5/10] COPY ./infra /app/cray/infra 0.9s => [vllm infra 6/10] COPY ./sdk /app/cray/sdk 0.0s => [vllm infra 7/10] COPY ./test /app/cray/test 0.0s => [vllm infra 8/10] COPY ./cray /app/cray/cray 0.0s => [vllm infra 9/10] COPY ./ml /app/cray/ml 0.0s => [vllm infra 10/10] COPY ./scripts /app/cray/scripts 0.0s => [vllm] exporting to image 4.0s => => exporting layers 4.0s => => writing image sha256:2e9c8cea0daed2da4c4bd5bec4c875c1e4a773395b95cd4ddbd7823479c4ef83 0.0s [+] Running 2/2o docker.io/library/cray-vllm 0.0s \u2714 Service vllm Built 217.1s \u2714 Container cray-vllm-1 Recreated 0.2s Attaching to vllm-1 vllm-1 | +++ dirname /app/cray/scripts/start_one_server.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + /app/cray/scripts/start_slurm.sh vllm-1 | +++ dirname /app/cray/scripts/start_slurm.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + python /app/cray/scripts/../infra/cray_infra/slurm/discovery/discover_clusters.py vllm-1 | + slurmctld vllm-1 | + slurmd vllm-1 | + python -m cray_infra.one_server.main vllm-1 | INFO 01-09 18:47:16 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | INFO: Will watch for changes in these directories: ['/app/cray/infra/cray_infra'] vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | INFO: Started reloader process [38] using WatchFiles vllm-1 | INFO 01-09 18:47:19 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | DEBUG:asyncio:Using selector: EpollSelector vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting servers: ['api'] vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting API server vllm-1 | INFO:persistqueue.serializers.pickle:Selected pickle protocol: '4' vllm-1 | INFO:persistqueue:DBUtils may not be installed, install via 'pip install persist-queue[extra]' vllm-1 | INFO: Started server process [51] vllm-1 | INFO: Waiting for application startup. vllm-1 | INFO:cray_infra.training.register_megatron_models:Registering Megatron models vllm-1 | INFO: Application startup complete. vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | ERROR:cray_infra.one_server.wait_for_vllm:Error getting health: Cannot connect to host localhost:8001 ssl:default [Connect call failed ('127.0.0.1', 8001)] vllm-1 | INFO:cray_infra.training.register_megatron_models:VLLM is not ready. Skipping model registration vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Restarting Megatron jobs vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Slurm jobs running: [] vllm-1 | DEBUG:persistqueue.sqlbase:Initializing Sqlite3 Queue with path /app/cray/inference_work_queue.sqlite vllm-1 | INFO:cray_infra.generate.clear_acked_requests_from_queue:Cleared 0 acked requests from the queue.","title":"Laptop"},{"location":"cray-docs/docs/deployment/modal-details/","text":"SMI Platform Deployment Guide Prerequisites Docker Dockerhub account depot.dev account Modal account 1. Build Docker Image with depot.dev Create depot.dev Account Visit https://depot.dev/ and create an account Build and Push Docker Image depot build --platform linux/amd64 \\ --build-arg BASE_NAME=cpu \\ --build-arg VLLM_TARGET_DEVICE=cpu \\ -t your-dockerhub/smi-platform:latest \\ --shm-size=8g . --push Authorization When prompted, click the authorization link (e.g., https://depot.dev/orgs/qmkv-blah-blah ) 2. Deploy to Modal Set Up Modal Create an account at https://modal.com Join the smi-workspace Install Modal Python package bash pip install modal Authenticate Modal bash modal setup This will open a web browser for authentication If not, manually copy the provided URL Configure Deployment Update Docker Image Credentials In deployment/modal/staging/cpu/cray.py , update the image configuration: cray_image = ( modal.Image.from_registry( \"your-dockerhub/image-tag\", secret=modal.Secret.from_dict( { \"REGISTRY_USERNAME\": \"your-username\", \"REGISTRY_PASSWORD\": \"your-dockerhub-passwd\", } ), ) .pip_install(\"fastapi >= 0.107.0\", \"pydantic >= 2.9\") .copy_local_file( local_path=local_config_path, remote_path=\"/app/cray/cray-config.yaml\" ) ) Serve Deployment modal serve deployment/modal/staging/cpu/deploy.py Expected Output Two web function URLs will be generated: FastAPI App URL VLLM App URL Update Deployment Configuration Stop the previous modal serve command Update deployment/modal/staging/cpu/cpu-deployment.yaml Replace api_url with FastAPI App URL Replace vllm_api_url with VLLM App URL Rerun Deployment modal serve deployment/modal/staging/cpu/cray.py 3. Testing Deployment Health Check PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/health.py {'api': 'up', 'vllm': 'up', 'all': 'up'} Expected output: {'api': 'up', 'vllm': 'up', 'all': 'up'} Generate Test PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/generate.py {'responses': [' 0 + 0 = 0\\nWhat is 0 + 0', ' 2. What is 1 + 1? 2. What is', ' What is 2 + 2? What is 2 + 2?', ' 6\\nWhat is 3 + 3? 6\\nWhat is']} Verifies text generation functionality Training Job Test PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': '800fc373a8befb18cff123cca003c10b2744ca37b488541a751bbb026063072c', 'job_directory': '/app/cray/jobs/77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37', 'model_name': '77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37'} Launches and verifies a training job Troubleshooting Ensure all credentials and URLs are correctly configured Check network connectivity Verify Docker and Modal authentication Notes Replace placeholders like your-dockerhub , your-username , and paths with your actual values Keep credentials secure and do not commit them to version control","title":"SMI Platform Deployment Guide"},{"location":"cray-docs/docs/deployment/modal-details/#smi-platform-deployment-guide","text":"","title":"SMI Platform Deployment Guide"},{"location":"cray-docs/docs/deployment/modal-details/#prerequisites","text":"Docker Dockerhub account depot.dev account Modal account","title":"Prerequisites"},{"location":"cray-docs/docs/deployment/modal-details/#1-build-docker-image-with-depotdev","text":"","title":"1. Build Docker Image with depot.dev"},{"location":"cray-docs/docs/deployment/modal-details/#create-depotdev-account","text":"Visit https://depot.dev/ and create an account","title":"Create depot.dev Account"},{"location":"cray-docs/docs/deployment/modal-details/#build-and-push-docker-image","text":"depot build --platform linux/amd64 \\ --build-arg BASE_NAME=cpu \\ --build-arg VLLM_TARGET_DEVICE=cpu \\ -t your-dockerhub/smi-platform:latest \\ --shm-size=8g . --push","title":"Build and Push Docker Image"},{"location":"cray-docs/docs/deployment/modal-details/#authorization","text":"When prompted, click the authorization link (e.g., https://depot.dev/orgs/qmkv-blah-blah )","title":"Authorization"},{"location":"cray-docs/docs/deployment/modal-details/#2-deploy-to-modal","text":"","title":"2. Deploy to Modal"},{"location":"cray-docs/docs/deployment/modal-details/#set-up-modal","text":"Create an account at https://modal.com Join the smi-workspace Install Modal Python package bash pip install modal Authenticate Modal bash modal setup This will open a web browser for authentication If not, manually copy the provided URL","title":"Set Up Modal"},{"location":"cray-docs/docs/deployment/modal-details/#configure-deployment","text":"","title":"Configure Deployment"},{"location":"cray-docs/docs/deployment/modal-details/#update-docker-image-credentials","text":"In deployment/modal/staging/cpu/cray.py , update the image configuration: cray_image = ( modal.Image.from_registry( \"your-dockerhub/image-tag\", secret=modal.Secret.from_dict( { \"REGISTRY_USERNAME\": \"your-username\", \"REGISTRY_PASSWORD\": \"your-dockerhub-passwd\", } ), ) .pip_install(\"fastapi >= 0.107.0\", \"pydantic >= 2.9\") .copy_local_file( local_path=local_config_path, remote_path=\"/app/cray/cray-config.yaml\" ) )","title":"Update Docker Image Credentials"},{"location":"cray-docs/docs/deployment/modal-details/#serve-deployment","text":"modal serve deployment/modal/staging/cpu/deploy.py","title":"Serve Deployment"},{"location":"cray-docs/docs/deployment/modal-details/#expected-output","text":"Two web function URLs will be generated: FastAPI App URL VLLM App URL","title":"Expected Output"},{"location":"cray-docs/docs/deployment/modal-details/#update-deployment-configuration","text":"Stop the previous modal serve command Update deployment/modal/staging/cpu/cpu-deployment.yaml Replace api_url with FastAPI App URL Replace vllm_api_url with VLLM App URL","title":"Update Deployment Configuration"},{"location":"cray-docs/docs/deployment/modal-details/#rerun-deployment","text":"modal serve deployment/modal/staging/cpu/cray.py","title":"Rerun Deployment"},{"location":"cray-docs/docs/deployment/modal-details/#3-testing-deployment","text":"","title":"3. Testing Deployment"},{"location":"cray-docs/docs/deployment/modal-details/#health-check","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/health.py {'api': 'up', 'vllm': 'up', 'all': 'up'} Expected output: {'api': 'up', 'vllm': 'up', 'all': 'up'}","title":"Health Check"},{"location":"cray-docs/docs/deployment/modal-details/#generate-test","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/generate.py {'responses': [' 0 + 0 = 0\\nWhat is 0 + 0', ' 2. What is 1 + 1? 2. What is', ' What is 2 + 2? What is 2 + 2?', ' 6\\nWhat is 3 + 3? 6\\nWhat is']} Verifies text generation functionality","title":"Generate Test"},{"location":"cray-docs/docs/deployment/modal-details/#training-job-test","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': '800fc373a8befb18cff123cca003c10b2744ca37b488541a751bbb026063072c', 'job_directory': '/app/cray/jobs/77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37', 'model_name': '77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37'} Launches and verifies a training job","title":"Training Job Test"},{"location":"cray-docs/docs/deployment/modal-details/#troubleshooting","text":"Ensure all credentials and URLs are correctly configured Check network connectivity Verify Docker and Modal authentication","title":"Troubleshooting"},{"location":"cray-docs/docs/deployment/modal-details/#notes","text":"Replace placeholders like your-dockerhub , your-username , and paths with your actual values Keep credentials secure and do not commit them to version control","title":"Notes"},{"location":"cray-docs/docs/deployment/modal/","text":"Modal Craylm can be deployed on Modal for easy access to GPUs. Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray ./cray deploy Modal should give you an endpoint you can start using.","title":"Modal"},{"location":"cray-docs/docs/deployment/modal/#modal","text":"Craylm can be deployed on Modal for easy access to GPUs. Clone the Craylm repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray ./cray deploy Modal should give you an endpoint you can start using.","title":"Modal"},{"location":"docs/","text":"Welcome to ScalarLM ScalarLM is a fully open source, CC-0 Licensed, integrated LLM inference and training platform. ScalarLM builds on top of the vLLM inference engine, the Megatron-LM training framework, and the HuggingFace model hub. It unifies the capabilities of these tools into a single platform, enabling users to easily perform LLM inference and training, and build higher lever applications such as Agents with a twist - they can teach themselves new abilities via back propagation. ScalarLM is designed for high peformance. It inherits the distributed training capabilities of Megatron-LM and the optimized inference engine of vLLM. Cray is also designed to be easy to use. It provides an OpenAI compatible server and a simple command line interface for users to interact with the platform. ScalarLM is inspired by the work of Seymour Roger Cray (September 28, 1925 \u2013 October 5, 1996), an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades, and founded Cray Research, which built many of these machines. Called \"the father of supercomputing\", Cray has been credited with creating the supercomputer industry. Learn more about ScalarLM at our Blog and GitHub . Get in Touch","title":"Welcome to ScalarLM"},{"location":"docs/#welcome-to-scalarlm","text":"ScalarLM is a fully open source, CC-0 Licensed, integrated LLM inference and training platform. ScalarLM builds on top of the vLLM inference engine, the Megatron-LM training framework, and the HuggingFace model hub. It unifies the capabilities of these tools into a single platform, enabling users to easily perform LLM inference and training, and build higher lever applications such as Agents with a twist - they can teach themselves new abilities via back propagation. ScalarLM is designed for high peformance. It inherits the distributed training capabilities of Megatron-LM and the optimized inference engine of vLLM. Cray is also designed to be easy to use. It provides an OpenAI compatible server and a simple command line interface for users to interact with the platform. ScalarLM is inspired by the work of Seymour Roger Cray (September 28, 1925 \u2013 October 5, 1996), an American electrical engineer and supercomputer architect who designed a series of computers that were the fastest in the world for decades, and founded Cray Research, which built many of these machines. Called \"the father of supercomputing\", Cray has been credited with creating the supercomputer industry. Learn more about ScalarLM at our Blog and GitHub . Get in Touch","title":"Welcome to ScalarLM"},{"location":"docs/arch/","text":"ScalarLM ScalarLM has three high level APIs: completions provides OpenAI client compatibility generate provides a simple interface for generating text train provides a simple interface for submitting training jobs Inference is performed by vLLM workers that are orchestrated by pulling requests from a queue. Training is performed by Megatron-LM workers that are orchestrated by SLURM. Trained models are automatically registered with the inference workers.","title":"ScalarLM"},{"location":"docs/arch/#scalarlm","text":"ScalarLM has three high level APIs: completions provides OpenAI client compatibility generate provides a simple interface for generating text train provides a simple interface for submitting training jobs Inference is performed by vLLM workers that are orchestrated by pulling requests from a queue. Training is performed by Megatron-LM workers that are orchestrated by SLURM. Trained models are automatically registered with the inference workers.","title":"ScalarLM"},{"location":"docs/contact/","text":"Contact Us Project ScalarLM is developed by an Artificial Intelligence engineering consortium, built on a philosophy of open collaboration to improve AI systems. Through our collective engineering efforts with industry and academia we continually integrate and improve the accuracy, safety, speed, and efficiency of AI technologies\u2013helping companies and universities around the world build better AI systems that will benefit society. Get in Touch Greg Diamos Naila Farooqui Sudnya Diamos Suhabe Bugrara We accept community contributions and are always looking for new collaborators. If you are interested in contributing to Project ScalarLM, please reach out to us at Get in Touch .","title":"Contact Us"},{"location":"docs/contact/#contact-us","text":"Project ScalarLM is developed by an Artificial Intelligence engineering consortium, built on a philosophy of open collaboration to improve AI systems. Through our collective engineering efforts with industry and academia we continually integrate and improve the accuracy, safety, speed, and efficiency of AI technologies\u2013helping companies and universities around the world build better AI systems that will benefit society. Get in Touch Greg Diamos Naila Farooqui Sudnya Diamos Suhabe Bugrara We accept community contributions and are always looking for new collaborators. If you are interested in contributing to Project ScalarLM, please reach out to us at Get in Touch .","title":"Contact Us"},{"location":"docs/inference/","text":"Inference OpenAI Compatible Server curl https://meta-llama--llama-3-2-3b-instruct.cray-lm.com/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-3B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }' Using the Python client You can also use the Python client to interact with the ScalarLM server. import masint masint.api_url = \"https://meta-llama--llama-3-2-3b-instruct.cray-lm.com\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Inference"},{"location":"docs/inference/#inference","text":"","title":"Inference"},{"location":"docs/inference/#openai-compatible-server","text":"curl https://meta-llama--llama-3-2-3b-instruct.cray-lm.com/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-3B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"OpenAI Compatible Server"},{"location":"docs/inference/#using-the-python-client","text":"You can also use the Python client to interact with the ScalarLM server. import masint masint.api_url = \"https://meta-llama--llama-3-2-3b-instruct.cray-lm.com\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Using the Python client"},{"location":"docs/quickstart/","text":"Let's start by submitting your first request to ScalarLM. Setup Clone the ScalarLM repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up This will bring up the ScalarLM development server on localhost:8000 , which includes an OpenAI compatible API. Your first request curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"masint/tiny-random-llama\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }' Using the Python client You can also use the Python client to interact with the local ScalarLM server. import masint # Make sure to set the API URL to the local ScalarLM server masint.api_url = \"http://localhost:8000\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results) Loading a different model Edit the file cray-lm/infra/cray_infra/util/default_config.py and change the model field to the desired model. model = \"meta-llama/Llama-3.2-1B-Instruct\" Then restart the server. ./cray up Submitting a request to the new model curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-1B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Quickstart"},{"location":"docs/quickstart/#setup","text":"Clone the ScalarLM repository and start the server. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray up This will bring up the ScalarLM development server on localhost:8000 , which includes an OpenAI compatible API.","title":"Setup"},{"location":"docs/quickstart/#your-first-request","text":"curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"masint/tiny-random-llama\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Your first request"},{"location":"docs/quickstart/#using-the-python-client","text":"You can also use the Python client to interact with the local ScalarLM server. import masint # Make sure to set the API URL to the local ScalarLM server masint.api_url = \"http://localhost:8000\" def get_dataset(): dataset = [] count = 4 for i in range(count): dataset.append(f\"What is {i} + {i}?\") return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() results = llm.generate(prompts=dataset) print(results)","title":"Using the Python client"},{"location":"docs/quickstart/#loading-a-different-model","text":"Edit the file cray-lm/infra/cray_infra/util/default_config.py and change the model field to the desired model. model = \"meta-llama/Llama-3.2-1B-Instruct\" Then restart the server. ./cray up","title":"Loading a different model"},{"location":"docs/quickstart/#submitting-a-request-to-the-new-model","text":"curl http://localhost:8000/v1/openai/chat/completions \\ -H \"Content-Type: application/json\" \\ -d '{ \"model\": \"meta-llama/Llama-3.2-1B-Instruct\", \"messages\": [ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"} ] }'","title":"Submitting a request to the new model"},{"location":"docs/training/","text":"Training Training jobs You can also use the Python client to submit training jobs to the ScalarLM server. import masint def get_dataset(): dataset = [] count = 5 for i in range(count): dataset.append( {\"input\": f\"What is {i} + {i}?\", \"output\": str(i + i)} ) return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() status = llm.train(dataset, train_args={\"max_steps\": 200, \"learning_rate\": 3e-3}) print(status) You get a command line output like this: (environment) gregorydiamos@Air-Gregory cray % python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': 'dataset', 'job_directory': '/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e', 'model_name': '69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e'}","title":"Training"},{"location":"docs/training/#training","text":"","title":"Training"},{"location":"docs/training/#training-jobs","text":"You can also use the Python client to submit training jobs to the ScalarLM server. import masint def get_dataset(): dataset = [] count = 5 for i in range(count): dataset.append( {\"input\": f\"What is {i} + {i}?\", \"output\": str(i + i)} ) return dataset llm = masint.SupermassiveIntelligence() dataset = get_dataset() status = llm.train(dataset, train_args={\"max_steps\": 200, \"learning_rate\": 3e-3}) print(status) You get a command line output like this: (environment) gregorydiamos@Air-Gregory cray % python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': 'dataset', 'job_directory': '/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e', 'model_name': '69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e'}","title":"Training jobs"},{"location":"docs/cli/cli/","text":"Command Line Interface The ScalarLM CLI is used to inspect and monitor training jobs, as well as to manage the Cray-LM platform. cray - ScalarLM CLI Usage: cray COMMAND cray [COMMAND] --help | -h cray --version | -v Commands: build-image Build image from dockerfile depot-build Build image from dockerfile and push to depot up Start the container test Run tests in the container deploy Deploy the cray platform to modal serve Serve the cray platform using modal llm Invoke the LLM tool diffusion Evaluate a diffusion model Options: --help, -h Show this help --version, -v Show version number Installation Clone the ScalarLM repository and run the cray command to try out the CLI. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray Python package The ScalarLM CLI is also available as a Python package. You can install it using pip: pip install cray-lm After installing the package, you can use the cray-lm command in your terminal. (environment) gregorydiamos@MacBook-Air-Gregory cray % cray-lm usage: cray-lm [-h] {logs,plot,ls,squeue} ... The command line interface for MasInt positional arguments: {logs,plot,ls,squeue} logs View logs plot Plot the results of a model ls List models squeue View the squeue options: -h, --help show this help message and exit The python package includes is a client for the ScalarLM platform, and can be used to interact with the ScalarLM server.","title":"Command Line Interface"},{"location":"docs/cli/cli/#command-line-interface","text":"The ScalarLM CLI is used to inspect and monitor training jobs, as well as to manage the Cray-LM platform. cray - ScalarLM CLI Usage: cray COMMAND cray [COMMAND] --help | -h cray --version | -v Commands: build-image Build image from dockerfile depot-build Build image from dockerfile and push to depot up Start the container test Run tests in the container deploy Deploy the cray platform to modal serve Serve the cray platform using modal llm Invoke the LLM tool diffusion Evaluate a diffusion model Options: --help, -h Show this help --version, -v Show version number","title":"Command Line Interface"},{"location":"docs/cli/cli/#installation","text":"Clone the ScalarLM repository and run the cray command to try out the CLI. git clone git@github.com:cray-lm/cray-lm.git cd cray-lm ./cray","title":"Installation"},{"location":"docs/cli/cli/#python-package","text":"The ScalarLM CLI is also available as a Python package. You can install it using pip: pip install cray-lm After installing the package, you can use the cray-lm command in your terminal. (environment) gregorydiamos@MacBook-Air-Gregory cray % cray-lm usage: cray-lm [-h] {logs,plot,ls,squeue} ... The command line interface for MasInt positional arguments: {logs,plot,ls,squeue} logs View logs plot Plot the results of a model ls List models squeue View the squeue options: -h, --help show this help message and exit The python package includes is a client for the ScalarLM platform, and can be used to interact with the ScalarLM server.","title":"Python package"},{"location":"docs/cli/list-models/","text":"List Models ./cray llm ls This command lists all of the models that have been trained on the ScalarLM server. 69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e ScalarLM names models with a unique identifier based on the input data and training parameters.","title":"List Models"},{"location":"docs/cli/list-models/#list-models","text":"./cray llm ls This command lists all of the models that have been trained on the ScalarLM server. 69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e ScalarLM names models with a unique identifier based on the input data and training parameters.","title":"List Models"},{"location":"docs/cli/plot/","text":"Plot ./cray llm plot This command plots the training loss of a specified model. If no model is specified, the command will plot the training loss of the most recently trained model.","title":"Plot"},{"location":"docs/cli/plot/#plot","text":"./cray llm plot This command plots the training loss of a specified model. If no model is specified, the command will plot the training loss of the most recently trained model.","title":"Plot"},{"location":"docs/cli/squeue/","text":"squeue ./cray llm squeue This command is a wrapper around the squeue command. It is used to display the status of jobs in the training queue. The output is similar to the squeue command, but with some additional formatting. JOBID PARTITION NAME USER STATE TIME TIME_LIMI NODES NODELIST(REASON) 8 short 00f186ab039b root PENDING 0:00 20:00 1 (Priority) 7 short f1ba9c0eb11b root PENDING 0:00 20:00 1 (Priority) 6 short 0746261fd1db root PENDING 0:00 20:00 1 (Priority) 5 short ae55dedbb496 root PENDING 0:00 20:00 1 (Priority) 4 short d2bc30a36081 root PENDING 0:00 20:00 1 (Priority) 3 short bce8e63a7bef root PENDING 0:00 20:00 1 (Resources) 2 short c42b59ab0fb1 root RUNNING 0:34 20:00 1 df294b9206ff","title":"squeue"},{"location":"docs/cli/squeue/#squeue","text":"./cray llm squeue This command is a wrapper around the squeue command. It is used to display the status of jobs in the training queue. The output is similar to the squeue command, but with some additional formatting. JOBID PARTITION NAME USER STATE TIME TIME_LIMI NODES NODELIST(REASON) 8 short 00f186ab039b root PENDING 0:00 20:00 1 (Priority) 7 short f1ba9c0eb11b root PENDING 0:00 20:00 1 (Priority) 6 short 0746261fd1db root PENDING 0:00 20:00 1 (Priority) 5 short ae55dedbb496 root PENDING 0:00 20:00 1 (Priority) 4 short d2bc30a36081 root PENDING 0:00 20:00 1 (Priority) 3 short bce8e63a7bef root PENDING 0:00 20:00 1 (Resources) 2 short c42b59ab0fb1 root RUNNING 0:34 20:00 1 df294b9206ff","title":"squeue"},{"location":"docs/cli/training-logs/","text":"Training Logs ./cray llm logs -f This command streams the training logs for the model with the specified identifier. The logs include information about the training process, such as the loss and accuracy of the model at each epoch. If no identifiers are provided, the command will list the most recent model. 0 + export CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 1 + CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 2 +++ dirname /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 3 ++ cd /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 4 ++ pwd 5 + LOCAL_DIRECTORY=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 6 + export PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 7 + PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 8 + mpirun --allow-run-as-root python /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml/cray_megatron/main.py 9 INFO:cray_infra.training.print_logo: 10 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u28a0\u2880\u2850\u2884\u28a2\u2850\u28a2\u2881\u2802\u2804\u2820\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 11 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2844\u28cc\u2830\u28d8\u28c6\u28a7\u285c\u28ee\u28f1\u28ce\u2837\u28cc\u285e\u28cc\u2852\u2824\u28c8\u2820\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 12 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2812\u280a\u2800\u2800\u2800\u2800\u2880\u2822\u2831\u285c\u28de\u28f3\u281d\u28d8\u28ed\u28fc\u28fe\u28f7\u28f6\u28f6\u28ee\u28ec\u28e5\u28d9\u2832\u28a1\u2882\u2821\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 13 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2803\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2822\u28d1\u28a3\u281d\u28ea\u28f5\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f6\u28ef\u28fb\u28a6\u28cd\u2822\u2885\u2882\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 14 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2886\u2871\u280c\u28e1\u289e\u28f5\u28ff\u28ff\u28ff\u283f\u281b\u281b\u2809\u2809\u281b\u281b\u283f\u28b7\u28fd\u28fb\u28e6\u28ce\u28b3\u28cc\u2806\u2871\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 15 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2802\u2820\u280c\u28a2\u2883\u287e\u28f1\u28ff\u28bf\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28bb\u28cf\u283b\u28f7\u28ec\u2873\u28e4\u2842\u281c\u28a0\u2840\u28c0\u2800\u2800\u2840\u2800\u2800\u2800\u2800\u2800\u2800 16 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2880\u2802\u28cc\u2883\u287e\u28a1\u28ff\u28a3\u284f\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b9\u2847\u284a\u28ff\u28ff\u28fe\u28fd\u28db\u2836\u28f6\u28ec\u28ed\u28e5\u28d9\u28da\u28b7\u28f6\u2826\u2864\u2880 17 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2881\u2802\u2830\u284c\u287c\u2821\u28fc\u2883\u287f\u2800\u2800\u2800\u2800MasInt\u2800\u2800\u2800\u2800\u2800\u2800\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28fe\u287f\u283f\u28db\u28ef\u2874\u288f\u2833\u2801\u2800 18 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2811\u284c\u2800\u28c9\u28fe\u28e9\u28fc\u28ff\u28fe\u2847\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u28c0\u28e0\u28e4\u28e4\u28ff\u28ff\u28ff\u28ff\u287f\u289b\u28db\u28ef\u28ed\u2836\u28de\u283b\u28c9\u2812\u2800\u2802\u2800\u2800\u2800 19 \u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u2876\u289d\u28e2\u28fe\u28ff\u28fc\u28ff\u28ff\u28ff\u28ff\u28ff\u28c0\u28fc\u28c0\u28c0\u28c0\u28e4\u28f4\u28f6\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u283f\u28ff\u283f\u285b\u280f\u280d\u2802\u2801\u28a0\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800 20 \u2800\u2820\u2880\u28a5\u28f0\u28fe\u28ff\u28ef\u28f6\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u281f\u28fd\u281f\u28ff\u2810\u2828\u2811\u2840\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 21 \u2850\u28a2\u28df\u28fe\u28ff\u28ff\u28df\u28db\u28ff\u28ff\u28ff\u28ff\u28bf\u28dd\u283b\u283f\u28bf\u28ef\u28db\u28bf\u28ff\u28ff\u28ff\u285b\u283b\u283f\u28db\u283b\u281b\u285b\u2829\u2881\u28f4\u287e\u2883\u28fe\u2807\u2880\u2821\u2802\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 22 \u2808\u2801\u280a\u2819\u2809\u2829\u280c\u2809\u2822\u2809\u2810\u2808\u2802\u2808\u2801\u2809\u2802\u2810\u2809\u28fb\u28f7\u28ed\u281b\u283f\u28f6\u28e6\u28e4\u28e4\u28f4\u28f4\u287e\u281f\u28eb\u28fe\u28ff\u284f\u2800\u2802\u2810\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 23 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2819\u28bb\u28bf\u28b6\u28e4\u28ec\u28c9\u28c9\u28ed\u28e4\u28f4\u28ff\u28ff\u287f\u2803\u2804\u2848\u2801\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 24 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2801\u2818\u288a\u2833\u282d\u287d\u28ff\u283f\u283f\u281f\u281b\u2809\u2800\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 25 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2800\u2801\u2808\u2810\u2800\u2818\u2800\u2808\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 26 27 DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443 28 DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /NousResearch/Llama-3.2-1B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0 29 `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`. 30 INFO:cray_megatron.megatron.training_loop:Training step 0 - epoch 0 - loss 11.851648330688477- learning rate 0.003 31 INFO:cray_megatron.megatron.training_loop:Training step 1 - epoch 0 - loss 11.491947174072266- learning rate 0.0029850000000000002 32 INFO:cray_megatron.megatron.training_loop:Training step 2 - epoch 1 - loss 11.067758560180664- learning rate 0.00297 33 INFO:cray_megatron.megatron.training_loop:Training step 3 - epoch 2 - loss 10.38668155670166- learning rate 0.0029549999999999997 34 INFO:cray_megatron.megatron.training_loop:Training step 4 - epoch 3 - loss 10.309948921203613- learning rate 0.0029399999999999995 35 INFO:cray_megatron.megatron.training_loop:Training step 5 - epoch 4 - loss 10.753833770751953- learning rate 0.0029249999999999996 36 INFO:cray_megatron.megatron.training_loop:Training step 6 - epoch 5 - loss 11.955288887023926- learning rate 0.00291 37 INFO:cray_megatron.megatron.training_loop:Training step 7 - epoch 6 - loss 10.206552505493164- learning rate 0.002895 38 INFO:cray_megatron.megatron.training_loop:Training step 8 - epoch 7 - loss 11.689804077148438- learning rate 0.0028799999999999997 39 INFO:cray_megatron.megatron.training_loop:Training step 9 - epoch 8 - loss 11.29571533203125- learning rate 0.0028649999999999995 40 INFO:cray_megatron.megatron.training_loop:Training step 10 - epoch 9 - loss 9.205053329467773- learning rate 0.0028499999999999997 41 INFO:cray_megatron.megatron.training_loop:Training step 11 - epoch 10 - loss 11.743261337280273- learning rate 0.0028349999999999994 42 INFO:cray_megatron.megatron.training_loop:Training step 12 - epoch 11 - loss 8.788749694824219- learning rate 0.002819999999999999 43 INFO:cray_megatron.megatron.training_loop:Training step 13 - epoch 12 - loss 9.033876419067383- learning rate 0.002804999999999999 44 INFO:cray_megatron.megatron.training_loop:Training step 14 - epoch 13 - loss 11.744029998779297- learning rate 0.0027899999999999986 45 INFO:cray_megatron.megatron.training_loop:Training step 15 - epoch 14 - loss 8.629796981811523- learning rate 0.002774999999999999 46 INFO:cray_megatron.megatron.training_loop:Training step 16 - epoch 15 - loss 8.350188255310059- learning rate 0.002759999999999999 47 INFO:cray_megatron.megatron.training_loop:Training step 17 - epoch 16 - loss 8.093982696533203- learning rate 0.0027449999999999987 48 INFO:cray_megatron.megatron.training_loop:Training step 18 - epoch 17 - loss 7.8525495529174805- learning rate 0.002729999999999999 49 INFO:cray_megatron.megatron.training_loop:Training step 19 - epoch 18 - loss 11.577287673950195- learning rate 0.002714999999999999 50 INFO:cray_megatron.megatron.training_loop:Training step 20 - epoch 19 - loss 7.367895126342773- learning rate 0.0026999999999999993 51 INFO:cray_megatron.megatron.training_loop:Training step 21 - epoch 20 - loss 11.79365348815918- learning rate 0.0026849999999999995 52 INFO:cray_megatron.megatron.training_loop:Training step 22 - epoch 21 - loss 6.936058044433594- learning rate 0.002669999999999999 53 INFO:cray_megatron.megatron.training_loop:Training step 23 - epoch 22 - loss 10.056737899780273- learning rate 0.0026549999999999994 54 INFO:cray_megatron.megatron.training_loop:Training step 24 - epoch 23 - loss 9.305437088012695- learning rate 0.0026399999999999996 55 INFO:cray_megatron.megatron.training_loop:Training step 25 - epoch 24 - loss 6.2938947677612305- learning rate 0.0026249999999999993 56 INFO:cray_megatron.megatron.training_loop:Training step 26 - epoch 25 - loss 6.068697929382324- learning rate 0.0026099999999999995 57 INFO:cray_megatron.megatron.training_loop:Training step 27 - epoch 26 - loss 5.812913417816162- learning rate 0.0025949999999999992 58 INFO:cray_megatron.megatron.training_loop:Training step 28 - epoch 27 - loss 10.825139999389648- learning rate 0.002579999999999999 59 INFO:cray_megatron.megatron.training_loop:Training step 29 - epoch 28 - loss 9.760759353637695- learning rate 0.002564999999999999 60 INFO:cray_megatron.megatron.training_loop:Training step 30 - epoch 29 - loss 10.444537162780762- learning rate 0.0025499999999999993 61 INFO:cray_megatron.megatron.training_loop:Training step 31 - epoch 30 - loss 9.888254165649414- learning rate 0.0025349999999999995 62 INFO:cray_megatron.megatron.training_loop:Training step 32 - epoch 31 - loss 4.675031661987305- learning rate 0.0025199999999999992 63 INFO:cray_megatron.megatron.training_loop:Training step 33 - epoch 32 - loss 4.461902618408203- learning rate 0.0025049999999999994 64 INFO:cray_megatron.megatron.training_loop:Training step 34 - epoch 33 - loss 4.232550621032715- learning rate 0.002489999999999999 65 INFO:cray_megatron.megatron.training_loop:Training step 35 - epoch 34 - loss 9.657859802246094- learning rate 0.0024749999999999993 66 INFO:cray_megatron.megatron.training_loop:Training step 36 - epoch 35 - loss 5.435771942138672- learning rate 0.002459999999999999 67 INFO:cray_megatron.megatron.training_loop:Training step 37 - epoch 36 - loss 4.934456825256348- learning rate 0.0024449999999999993 68 INFO:cray_megatron.megatron.training_loop:Training step 38 - epoch 37 - loss 3.3201217651367188- learning rate 0.0024299999999999994 69 INFO:cray_megatron.megatron.training_loop:Training step 39 - epoch 38 - loss 3.090512990951538- learning rate 0.002414999999999999 70 INFO:cray_megatron.megatron.training_loop:Training step 40 - epoch 39 - loss 2.8569488525390625- learning rate 0.0023999999999999994 71 INFO:cray_megatron.megatron.training_loop:Training step 41 - epoch 40 - loss 2.6222681999206543- learning rate 0.0023849999999999995 72 INFO:cray_megatron.megatron.training_loop:Training step 42 - epoch 41 - loss 2.3898932933807373- learning rate 0.0023699999999999997 73 INFO:cray_megatron.megatron.training_loop:Training step 43 - epoch 42 - loss 2.449845314025879- learning rate 0.0023549999999999995 74 INFO:cray_megatron.megatron.training_loop:Training step 44 - epoch 43 - loss 1.9457842111587524- learning rate 0.0023399999999999996 75 INFO:cray_megatron.megatron.training_loop:Training step 45 - epoch 44 - loss 3.3052239418029785- learning rate 0.002325 76 INFO:cray_megatron.megatron.training_loop:Training step 46 - epoch 45 - loss 1.5511304140090942- learning rate 0.00231 77 INFO:cray_megatron.megatron.training_loop:Training step 47 - epoch 46 - loss 1.381464958190918- learning rate 0.002295 78 INFO:cray_megatron.megatron.training_loop:Training step 48 - epoch 47 - loss 1.8805816173553467- learning rate 0.0022800000000000003 79 INFO:cray_megatron.megatron.training_loop:Training step 49 - epoch 48 - loss 1.6158814430236816- learning rate 0.0022650000000000005 80 INFO:cray_megatron.megatron.training_loop:Training step 50 - epoch 49 - loss 0.9921494722366333- learning rate 0.0022500000000000003 81 INFO:cray_megatron.megatron.training_loop:Training step 51 - epoch 50 - loss 0.9002286791801453- learning rate 0.002235 82 INFO:cray_megatron.megatron.training_loop:Training step 52 - epoch 51 - loss 1.0186548233032227- learning rate 0.00222 83 INFO:cray_megatron.megatron.training_loop:Training step 53 - epoch 52 - loss 0.7658149003982544- learning rate 0.002205 84 INFO:cray_megatron.megatron.training_loop:Training step 54 - epoch 53 - loss 0.7076711654663086- learning rate 0.00219 85 INFO:cray_megatron.megatron.training_loop:Training step 55 - epoch 54 - loss 0.9462921619415283- learning rate 0.002175 86 INFO:cray_megatron.megatron.training_loop:Training step 56 - epoch 55 - loss 0.6228013038635254- learning rate 0.00216 87 INFO:cray_megatron.megatron.training_loop:Training step 57 - epoch 56 - loss 0.5883803367614746- learning rate 0.002145 88 INFO:cray_megatron.megatron.training_loop:Training step 58 - epoch 57 - loss 0.7707682251930237- learning rate 0.0021300000000000004 89 INFO:cray_megatron.megatron.training_loop:Training step 59 - epoch 58 - loss 0.758730411529541- learning rate 0.0021150000000000006 90 INFO:cray_megatron.megatron.training_loop:Training step 60 - epoch 59 - loss 0.506292462348938- learning rate 0.0021000000000000007 91 INFO:cray_megatron.megatron.training_loop:Training step 61 - epoch 60 - loss 0.4830833673477173- learning rate 0.002085000000000001 92 INFO:cray_megatron.megatron.training_loop:Training step 62 - epoch 61 - loss 0.7608119249343872- learning rate 0.002070000000000001 93 INFO:cray_megatron.megatron.training_loop:Training step 63 - epoch 62 - loss 0.43636059761047363- learning rate 0.002055000000000001 94 INFO:cray_megatron.megatron.training_loop:Training step 64 - epoch 63 - loss 0.748888373374939- learning rate 0.002040000000000001 95 INFO:cray_megatron.megatron.training_loop:Training step 65 - epoch 64 - loss 0.3981848359107971- learning rate 0.002025000000000001 96 INFO:cray_megatron.megatron.training_loop:Training step 66 - epoch 65 - loss 0.38111788034439087- learning rate 0.0020100000000000014 97 INFO:cray_megatron.megatron.training_loop:Training step 67 - epoch 66 - loss 0.6918612718582153- learning rate 0.001995000000000001 98 INFO:cray_megatron.megatron.training_loop:Training step 68 - epoch 67 - loss 0.3478345274925232- learning rate 0.001980000000000001 99 INFO:cray_megatron.megatron.training_loop:Training step 69 - epoch 68 - loss 0.7505407333374023- learning rate 0.001965000000000001 100 INFO:cray_megatron.megatron.training_loop:Training step 70 - epoch 69 - loss 0.7745790481567383- learning rate 0.001950000000000001 101 INFO:cray_megatron.megatron.training_loop:Training step 71 - epoch 70 - loss 0.7360649704933167- learning rate 0.001935000000000001 102 INFO:cray_megatron.megatron.training_loop:Training step 72 - epoch 71 - loss 0.6509546637535095- learning rate 0.001920000000000001 103 INFO:cray_megatron.megatron.training_loop:Training step 73 - epoch 72 - loss 0.3059840202331543- learning rate 0.0019050000000000009 104 INFO:cray_megatron.megatron.training_loop:Training step 74 - epoch 73 - loss 0.29385578632354736- learning rate 0.0018900000000000008 105 INFO:cray_megatron.megatron.training_loop:Training step 75 - epoch 74 - loss 0.2902987003326416- learning rate 0.0018750000000000008 106 INFO:cray_megatron.megatron.training_loop:Training step 76 - epoch 75 - loss 0.7161434888839722- learning rate 0.0018600000000000008 107 INFO:cray_megatron.megatron.training_loop:Training step 77 - epoch 76 - loss 0.2615271806716919- learning rate 0.0018450000000000007 108 INFO:cray_megatron.megatron.training_loop:Training step 78 - epoch 77 - loss 0.8070529699325562- learning rate 0.0018300000000000007 109 INFO:cray_megatron.megatron.training_loop:Training step 79 - epoch 78 - loss 0.7276452779769897- learning rate 0.0018150000000000006 110 INFO:cray_megatron.megatron.training_loop:Training step 80 - epoch 79 - loss 0.8069541454315186- learning rate 0.0018000000000000006 111 INFO:cray_megatron.megatron.training_loop:Training step 81 - epoch 80 - loss 0.6734392642974854- learning rate 0.0017850000000000006 112 INFO:cray_megatron.megatron.training_loop:Training step 82 - epoch 81 - loss 0.6499148607254028- learning rate 0.0017700000000000005 113 INFO:cray_megatron.megatron.training_loop:Training step 83 - epoch 82 - loss 0.7235682010650635- learning rate 0.0017550000000000005 114 INFO:cray_megatron.megatron.training_loop:Training step 84 - epoch 83 - loss 0.788324236869812- learning rate 0.0017400000000000004 115 INFO:cray_megatron.megatron.training_loop:Training step 85 - epoch 84 - loss 0.7486412525177002- learning rate 0.0017250000000000004 116 INFO:cray_megatron.megatron.training_loop:Training step 86 - epoch 85 - loss 0.6475511193275452- learning rate 0.0017100000000000006 117 INFO:cray_megatron.megatron.training_loop:Training step 87 - epoch 86 - loss 0.23438769578933716- learning rate 0.0016950000000000005 118 INFO:cray_megatron.megatron.training_loop:Training step 88 - epoch 87 - loss 0.69432532787323- learning rate 0.0016800000000000005 119 INFO:cray_megatron.megatron.training_loop:Training step 89 - epoch 88 - loss 0.701191782951355- learning rate 0.0016650000000000005 120 INFO:cray_megatron.megatron.training_loop:Training step 90 - epoch 89 - loss 0.8208021521568298- learning rate 0.0016500000000000004 121 INFO:cray_megatron.megatron.training_loop:Training step 91 - epoch 90 - loss 0.7423532009124756- learning rate 0.0016350000000000006 122 INFO:cray_megatron.megatron.training_loop:Training step 92 - epoch 91 - loss 0.22764872014522552- learning rate 0.0016200000000000008 123 INFO:cray_megatron.megatron.training_loop:Training step 93 - epoch 92 - loss 0.6770063042640686- learning rate 0.0016050000000000007 124 INFO:cray_megatron.megatron.training_loop:Training step 94 - epoch 93 - loss 0.2195751667022705- learning rate 0.0015900000000000007 125 INFO:cray_megatron.megatron.training_loop:Training step 95 - epoch 94 - loss 0.21528244018554688- learning rate 0.0015750000000000007 126 INFO:cray_megatron.megatron.training_loop:Training step 96 - epoch 95 - loss 0.2105533480644226- learning rate 0.0015600000000000006 127 INFO:cray_megatron.megatron.training_loop:Training step 97 - epoch 96 - loss 0.20401671528816223- learning rate 0.0015450000000000006 128 INFO:cray_megatron.megatron.training_loop:Training step 98 - epoch 97 - loss 0.19684851169586182- learning rate 0.0015300000000000005 129 INFO:cray_megatron.megatron.training_loop:Training step 99 - epoch 98 - loss 0.18342770636081696- learning rate 0.0015150000000000005 130 INFO:cray_megatron.megatron.training_loop:Training step 100 - epoch 99 - loss 0.17346294224262238- learning rate 0.0015000000000000005 131 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_100.pt 132 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model 133 INFO:cray_megatron.megatron.training_loop:Checkpoint on step 100 took 0.748274564743042 seconds 134 INFO:cray_megatron.megatron.training_loop:Training step 101 - epoch 100 - loss 0.16589578986167908- learning rate 0.0014850000000000004 135 INFO:cray_megatron.megatron.training_loop:Training step 102 - epoch 101 - loss 0.7842352986335754- learning rate 0.0014700000000000004 136 INFO:cray_megatron.megatron.training_loop:Training step 103 - epoch 102 - loss 0.8229332566261292- learning rate 0.0014550000000000003 137 INFO:cray_megatron.megatron.training_loop:Training step 104 - epoch 103 - loss 0.749505877494812- learning rate 0.0014400000000000003 138 INFO:cray_megatron.megatron.training_loop:Training step 105 - epoch 104 - loss 0.1399921178817749- learning rate 0.0014250000000000003 139 INFO:cray_megatron.megatron.training_loop:Training step 106 - epoch 105 - loss 0.13615575432777405- learning rate 0.0014100000000000002 140 INFO:cray_megatron.megatron.training_loop:Training step 107 - epoch 106 - loss 0.1328878551721573- learning rate 0.0013950000000000002 141 INFO:cray_megatron.megatron.training_loop:Training step 108 - epoch 107 - loss 0.1299896240234375- learning rate 0.0013800000000000002 142 INFO:cray_megatron.megatron.training_loop:Training step 109 - epoch 108 - loss 0.12737448513507843- learning rate 0.0013650000000000001 143 INFO:cray_megatron.megatron.training_loop:Training step 110 - epoch 109 - loss 0.8569282293319702- learning rate 0.00135 144 INFO:cray_megatron.megatron.training_loop:Training step 111 - epoch 110 - loss 0.8064426183700562- learning rate 0.001335 145 INFO:cray_megatron.megatron.training_loop:Training step 112 - epoch 111 - loss 0.12294523417949677- learning rate 0.00132 146 INFO:cray_megatron.megatron.training_loop:Training step 113 - epoch 112 - loss 0.7471427917480469- learning rate 0.001305 147 INFO:cray_megatron.megatron.training_loop:Training step 114 - epoch 113 - loss 0.12056495994329453- learning rate 0.00129 148 INFO:cray_megatron.megatron.training_loop:Training step 115 - epoch 114 - loss 0.11913363635540009- learning rate 0.0012749999999999999 149 INFO:cray_megatron.megatron.training_loop:Training step 116 - epoch 115 - loss 0.11778314411640167- learning rate 0.0012599999999999998 150 INFO:cray_megatron.megatron.training_loop:Training step 117 - epoch 116 - loss 0.11592821776866913- learning rate 0.0012449999999999998 151 INFO:cray_megatron.megatron.training_loop:Training step 118 - epoch 117 - loss 0.747460126876831- learning rate 0.0012299999999999998 152 INFO:cray_megatron.megatron.training_loop:Training step 119 - epoch 118 - loss 0.11181403696537018- learning rate 0.0012149999999999997 153 INFO:cray_megatron.megatron.training_loop:Training step 120 - epoch 119 - loss 0.11106443405151367- learning rate 0.0011999999999999997 154 INFO:cray_megatron.megatron.training_loop:Training step 121 - epoch 120 - loss 0.7953877449035645- learning rate 0.0011849999999999996 155 INFO:cray_megatron.megatron.training_loop:Training step 122 - epoch 121 - loss 0.7007923126220703- learning rate 0.0011699999999999996 156 INFO:cray_megatron.megatron.training_loop:Training step 123 - epoch 122 - loss 0.5777735710144043- learning rate 0.0011549999999999996 157 INFO:cray_megatron.megatron.training_loop:Training step 124 - epoch 123 - loss 0.10659528523683548- learning rate 0.0011399999999999995 158 INFO:cray_megatron.megatron.training_loop:Training step 125 - epoch 124 - loss 0.6686602830886841- learning rate 0.0011249999999999995 159 INFO:cray_megatron.megatron.training_loop:Training step 126 - epoch 125 - loss 0.7213398218154907- learning rate 0.0011099999999999994 160 INFO:cray_megatron.megatron.training_loop:Training step 127 - epoch 126 - loss 0.10370150953531265- learning rate 0.0010949999999999994 161 INFO:cray_megatron.megatron.training_loop:Training step 128 - epoch 127 - loss 0.715872585773468- learning rate 0.0010799999999999994 162 INFO:cray_megatron.megatron.training_loop:Training step 129 - epoch 128 - loss 0.6672084331512451- learning rate 0.0010649999999999993 163 INFO:cray_megatron.megatron.training_loop:Training step 130 - epoch 129 - loss 0.6094690561294556- learning rate 0.0010499999999999993 164 INFO:cray_megatron.megatron.training_loop:Training step 131 - epoch 130 - loss 0.09981067478656769- learning rate 0.0010349999999999992 165 INFO:cray_megatron.megatron.training_loop:Training step 132 - epoch 131 - loss 0.09831465780735016- learning rate 0.0010199999999999992 166 INFO:cray_megatron.megatron.training_loop:Training step 133 - epoch 132 - loss 0.8732300996780396- learning rate 0.0010049999999999992 167 INFO:cray_megatron.megatron.training_loop:Training step 134 - epoch 133 - loss 0.09659353643655777- learning rate 0.0009899999999999991 168 INFO:cray_megatron.megatron.training_loop:Training step 135 - epoch 134 - loss 0.0957847312092781- learning rate 0.0009749999999999992 169 INFO:cray_megatron.megatron.training_loop:Training step 136 - epoch 135 - loss 0.09486415982246399- learning rate 0.0009599999999999993 170 INFO:cray_megatron.megatron.training_loop:Training step 137 - epoch 136 - loss 0.687118411064148- learning rate 0.0009449999999999992 171 INFO:cray_megatron.megatron.training_loop:Training step 138 - epoch 137 - loss 0.7465814352035522- learning rate 0.0009299999999999993 172 INFO:cray_megatron.megatron.training_loop:Training step 139 - epoch 138 - loss 0.09353536367416382- learning rate 0.0009149999999999994 173 INFO:cray_megatron.megatron.training_loop:Training step 140 - epoch 139 - loss 0.6857355833053589- learning rate 0.0008999999999999993 174 INFO:cray_megatron.megatron.training_loop:Training step 141 - epoch 140 - loss 0.8234232068061829- learning rate 0.0008849999999999993 175 INFO:cray_megatron.megatron.training_loop:Training step 142 - epoch 141 - loss 0.09200795739889145- learning rate 0.0008699999999999994 176 INFO:cray_megatron.megatron.training_loop:Training step 143 - epoch 142 - loss 0.6732250452041626- learning rate 0.0008549999999999993 177 INFO:cray_megatron.megatron.training_loop:Training step 144 - epoch 143 - loss 0.08996626734733582- learning rate 0.0008399999999999993 178 INFO:cray_megatron.megatron.training_loop:Training step 145 - epoch 144 - loss 0.5915161371231079- learning rate 0.0008249999999999992 179 INFO:cray_megatron.megatron.training_loop:Training step 146 - epoch 145 - loss 0.08881303668022156- learning rate 0.0008099999999999992 180 INFO:cray_megatron.megatron.training_loop:Training step 147 - epoch 146 - loss 0.7250931262969971- learning rate 0.0007949999999999993 181 INFO:cray_megatron.megatron.training_loop:Training step 148 - epoch 147 - loss 0.6727677583694458- learning rate 0.0007799999999999993 182 INFO:cray_megatron.megatron.training_loop:Training step 149 - epoch 148 - loss 0.2871503531932831- learning rate 0.0007649999999999993 183 INFO:cray_megatron.megatron.training_loop:Training step 150 - epoch 149 - loss 0.08630774915218353- learning rate 0.0007499999999999993 184 INFO:cray_megatron.megatron.training_loop:Training step 151 - epoch 150 - loss 0.6593747138977051- learning rate 0.0007349999999999992 185 INFO:cray_megatron.megatron.training_loop:Training step 152 - epoch 151 - loss 0.6607116460800171- learning rate 0.0007199999999999992 186 INFO:cray_megatron.megatron.training_loop:Training step 153 - epoch 152 - loss 0.08505091071128845- learning rate 0.0007049999999999991 187 INFO:cray_megatron.megatron.training_loop:Training step 154 - epoch 153 - loss 0.7495298385620117- learning rate 0.0006899999999999991 188 INFO:cray_megatron.megatron.training_loop:Training step 155 - epoch 154 - loss 0.0840618759393692- learning rate 0.0006749999999999992 189 INFO:cray_megatron.megatron.training_loop:Training step 156 - epoch 155 - loss 0.6931415796279907- learning rate 0.0006599999999999991 190 INFO:cray_megatron.megatron.training_loop:Training step 157 - epoch 156 - loss 0.6979023218154907- learning rate 0.0006449999999999992 191 INFO:cray_megatron.megatron.training_loop:Training step 158 - epoch 157 - loss 0.08278802037239075- learning rate 0.0006299999999999992 192 INFO:cray_megatron.megatron.training_loop:Training step 159 - epoch 158 - loss 0.0822552889585495- learning rate 0.0006149999999999991 193 INFO:cray_megatron.megatron.training_loop:Training step 160 - epoch 159 - loss 0.6657384037971497- learning rate 0.0005999999999999991 194 INFO:cray_megatron.megatron.training_loop:Training step 161 - epoch 160 - loss 0.0813547819852829- learning rate 0.000584999999999999 195 INFO:cray_megatron.megatron.training_loop:Training step 162 - epoch 161 - loss 0.6767227649688721- learning rate 0.000569999999999999 196 INFO:cray_megatron.megatron.training_loop:Training step 163 - epoch 162 - loss 0.08070477843284607- learning rate 0.0005549999999999991 197 INFO:cray_megatron.megatron.training_loop:Training step 164 - epoch 163 - loss 0.6971059441566467- learning rate 0.0005399999999999991 198 INFO:cray_megatron.megatron.training_loop:Training step 165 - epoch 164 - loss 0.08001180738210678- learning rate 0.0005249999999999992 199 INFO:cray_megatron.megatron.training_loop:Training step 166 - epoch 165 - loss 0.6862263083457947- learning rate 0.0005099999999999993 200 INFO:cray_megatron.megatron.training_loop:Training step 167 - epoch 166 - loss 0.7431939840316772- learning rate 0.0004949999999999993 201 INFO:cray_megatron.megatron.training_loop:Training step 168 - epoch 167 - loss 0.5616518259048462- learning rate 0.00047999999999999936 202 INFO:cray_megatron.megatron.training_loop:Training step 169 - epoch 168 - loss 0.6773163676261902- learning rate 0.0004649999999999994 203 INFO:cray_megatron.megatron.training_loop:Training step 170 - epoch 169 - loss 0.6207675337791443- learning rate 0.0004499999999999994 204 INFO:cray_megatron.megatron.training_loop:Training step 171 - epoch 170 - loss 0.07802726328372955- learning rate 0.0004349999999999994 205 INFO:cray_megatron.megatron.training_loop:Training step 172 - epoch 171 - loss 0.07783862948417664- learning rate 0.0004199999999999994 206 INFO:cray_megatron.megatron.training_loop:Training step 173 - epoch 172 - loss 0.0776292234659195- learning rate 0.00040499999999999944 207 INFO:cray_megatron.megatron.training_loop:Training step 174 - epoch 173 - loss 0.07749556005001068- learning rate 0.0003899999999999995 208 INFO:cray_megatron.megatron.training_loop:Training step 175 - epoch 174 - loss 0.07696105539798737- learning rate 0.0003749999999999995 209 INFO:cray_megatron.megatron.training_loop:Training step 176 - epoch 175 - loss 0.7952118515968323- learning rate 0.00035999999999999953 210 INFO:cray_megatron.megatron.training_loop:Training step 177 - epoch 176 - loss 0.07636845856904984- learning rate 0.00034499999999999955 211 INFO:cray_megatron.megatron.training_loop:Training step 178 - epoch 177 - loss 0.7084242701530457- learning rate 0.00032999999999999956 212 INFO:cray_megatron.megatron.training_loop:Training step 179 - epoch 178 - loss 0.6410847902297974- learning rate 0.0003149999999999996 213 INFO:cray_megatron.megatron.training_loop:Training step 180 - epoch 179 - loss 0.07575994729995728- learning rate 0.0002999999999999996 214 INFO:cray_megatron.megatron.training_loop:Training step 181 - epoch 180 - loss 0.5927628874778748- learning rate 0.0002849999999999996 215 INFO:cray_megatron.megatron.training_loop:Training step 182 - epoch 181 - loss 0.07534792274236679- learning rate 0.0002699999999999996 216 INFO:cray_megatron.megatron.training_loop:Training step 183 - epoch 182 - loss 0.9427987337112427- learning rate 0.00025499999999999964 217 INFO:cray_megatron.megatron.training_loop:Training step 184 - epoch 183 - loss 0.07497585564851761- learning rate 0.00023999999999999965 218 INFO:cray_megatron.megatron.training_loop:Training step 185 - epoch 184 - loss 0.07496164739131927- learning rate 0.00022499999999999967 219 INFO:cray_megatron.megatron.training_loop:Training step 186 - epoch 185 - loss 0.6813051700592041- learning rate 0.00020999999999999968 220 INFO:cray_megatron.megatron.training_loop:Training step 187 - epoch 186 - loss 0.8017317056655884- learning rate 0.00019499999999999973 221 INFO:cray_megatron.megatron.training_loop:Training step 188 - epoch 187 - loss 0.6315902471542358- learning rate 0.00017999999999999977 222 INFO:cray_megatron.megatron.training_loop:Training step 189 - epoch 188 - loss 0.07442592084407806- learning rate 0.00016499999999999978 223 INFO:cray_megatron.megatron.training_loop:Training step 190 - epoch 189 - loss 0.6251041889190674- learning rate 0.0001499999999999998 224 INFO:cray_megatron.megatron.training_loop:Training step 191 - epoch 190 - loss 0.8014819622039795- learning rate 0.0001349999999999998 225 INFO:cray_megatron.megatron.training_loop:Training step 192 - epoch 191 - loss 0.8565230369567871- learning rate 0.00011999999999999983 226 INFO:cray_megatron.megatron.training_loop:Training step 193 - epoch 192 - loss 0.6923254728317261- learning rate 0.00010499999999999984 227 INFO:cray_megatron.megatron.training_loop:Training step 194 - epoch 193 - loss 0.8134770393371582- learning rate 8.999999999999987e-05 228 INFO:cray_megatron.megatron.training_loop:Training step 195 - epoch 194 - loss 0.8165243864059448- learning rate 7.49999999999999e-05 229 INFO:cray_megatron.megatron.training_loop:Training step 196 - epoch 195 - loss 0.6490029096603394- learning rate 5.999999999999992e-05 230 INFO:cray_megatron.megatron.training_loop:Training step 197 - epoch 196 - loss 0.6595770716667175- learning rate 4.499999999999994e-05 231 INFO:cray_megatron.megatron.training_loop:Training step 198 - epoch 197 - loss 0.07445919513702393- learning rate 2.9999999999999963e-05 232 INFO:cray_megatron.megatron.training_loop:Training step 199 - epoch 198 - loss 0.795946478843689- learning rate 1.4999999999999982e-05 233 INFO:cray_megatron.megatron.training_loop:Training finished successfully after 30.568594932556152 seconds 234 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_199.pt 235 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model","title":"Training Logs"},{"location":"docs/cli/training-logs/#training-logs","text":"./cray llm logs -f This command streams the training logs for the model with the specified identifier. The logs include information about the training process, such as the loss and accuracy of the model at each epoch. If no identifiers are provided, the command will list the most recent model. 0 + export CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 1 + CRAY_TRAINING_JOB_CONFIG_PATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 2 +++ dirname /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/config.yaml 3 ++ cd /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 4 ++ pwd 5 + LOCAL_DIRECTORY=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e 6 + export PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 7 + PYTHONPATH=/app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml::/app/cray/infra:/app/cray/sdk:/app/cray/ml 8 + mpirun --allow-run-as-root python /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/ml/cray_megatron/main.py 9 INFO:cray_infra.training.print_logo: 10 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u28a0\u2880\u2850\u2884\u28a2\u2850\u28a2\u2881\u2802\u2804\u2820\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 11 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2844\u28cc\u2830\u28d8\u28c6\u28a7\u285c\u28ee\u28f1\u28ce\u2837\u28cc\u285e\u28cc\u2852\u2824\u28c8\u2820\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 12 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2812\u280a\u2800\u2800\u2800\u2800\u2880\u2822\u2831\u285c\u28de\u28f3\u281d\u28d8\u28ed\u28fc\u28fe\u28f7\u28f6\u28f6\u28ee\u28ec\u28e5\u28d9\u2832\u28a1\u2882\u2821\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 13 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2803\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2822\u28d1\u28a3\u281d\u28ea\u28f5\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f6\u28ef\u28fb\u28a6\u28cd\u2822\u2885\u2882\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 14 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2800\u2800\u2886\u2871\u280c\u28e1\u289e\u28f5\u28ff\u28ff\u28ff\u283f\u281b\u281b\u2809\u2809\u281b\u281b\u283f\u28b7\u28fd\u28fb\u28e6\u28ce\u28b3\u28cc\u2806\u2871\u2880\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 15 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u2802\u2820\u280c\u28a2\u2883\u287e\u28f1\u28ff\u28bf\u287e\u280b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2809\u28bb\u28cf\u283b\u28f7\u28ec\u2873\u28e4\u2842\u281c\u28a0\u2840\u28c0\u2800\u2800\u2840\u2800\u2800\u2800\u2800\u2800\u2800 16 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2880\u2802\u28cc\u2883\u287e\u28a1\u28ff\u28a3\u284f\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b9\u2847\u284a\u28ff\u28ff\u28fe\u28fd\u28db\u2836\u28f6\u28ec\u28ed\u28e5\u28d9\u28da\u28b7\u28f6\u2826\u2864\u2880 17 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2881\u2802\u2830\u284c\u287c\u2821\u28fc\u2883\u287f\u2800\u2800\u2800\u2800MasInt\u2800\u2800\u2800\u2800\u2800\u2800\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28fe\u287f\u283f\u28db\u28ef\u2874\u288f\u2833\u2801\u2800 18 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2820\u2811\u284c\u2800\u28c9\u28fe\u28e9\u28fc\u28ff\u28fe\u2847\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u28c0\u28e0\u28e4\u28e4\u28ff\u28ff\u28ff\u28ff\u287f\u289b\u28db\u28ef\u28ed\u2836\u28de\u283b\u28c9\u2812\u2800\u2802\u2800\u2800\u2800 19 \u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28c0\u2876\u289d\u28e2\u28fe\u28ff\u28fc\u28ff\u28ff\u28ff\u28ff\u28ff\u28c0\u28fc\u28c0\u28c0\u28c0\u28e4\u28f4\u28f6\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u283f\u28ff\u283f\u285b\u280f\u280d\u2802\u2801\u28a0\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800 20 \u2800\u2820\u2880\u28a5\u28f0\u28fe\u28ff\u28ef\u28f6\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u281f\u28fd\u281f\u28ff\u2810\u2828\u2811\u2840\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 21 \u2850\u28a2\u28df\u28fe\u28ff\u28ff\u28df\u28db\u28ff\u28ff\u28ff\u28ff\u28bf\u28dd\u283b\u283f\u28bf\u28ef\u28db\u28bf\u28ff\u28ff\u28ff\u285b\u283b\u283f\u28db\u283b\u281b\u285b\u2829\u2881\u28f4\u287e\u2883\u28fe\u2807\u2880\u2821\u2802\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 22 \u2808\u2801\u280a\u2819\u2809\u2829\u280c\u2809\u2822\u2809\u2810\u2808\u2802\u2808\u2801\u2809\u2802\u2810\u2809\u28fb\u28f7\u28ed\u281b\u283f\u28f6\u28e6\u28e4\u28e4\u28f4\u28f4\u287e\u281f\u28eb\u28fe\u28ff\u284f\u2800\u2802\u2810\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 23 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2819\u28bb\u28bf\u28b6\u28e4\u28ec\u28c9\u28c9\u28ed\u28e4\u28f4\u28ff\u28ff\u287f\u2803\u2804\u2848\u2801\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 24 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2801\u2818\u288a\u2833\u282d\u287d\u28ff\u283f\u283f\u281f\u281b\u2809\u2800\u2801\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 25 \u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2808\u2800\u2801\u2808\u2810\u2800\u2818\u2800\u2808\u2800\u2808\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800 26 27 DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443 28 DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /NousResearch/Llama-3.2-1B/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0 29 `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`. 30 INFO:cray_megatron.megatron.training_loop:Training step 0 - epoch 0 - loss 11.851648330688477- learning rate 0.003 31 INFO:cray_megatron.megatron.training_loop:Training step 1 - epoch 0 - loss 11.491947174072266- learning rate 0.0029850000000000002 32 INFO:cray_megatron.megatron.training_loop:Training step 2 - epoch 1 - loss 11.067758560180664- learning rate 0.00297 33 INFO:cray_megatron.megatron.training_loop:Training step 3 - epoch 2 - loss 10.38668155670166- learning rate 0.0029549999999999997 34 INFO:cray_megatron.megatron.training_loop:Training step 4 - epoch 3 - loss 10.309948921203613- learning rate 0.0029399999999999995 35 INFO:cray_megatron.megatron.training_loop:Training step 5 - epoch 4 - loss 10.753833770751953- learning rate 0.0029249999999999996 36 INFO:cray_megatron.megatron.training_loop:Training step 6 - epoch 5 - loss 11.955288887023926- learning rate 0.00291 37 INFO:cray_megatron.megatron.training_loop:Training step 7 - epoch 6 - loss 10.206552505493164- learning rate 0.002895 38 INFO:cray_megatron.megatron.training_loop:Training step 8 - epoch 7 - loss 11.689804077148438- learning rate 0.0028799999999999997 39 INFO:cray_megatron.megatron.training_loop:Training step 9 - epoch 8 - loss 11.29571533203125- learning rate 0.0028649999999999995 40 INFO:cray_megatron.megatron.training_loop:Training step 10 - epoch 9 - loss 9.205053329467773- learning rate 0.0028499999999999997 41 INFO:cray_megatron.megatron.training_loop:Training step 11 - epoch 10 - loss 11.743261337280273- learning rate 0.0028349999999999994 42 INFO:cray_megatron.megatron.training_loop:Training step 12 - epoch 11 - loss 8.788749694824219- learning rate 0.002819999999999999 43 INFO:cray_megatron.megatron.training_loop:Training step 13 - epoch 12 - loss 9.033876419067383- learning rate 0.002804999999999999 44 INFO:cray_megatron.megatron.training_loop:Training step 14 - epoch 13 - loss 11.744029998779297- learning rate 0.0027899999999999986 45 INFO:cray_megatron.megatron.training_loop:Training step 15 - epoch 14 - loss 8.629796981811523- learning rate 0.002774999999999999 46 INFO:cray_megatron.megatron.training_loop:Training step 16 - epoch 15 - loss 8.350188255310059- learning rate 0.002759999999999999 47 INFO:cray_megatron.megatron.training_loop:Training step 17 - epoch 16 - loss 8.093982696533203- learning rate 0.0027449999999999987 48 INFO:cray_megatron.megatron.training_loop:Training step 18 - epoch 17 - loss 7.8525495529174805- learning rate 0.002729999999999999 49 INFO:cray_megatron.megatron.training_loop:Training step 19 - epoch 18 - loss 11.577287673950195- learning rate 0.002714999999999999 50 INFO:cray_megatron.megatron.training_loop:Training step 20 - epoch 19 - loss 7.367895126342773- learning rate 0.0026999999999999993 51 INFO:cray_megatron.megatron.training_loop:Training step 21 - epoch 20 - loss 11.79365348815918- learning rate 0.0026849999999999995 52 INFO:cray_megatron.megatron.training_loop:Training step 22 - epoch 21 - loss 6.936058044433594- learning rate 0.002669999999999999 53 INFO:cray_megatron.megatron.training_loop:Training step 23 - epoch 22 - loss 10.056737899780273- learning rate 0.0026549999999999994 54 INFO:cray_megatron.megatron.training_loop:Training step 24 - epoch 23 - loss 9.305437088012695- learning rate 0.0026399999999999996 55 INFO:cray_megatron.megatron.training_loop:Training step 25 - epoch 24 - loss 6.2938947677612305- learning rate 0.0026249999999999993 56 INFO:cray_megatron.megatron.training_loop:Training step 26 - epoch 25 - loss 6.068697929382324- learning rate 0.0026099999999999995 57 INFO:cray_megatron.megatron.training_loop:Training step 27 - epoch 26 - loss 5.812913417816162- learning rate 0.0025949999999999992 58 INFO:cray_megatron.megatron.training_loop:Training step 28 - epoch 27 - loss 10.825139999389648- learning rate 0.002579999999999999 59 INFO:cray_megatron.megatron.training_loop:Training step 29 - epoch 28 - loss 9.760759353637695- learning rate 0.002564999999999999 60 INFO:cray_megatron.megatron.training_loop:Training step 30 - epoch 29 - loss 10.444537162780762- learning rate 0.0025499999999999993 61 INFO:cray_megatron.megatron.training_loop:Training step 31 - epoch 30 - loss 9.888254165649414- learning rate 0.0025349999999999995 62 INFO:cray_megatron.megatron.training_loop:Training step 32 - epoch 31 - loss 4.675031661987305- learning rate 0.0025199999999999992 63 INFO:cray_megatron.megatron.training_loop:Training step 33 - epoch 32 - loss 4.461902618408203- learning rate 0.0025049999999999994 64 INFO:cray_megatron.megatron.training_loop:Training step 34 - epoch 33 - loss 4.232550621032715- learning rate 0.002489999999999999 65 INFO:cray_megatron.megatron.training_loop:Training step 35 - epoch 34 - loss 9.657859802246094- learning rate 0.0024749999999999993 66 INFO:cray_megatron.megatron.training_loop:Training step 36 - epoch 35 - loss 5.435771942138672- learning rate 0.002459999999999999 67 INFO:cray_megatron.megatron.training_loop:Training step 37 - epoch 36 - loss 4.934456825256348- learning rate 0.0024449999999999993 68 INFO:cray_megatron.megatron.training_loop:Training step 38 - epoch 37 - loss 3.3201217651367188- learning rate 0.0024299999999999994 69 INFO:cray_megatron.megatron.training_loop:Training step 39 - epoch 38 - loss 3.090512990951538- learning rate 0.002414999999999999 70 INFO:cray_megatron.megatron.training_loop:Training step 40 - epoch 39 - loss 2.8569488525390625- learning rate 0.0023999999999999994 71 INFO:cray_megatron.megatron.training_loop:Training step 41 - epoch 40 - loss 2.6222681999206543- learning rate 0.0023849999999999995 72 INFO:cray_megatron.megatron.training_loop:Training step 42 - epoch 41 - loss 2.3898932933807373- learning rate 0.0023699999999999997 73 INFO:cray_megatron.megatron.training_loop:Training step 43 - epoch 42 - loss 2.449845314025879- learning rate 0.0023549999999999995 74 INFO:cray_megatron.megatron.training_loop:Training step 44 - epoch 43 - loss 1.9457842111587524- learning rate 0.0023399999999999996 75 INFO:cray_megatron.megatron.training_loop:Training step 45 - epoch 44 - loss 3.3052239418029785- learning rate 0.002325 76 INFO:cray_megatron.megatron.training_loop:Training step 46 - epoch 45 - loss 1.5511304140090942- learning rate 0.00231 77 INFO:cray_megatron.megatron.training_loop:Training step 47 - epoch 46 - loss 1.381464958190918- learning rate 0.002295 78 INFO:cray_megatron.megatron.training_loop:Training step 48 - epoch 47 - loss 1.8805816173553467- learning rate 0.0022800000000000003 79 INFO:cray_megatron.megatron.training_loop:Training step 49 - epoch 48 - loss 1.6158814430236816- learning rate 0.0022650000000000005 80 INFO:cray_megatron.megatron.training_loop:Training step 50 - epoch 49 - loss 0.9921494722366333- learning rate 0.0022500000000000003 81 INFO:cray_megatron.megatron.training_loop:Training step 51 - epoch 50 - loss 0.9002286791801453- learning rate 0.002235 82 INFO:cray_megatron.megatron.training_loop:Training step 52 - epoch 51 - loss 1.0186548233032227- learning rate 0.00222 83 INFO:cray_megatron.megatron.training_loop:Training step 53 - epoch 52 - loss 0.7658149003982544- learning rate 0.002205 84 INFO:cray_megatron.megatron.training_loop:Training step 54 - epoch 53 - loss 0.7076711654663086- learning rate 0.00219 85 INFO:cray_megatron.megatron.training_loop:Training step 55 - epoch 54 - loss 0.9462921619415283- learning rate 0.002175 86 INFO:cray_megatron.megatron.training_loop:Training step 56 - epoch 55 - loss 0.6228013038635254- learning rate 0.00216 87 INFO:cray_megatron.megatron.training_loop:Training step 57 - epoch 56 - loss 0.5883803367614746- learning rate 0.002145 88 INFO:cray_megatron.megatron.training_loop:Training step 58 - epoch 57 - loss 0.7707682251930237- learning rate 0.0021300000000000004 89 INFO:cray_megatron.megatron.training_loop:Training step 59 - epoch 58 - loss 0.758730411529541- learning rate 0.0021150000000000006 90 INFO:cray_megatron.megatron.training_loop:Training step 60 - epoch 59 - loss 0.506292462348938- learning rate 0.0021000000000000007 91 INFO:cray_megatron.megatron.training_loop:Training step 61 - epoch 60 - loss 0.4830833673477173- learning rate 0.002085000000000001 92 INFO:cray_megatron.megatron.training_loop:Training step 62 - epoch 61 - loss 0.7608119249343872- learning rate 0.002070000000000001 93 INFO:cray_megatron.megatron.training_loop:Training step 63 - epoch 62 - loss 0.43636059761047363- learning rate 0.002055000000000001 94 INFO:cray_megatron.megatron.training_loop:Training step 64 - epoch 63 - loss 0.748888373374939- learning rate 0.002040000000000001 95 INFO:cray_megatron.megatron.training_loop:Training step 65 - epoch 64 - loss 0.3981848359107971- learning rate 0.002025000000000001 96 INFO:cray_megatron.megatron.training_loop:Training step 66 - epoch 65 - loss 0.38111788034439087- learning rate 0.0020100000000000014 97 INFO:cray_megatron.megatron.training_loop:Training step 67 - epoch 66 - loss 0.6918612718582153- learning rate 0.001995000000000001 98 INFO:cray_megatron.megatron.training_loop:Training step 68 - epoch 67 - loss 0.3478345274925232- learning rate 0.001980000000000001 99 INFO:cray_megatron.megatron.training_loop:Training step 69 - epoch 68 - loss 0.7505407333374023- learning rate 0.001965000000000001 100 INFO:cray_megatron.megatron.training_loop:Training step 70 - epoch 69 - loss 0.7745790481567383- learning rate 0.001950000000000001 101 INFO:cray_megatron.megatron.training_loop:Training step 71 - epoch 70 - loss 0.7360649704933167- learning rate 0.001935000000000001 102 INFO:cray_megatron.megatron.training_loop:Training step 72 - epoch 71 - loss 0.6509546637535095- learning rate 0.001920000000000001 103 INFO:cray_megatron.megatron.training_loop:Training step 73 - epoch 72 - loss 0.3059840202331543- learning rate 0.0019050000000000009 104 INFO:cray_megatron.megatron.training_loop:Training step 74 - epoch 73 - loss 0.29385578632354736- learning rate 0.0018900000000000008 105 INFO:cray_megatron.megatron.training_loop:Training step 75 - epoch 74 - loss 0.2902987003326416- learning rate 0.0018750000000000008 106 INFO:cray_megatron.megatron.training_loop:Training step 76 - epoch 75 - loss 0.7161434888839722- learning rate 0.0018600000000000008 107 INFO:cray_megatron.megatron.training_loop:Training step 77 - epoch 76 - loss 0.2615271806716919- learning rate 0.0018450000000000007 108 INFO:cray_megatron.megatron.training_loop:Training step 78 - epoch 77 - loss 0.8070529699325562- learning rate 0.0018300000000000007 109 INFO:cray_megatron.megatron.training_loop:Training step 79 - epoch 78 - loss 0.7276452779769897- learning rate 0.0018150000000000006 110 INFO:cray_megatron.megatron.training_loop:Training step 80 - epoch 79 - loss 0.8069541454315186- learning rate 0.0018000000000000006 111 INFO:cray_megatron.megatron.training_loop:Training step 81 - epoch 80 - loss 0.6734392642974854- learning rate 0.0017850000000000006 112 INFO:cray_megatron.megatron.training_loop:Training step 82 - epoch 81 - loss 0.6499148607254028- learning rate 0.0017700000000000005 113 INFO:cray_megatron.megatron.training_loop:Training step 83 - epoch 82 - loss 0.7235682010650635- learning rate 0.0017550000000000005 114 INFO:cray_megatron.megatron.training_loop:Training step 84 - epoch 83 - loss 0.788324236869812- learning rate 0.0017400000000000004 115 INFO:cray_megatron.megatron.training_loop:Training step 85 - epoch 84 - loss 0.7486412525177002- learning rate 0.0017250000000000004 116 INFO:cray_megatron.megatron.training_loop:Training step 86 - epoch 85 - loss 0.6475511193275452- learning rate 0.0017100000000000006 117 INFO:cray_megatron.megatron.training_loop:Training step 87 - epoch 86 - loss 0.23438769578933716- learning rate 0.0016950000000000005 118 INFO:cray_megatron.megatron.training_loop:Training step 88 - epoch 87 - loss 0.69432532787323- learning rate 0.0016800000000000005 119 INFO:cray_megatron.megatron.training_loop:Training step 89 - epoch 88 - loss 0.701191782951355- learning rate 0.0016650000000000005 120 INFO:cray_megatron.megatron.training_loop:Training step 90 - epoch 89 - loss 0.8208021521568298- learning rate 0.0016500000000000004 121 INFO:cray_megatron.megatron.training_loop:Training step 91 - epoch 90 - loss 0.7423532009124756- learning rate 0.0016350000000000006 122 INFO:cray_megatron.megatron.training_loop:Training step 92 - epoch 91 - loss 0.22764872014522552- learning rate 0.0016200000000000008 123 INFO:cray_megatron.megatron.training_loop:Training step 93 - epoch 92 - loss 0.6770063042640686- learning rate 0.0016050000000000007 124 INFO:cray_megatron.megatron.training_loop:Training step 94 - epoch 93 - loss 0.2195751667022705- learning rate 0.0015900000000000007 125 INFO:cray_megatron.megatron.training_loop:Training step 95 - epoch 94 - loss 0.21528244018554688- learning rate 0.0015750000000000007 126 INFO:cray_megatron.megatron.training_loop:Training step 96 - epoch 95 - loss 0.2105533480644226- learning rate 0.0015600000000000006 127 INFO:cray_megatron.megatron.training_loop:Training step 97 - epoch 96 - loss 0.20401671528816223- learning rate 0.0015450000000000006 128 INFO:cray_megatron.megatron.training_loop:Training step 98 - epoch 97 - loss 0.19684851169586182- learning rate 0.0015300000000000005 129 INFO:cray_megatron.megatron.training_loop:Training step 99 - epoch 98 - loss 0.18342770636081696- learning rate 0.0015150000000000005 130 INFO:cray_megatron.megatron.training_loop:Training step 100 - epoch 99 - loss 0.17346294224262238- learning rate 0.0015000000000000005 131 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_100.pt 132 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model 133 INFO:cray_megatron.megatron.training_loop:Checkpoint on step 100 took 0.748274564743042 seconds 134 INFO:cray_megatron.megatron.training_loop:Training step 101 - epoch 100 - loss 0.16589578986167908- learning rate 0.0014850000000000004 135 INFO:cray_megatron.megatron.training_loop:Training step 102 - epoch 101 - loss 0.7842352986335754- learning rate 0.0014700000000000004 136 INFO:cray_megatron.megatron.training_loop:Training step 103 - epoch 102 - loss 0.8229332566261292- learning rate 0.0014550000000000003 137 INFO:cray_megatron.megatron.training_loop:Training step 104 - epoch 103 - loss 0.749505877494812- learning rate 0.0014400000000000003 138 INFO:cray_megatron.megatron.training_loop:Training step 105 - epoch 104 - loss 0.1399921178817749- learning rate 0.0014250000000000003 139 INFO:cray_megatron.megatron.training_loop:Training step 106 - epoch 105 - loss 0.13615575432777405- learning rate 0.0014100000000000002 140 INFO:cray_megatron.megatron.training_loop:Training step 107 - epoch 106 - loss 0.1328878551721573- learning rate 0.0013950000000000002 141 INFO:cray_megatron.megatron.training_loop:Training step 108 - epoch 107 - loss 0.1299896240234375- learning rate 0.0013800000000000002 142 INFO:cray_megatron.megatron.training_loop:Training step 109 - epoch 108 - loss 0.12737448513507843- learning rate 0.0013650000000000001 143 INFO:cray_megatron.megatron.training_loop:Training step 110 - epoch 109 - loss 0.8569282293319702- learning rate 0.00135 144 INFO:cray_megatron.megatron.training_loop:Training step 111 - epoch 110 - loss 0.8064426183700562- learning rate 0.001335 145 INFO:cray_megatron.megatron.training_loop:Training step 112 - epoch 111 - loss 0.12294523417949677- learning rate 0.00132 146 INFO:cray_megatron.megatron.training_loop:Training step 113 - epoch 112 - loss 0.7471427917480469- learning rate 0.001305 147 INFO:cray_megatron.megatron.training_loop:Training step 114 - epoch 113 - loss 0.12056495994329453- learning rate 0.00129 148 INFO:cray_megatron.megatron.training_loop:Training step 115 - epoch 114 - loss 0.11913363635540009- learning rate 0.0012749999999999999 149 INFO:cray_megatron.megatron.training_loop:Training step 116 - epoch 115 - loss 0.11778314411640167- learning rate 0.0012599999999999998 150 INFO:cray_megatron.megatron.training_loop:Training step 117 - epoch 116 - loss 0.11592821776866913- learning rate 0.0012449999999999998 151 INFO:cray_megatron.megatron.training_loop:Training step 118 - epoch 117 - loss 0.747460126876831- learning rate 0.0012299999999999998 152 INFO:cray_megatron.megatron.training_loop:Training step 119 - epoch 118 - loss 0.11181403696537018- learning rate 0.0012149999999999997 153 INFO:cray_megatron.megatron.training_loop:Training step 120 - epoch 119 - loss 0.11106443405151367- learning rate 0.0011999999999999997 154 INFO:cray_megatron.megatron.training_loop:Training step 121 - epoch 120 - loss 0.7953877449035645- learning rate 0.0011849999999999996 155 INFO:cray_megatron.megatron.training_loop:Training step 122 - epoch 121 - loss 0.7007923126220703- learning rate 0.0011699999999999996 156 INFO:cray_megatron.megatron.training_loop:Training step 123 - epoch 122 - loss 0.5777735710144043- learning rate 0.0011549999999999996 157 INFO:cray_megatron.megatron.training_loop:Training step 124 - epoch 123 - loss 0.10659528523683548- learning rate 0.0011399999999999995 158 INFO:cray_megatron.megatron.training_loop:Training step 125 - epoch 124 - loss 0.6686602830886841- learning rate 0.0011249999999999995 159 INFO:cray_megatron.megatron.training_loop:Training step 126 - epoch 125 - loss 0.7213398218154907- learning rate 0.0011099999999999994 160 INFO:cray_megatron.megatron.training_loop:Training step 127 - epoch 126 - loss 0.10370150953531265- learning rate 0.0010949999999999994 161 INFO:cray_megatron.megatron.training_loop:Training step 128 - epoch 127 - loss 0.715872585773468- learning rate 0.0010799999999999994 162 INFO:cray_megatron.megatron.training_loop:Training step 129 - epoch 128 - loss 0.6672084331512451- learning rate 0.0010649999999999993 163 INFO:cray_megatron.megatron.training_loop:Training step 130 - epoch 129 - loss 0.6094690561294556- learning rate 0.0010499999999999993 164 INFO:cray_megatron.megatron.training_loop:Training step 131 - epoch 130 - loss 0.09981067478656769- learning rate 0.0010349999999999992 165 INFO:cray_megatron.megatron.training_loop:Training step 132 - epoch 131 - loss 0.09831465780735016- learning rate 0.0010199999999999992 166 INFO:cray_megatron.megatron.training_loop:Training step 133 - epoch 132 - loss 0.8732300996780396- learning rate 0.0010049999999999992 167 INFO:cray_megatron.megatron.training_loop:Training step 134 - epoch 133 - loss 0.09659353643655777- learning rate 0.0009899999999999991 168 INFO:cray_megatron.megatron.training_loop:Training step 135 - epoch 134 - loss 0.0957847312092781- learning rate 0.0009749999999999992 169 INFO:cray_megatron.megatron.training_loop:Training step 136 - epoch 135 - loss 0.09486415982246399- learning rate 0.0009599999999999993 170 INFO:cray_megatron.megatron.training_loop:Training step 137 - epoch 136 - loss 0.687118411064148- learning rate 0.0009449999999999992 171 INFO:cray_megatron.megatron.training_loop:Training step 138 - epoch 137 - loss 0.7465814352035522- learning rate 0.0009299999999999993 172 INFO:cray_megatron.megatron.training_loop:Training step 139 - epoch 138 - loss 0.09353536367416382- learning rate 0.0009149999999999994 173 INFO:cray_megatron.megatron.training_loop:Training step 140 - epoch 139 - loss 0.6857355833053589- learning rate 0.0008999999999999993 174 INFO:cray_megatron.megatron.training_loop:Training step 141 - epoch 140 - loss 0.8234232068061829- learning rate 0.0008849999999999993 175 INFO:cray_megatron.megatron.training_loop:Training step 142 - epoch 141 - loss 0.09200795739889145- learning rate 0.0008699999999999994 176 INFO:cray_megatron.megatron.training_loop:Training step 143 - epoch 142 - loss 0.6732250452041626- learning rate 0.0008549999999999993 177 INFO:cray_megatron.megatron.training_loop:Training step 144 - epoch 143 - loss 0.08996626734733582- learning rate 0.0008399999999999993 178 INFO:cray_megatron.megatron.training_loop:Training step 145 - epoch 144 - loss 0.5915161371231079- learning rate 0.0008249999999999992 179 INFO:cray_megatron.megatron.training_loop:Training step 146 - epoch 145 - loss 0.08881303668022156- learning rate 0.0008099999999999992 180 INFO:cray_megatron.megatron.training_loop:Training step 147 - epoch 146 - loss 0.7250931262969971- learning rate 0.0007949999999999993 181 INFO:cray_megatron.megatron.training_loop:Training step 148 - epoch 147 - loss 0.6727677583694458- learning rate 0.0007799999999999993 182 INFO:cray_megatron.megatron.training_loop:Training step 149 - epoch 148 - loss 0.2871503531932831- learning rate 0.0007649999999999993 183 INFO:cray_megatron.megatron.training_loop:Training step 150 - epoch 149 - loss 0.08630774915218353- learning rate 0.0007499999999999993 184 INFO:cray_megatron.megatron.training_loop:Training step 151 - epoch 150 - loss 0.6593747138977051- learning rate 0.0007349999999999992 185 INFO:cray_megatron.megatron.training_loop:Training step 152 - epoch 151 - loss 0.6607116460800171- learning rate 0.0007199999999999992 186 INFO:cray_megatron.megatron.training_loop:Training step 153 - epoch 152 - loss 0.08505091071128845- learning rate 0.0007049999999999991 187 INFO:cray_megatron.megatron.training_loop:Training step 154 - epoch 153 - loss 0.7495298385620117- learning rate 0.0006899999999999991 188 INFO:cray_megatron.megatron.training_loop:Training step 155 - epoch 154 - loss 0.0840618759393692- learning rate 0.0006749999999999992 189 INFO:cray_megatron.megatron.training_loop:Training step 156 - epoch 155 - loss 0.6931415796279907- learning rate 0.0006599999999999991 190 INFO:cray_megatron.megatron.training_loop:Training step 157 - epoch 156 - loss 0.6979023218154907- learning rate 0.0006449999999999992 191 INFO:cray_megatron.megatron.training_loop:Training step 158 - epoch 157 - loss 0.08278802037239075- learning rate 0.0006299999999999992 192 INFO:cray_megatron.megatron.training_loop:Training step 159 - epoch 158 - loss 0.0822552889585495- learning rate 0.0006149999999999991 193 INFO:cray_megatron.megatron.training_loop:Training step 160 - epoch 159 - loss 0.6657384037971497- learning rate 0.0005999999999999991 194 INFO:cray_megatron.megatron.training_loop:Training step 161 - epoch 160 - loss 0.0813547819852829- learning rate 0.000584999999999999 195 INFO:cray_megatron.megatron.training_loop:Training step 162 - epoch 161 - loss 0.6767227649688721- learning rate 0.000569999999999999 196 INFO:cray_megatron.megatron.training_loop:Training step 163 - epoch 162 - loss 0.08070477843284607- learning rate 0.0005549999999999991 197 INFO:cray_megatron.megatron.training_loop:Training step 164 - epoch 163 - loss 0.6971059441566467- learning rate 0.0005399999999999991 198 INFO:cray_megatron.megatron.training_loop:Training step 165 - epoch 164 - loss 0.08001180738210678- learning rate 0.0005249999999999992 199 INFO:cray_megatron.megatron.training_loop:Training step 166 - epoch 165 - loss 0.6862263083457947- learning rate 0.0005099999999999993 200 INFO:cray_megatron.megatron.training_loop:Training step 167 - epoch 166 - loss 0.7431939840316772- learning rate 0.0004949999999999993 201 INFO:cray_megatron.megatron.training_loop:Training step 168 - epoch 167 - loss 0.5616518259048462- learning rate 0.00047999999999999936 202 INFO:cray_megatron.megatron.training_loop:Training step 169 - epoch 168 - loss 0.6773163676261902- learning rate 0.0004649999999999994 203 INFO:cray_megatron.megatron.training_loop:Training step 170 - epoch 169 - loss 0.6207675337791443- learning rate 0.0004499999999999994 204 INFO:cray_megatron.megatron.training_loop:Training step 171 - epoch 170 - loss 0.07802726328372955- learning rate 0.0004349999999999994 205 INFO:cray_megatron.megatron.training_loop:Training step 172 - epoch 171 - loss 0.07783862948417664- learning rate 0.0004199999999999994 206 INFO:cray_megatron.megatron.training_loop:Training step 173 - epoch 172 - loss 0.0776292234659195- learning rate 0.00040499999999999944 207 INFO:cray_megatron.megatron.training_loop:Training step 174 - epoch 173 - loss 0.07749556005001068- learning rate 0.0003899999999999995 208 INFO:cray_megatron.megatron.training_loop:Training step 175 - epoch 174 - loss 0.07696105539798737- learning rate 0.0003749999999999995 209 INFO:cray_megatron.megatron.training_loop:Training step 176 - epoch 175 - loss 0.7952118515968323- learning rate 0.00035999999999999953 210 INFO:cray_megatron.megatron.training_loop:Training step 177 - epoch 176 - loss 0.07636845856904984- learning rate 0.00034499999999999955 211 INFO:cray_megatron.megatron.training_loop:Training step 178 - epoch 177 - loss 0.7084242701530457- learning rate 0.00032999999999999956 212 INFO:cray_megatron.megatron.training_loop:Training step 179 - epoch 178 - loss 0.6410847902297974- learning rate 0.0003149999999999996 213 INFO:cray_megatron.megatron.training_loop:Training step 180 - epoch 179 - loss 0.07575994729995728- learning rate 0.0002999999999999996 214 INFO:cray_megatron.megatron.training_loop:Training step 181 - epoch 180 - loss 0.5927628874778748- learning rate 0.0002849999999999996 215 INFO:cray_megatron.megatron.training_loop:Training step 182 - epoch 181 - loss 0.07534792274236679- learning rate 0.0002699999999999996 216 INFO:cray_megatron.megatron.training_loop:Training step 183 - epoch 182 - loss 0.9427987337112427- learning rate 0.00025499999999999964 217 INFO:cray_megatron.megatron.training_loop:Training step 184 - epoch 183 - loss 0.07497585564851761- learning rate 0.00023999999999999965 218 INFO:cray_megatron.megatron.training_loop:Training step 185 - epoch 184 - loss 0.07496164739131927- learning rate 0.00022499999999999967 219 INFO:cray_megatron.megatron.training_loop:Training step 186 - epoch 185 - loss 0.6813051700592041- learning rate 0.00020999999999999968 220 INFO:cray_megatron.megatron.training_loop:Training step 187 - epoch 186 - loss 0.8017317056655884- learning rate 0.00019499999999999973 221 INFO:cray_megatron.megatron.training_loop:Training step 188 - epoch 187 - loss 0.6315902471542358- learning rate 0.00017999999999999977 222 INFO:cray_megatron.megatron.training_loop:Training step 189 - epoch 188 - loss 0.07442592084407806- learning rate 0.00016499999999999978 223 INFO:cray_megatron.megatron.training_loop:Training step 190 - epoch 189 - loss 0.6251041889190674- learning rate 0.0001499999999999998 224 INFO:cray_megatron.megatron.training_loop:Training step 191 - epoch 190 - loss 0.8014819622039795- learning rate 0.0001349999999999998 225 INFO:cray_megatron.megatron.training_loop:Training step 192 - epoch 191 - loss 0.8565230369567871- learning rate 0.00011999999999999983 226 INFO:cray_megatron.megatron.training_loop:Training step 193 - epoch 192 - loss 0.6923254728317261- learning rate 0.00010499999999999984 227 INFO:cray_megatron.megatron.training_loop:Training step 194 - epoch 193 - loss 0.8134770393371582- learning rate 8.999999999999987e-05 228 INFO:cray_megatron.megatron.training_loop:Training step 195 - epoch 194 - loss 0.8165243864059448- learning rate 7.49999999999999e-05 229 INFO:cray_megatron.megatron.training_loop:Training step 196 - epoch 195 - loss 0.6490029096603394- learning rate 5.999999999999992e-05 230 INFO:cray_megatron.megatron.training_loop:Training step 197 - epoch 196 - loss 0.6595770716667175- learning rate 4.499999999999994e-05 231 INFO:cray_megatron.megatron.training_loop:Training step 198 - epoch 197 - loss 0.07445919513702393- learning rate 2.9999999999999963e-05 232 INFO:cray_megatron.megatron.training_loop:Training step 199 - epoch 198 - loss 0.795946478843689- learning rate 1.4999999999999982e-05 233 INFO:cray_megatron.megatron.training_loop:Training finished successfully after 30.568594932556152 seconds 234 INFO:cray_infra.training.training_harness:Checkpoint saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/checkpoint_199.pt 235 INFO:cray_infra.training.training_harness:Model saved to /app/cray/jobs/69118a251a074f9f9d37a2ddc903243e428d30c3c31ad019cbf62ac777e42e6e/saved_model","title":"Training Logs"},{"location":"docs/deployment/docker/","text":"Docker builds Check out prebuilt docker containers for different targets: Target Container Latest Release v0.5 NVIDIA gdiamos/cray-nvidia:latest gdiamos/cray-nvidia:v0.5 ARM gdiamos/cray-arm:latest gdiamos/cray-arm:v0.5 AMD gdiamos/cray-amd:latest gdiamos/cray-amd:v0.5 x86 gdiamos/cray-cpu:latest gdiamos/cray-cpu:v0.5 For example, to launch a development server on a modern macbook, e.g. m2 docker run -it -p 8000:8000 --entrypoint /app/cray/scripts/start_one_server.sh gdiamos/cray-arm:v0.5","title":"Docker builds"},{"location":"docs/deployment/docker/#docker-builds","text":"Check out prebuilt docker containers for different targets: Target Container Latest Release v0.5 NVIDIA gdiamos/cray-nvidia:latest gdiamos/cray-nvidia:v0.5 ARM gdiamos/cray-arm:latest gdiamos/cray-arm:v0.5 AMD gdiamos/cray-amd:latest gdiamos/cray-amd:v0.5 x86 gdiamos/cray-cpu:latest gdiamos/cray-cpu:v0.5 For example, to launch a development server on a modern macbook, e.g. m2 docker run -it -p 8000:8000 --entrypoint /app/cray/scripts/start_one_server.sh gdiamos/cray-arm:v0.5","title":"Docker builds"},{"location":"docs/deployment/kubernetes/","text":"Kubernetes Deployment ScalarLM can be deployed on Kubernetes. This guide will walk you through the steps to deploy Cray on Kubernetes. Prerequisites Make sure you have a kubernetes cluster running. You can set one up yourself or use a managed service like GKE or AKS. You can also use the provided Ansible recipe to install Kubernetes on a Lambda VM running Ubuntu 22.04. The recipe is available at Ansible Kubernetes . If you check out the repository on the server, you can run the playbook with the following command: ansible-playbook -i hosts -v k8.yml The ansible playbook is a list of tasks that will install Kubernetes on the Lambda VM. You can inspect the playbook to see what it does and modify it to suit your needs. It is also possible to run the playbook on a remote server by setting up the SSH connection in the hosts file. [all] lambda ansible_host=... Deploy ScalarLM To deploy ScalarLM on Kubernetes, you need to clone the Cray repository and run the following command: git clone git@github.com:cray-lm/cray-lm.git cd cray-lm/deployment/helm/lambda Edit the values.yaml file: set the externalIP address of the Lambda VM, or configure your ingress controller set the model to the huggingface model you want to deploy Then run the following command to deploy ScalarLM: helm install cray cray Verify the Deployment To verify the deployment, you can run the following command: kubectl get pods You should see the ScalarLM pod running. You can get the logs of the pod by running: kubectl logs cray-...","title":"Kubernetes Deployment"},{"location":"docs/deployment/kubernetes/#kubernetes-deployment","text":"ScalarLM can be deployed on Kubernetes. This guide will walk you through the steps to deploy Cray on Kubernetes.","title":"Kubernetes Deployment"},{"location":"docs/deployment/kubernetes/#prerequisites","text":"Make sure you have a kubernetes cluster running. You can set one up yourself or use a managed service like GKE or AKS. You can also use the provided Ansible recipe to install Kubernetes on a Lambda VM running Ubuntu 22.04. The recipe is available at Ansible Kubernetes . If you check out the repository on the server, you can run the playbook with the following command: ansible-playbook -i hosts -v k8.yml The ansible playbook is a list of tasks that will install Kubernetes on the Lambda VM. You can inspect the playbook to see what it does and modify it to suit your needs. It is also possible to run the playbook on a remote server by setting up the SSH connection in the hosts file. [all] lambda ansible_host=...","title":"Prerequisites"},{"location":"docs/deployment/kubernetes/#deploy-scalarlm","text":"To deploy ScalarLM on Kubernetes, you need to clone the Cray repository and run the following command: git clone git@github.com:cray-lm/cray-lm.git cd cray-lm/deployment/helm/lambda Edit the values.yaml file: set the externalIP address of the Lambda VM, or configure your ingress controller set the model to the huggingface model you want to deploy Then run the following command to deploy ScalarLM: helm install cray cray","title":"Deploy ScalarLM"},{"location":"docs/deployment/kubernetes/#verify-the-deployment","text":"To verify the deployment, you can run the following command: kubectl get pods You should see the ScalarLM pod running. You can get the logs of the pod by running: kubectl logs cray-...","title":"Verify the Deployment"},{"location":"docs/deployment/laptop/","text":"Laptop ScalarLM can be run on your laptop for development purposes. It requires Docker. Clone the ScalarLM repository and start the server. git clone git@github.com:tensorwavelm/scalarlm.git cd scalarlm ./cray up You should see the server come up. (environment) gregorydiamos@Air-Gregory cray % ./cray up +++ dirname ./cray ++ cd . ++ pwd + LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray + /Users/gregorydiamos/checkout/cray/cmd/bashly.sh generate ++++ dirname /Users/gregorydiamos/checkout/cray/cmd/bashly.sh +++ cd /Users/gregorydiamos/checkout/cray/cmd +++ pwd ++ LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray/cmd +++ id -u +++ id -g ++ docker run --rm -it --user 501:20 --volume /Users/gregorydiamos/checkout/cray/cmd:/app/cmd --volume /Users/gregorydiamos/checkout/cray/cmd/../scripts:/app/scripts --volume /Users/gregorydiamos/checkout/cray/cmd/bashly-settings.yml:/app/bashly-settings.yml dannyben/bashly generate creating user files in cmd skipped cmd/build_image_command.sh (exists) skipped cmd/depot_build_command.sh (exists) skipped cmd/up_command.sh (exists) skipped cmd/test_command.sh (exists) skipped cmd/deploy_command.sh (exists) skipped cmd/serve_command.sh (exists) skipped cmd/llm_plot_command.sh (exists) skipped cmd/llm_logs_command.sh (exists) skipped cmd/llm_ls_command.sh (exists) skipped cmd/llm_squeue_command.sh (exists) skipped cmd/diffusion_command.sh (exists) created /app/scripts/cray run /app/scripts/cray --help to test your bash script + /Users/gregorydiamos/checkout/cray/scripts/cray up [+] Running 0/14.2s (10/37) docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s [+] Building 217.0s (39/39) FINISHED docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 4.35kB 0.0s => [vllm internal] load metadata for docker.io/library/ubuntu:24.04 0.3s => [vllm internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => CACHED [vllm cpu 1/6] FROM docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => => resolve docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => [vllm internal] load build context 0.2s => => transferring context: 723.40kB 0.2s => [vllm cpu 2/6] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y python3 python3-pip python3-venv openmpi-bin libopenmpi-dev libpmix-dev 60.7s => [vllm cpu 3/6] RUN python3 -m venv /app/.venv 2.6s => [vllm cpu 4/6] RUN . /app/.venv/bin/activate 0.1s => [vllm cpu 5/6] RUN pip install uv 1.4s => [vllm cpu 6/6] RUN uv pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cpu 6.3s => [vllm vllm 1/17] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y curl ccache git vim numactl gcc-12 g++-12 libomp-dev libnuma-dev && apt-get ins 74.9s => [vllm vllm 2/17] COPY ./requirements.txt /app/cray/requirements.txt 0.1s => [vllm vllm 3/17] COPY ./test/requirements-pytest.txt /app/cray/requirements-pytest.txt 0.0s => [vllm vllm 4/17] COPY ./infra/requirements-vllm-build.txt /app/cray/requirements-vllm-build.txt 0.0s => [vllm vllm 5/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements.txt 8.6s => [vllm vllm 6/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-vllm-build.txt 1.6s => [vllm vllm 7/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-pytest.txt 0.5s => [vllm vllm 8/17] WORKDIR /app/cray 0.0s => [vllm vllm 9/17] COPY ./infra/cray_infra/vllm /app/cray/infra/cray_infra/vllm 0.1s => [vllm vllm 10/17] COPY ./infra/setup.py /app/cray/infra/cray_infra/setup.py 0.0s => [vllm vllm 11/17] COPY ./infra/CMakeLists.txt /app/cray/infra/cray_infra/CMakeLists.txt 0.0s => [vllm vllm 12/17] COPY ./infra/cmake /app/cray/infra/cray_infra/cmake 0.0s => [vllm vllm 13/17] COPY ./infra/csrc /app/cray/infra/cray_infra/csrc 0.0s => [vllm vllm 14/17] COPY ./infra/requirements-vllm.txt /app/cray/infra/cray_infra/requirements.txt 0.0s => [vllm vllm 15/17] WORKDIR /app/cray/infra/cray_infra 0.0s => [vllm vllm 16/17] RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.cache/ccache MAX_JOBS=8 TORCH_CUDA_ARCH_LIST=\"7.5 8.6\" VLLM_TARGET_DEVICE=cpu python 39.0s => [vllm vllm 17/17] WORKDIR /app/cray 0.0s => [vllm infra 1/10] RUN apt-get update -y && apt-get install -y slurm-wlm libslurm-dev build-essential less curl wget net-tools vim iputils-ping && rm -rf /var/lib/apt/lists/* 15.0s => [vllm infra 2/10] COPY ./infra/slurm_src /app/cray/infra/slurm_src 0.0s => [vllm infra 3/10] RUN /app/cray/infra/slurm_src/compile.sh 0.2s => [vllm infra 4/10] RUN mkdir -p /app/cray/jobs 0.1s => [vllm infra 5/10] COPY ./infra /app/cray/infra 0.9s => [vllm infra 6/10] COPY ./sdk /app/cray/sdk 0.0s => [vllm infra 7/10] COPY ./test /app/cray/test 0.0s => [vllm infra 8/10] COPY ./cray /app/cray/cray 0.0s => [vllm infra 9/10] COPY ./ml /app/cray/ml 0.0s => [vllm infra 10/10] COPY ./scripts /app/cray/scripts 0.0s => [vllm] exporting to image 4.0s => => exporting layers 4.0s => => writing image sha256:2e9c8cea0daed2da4c4bd5bec4c875c1e4a773395b95cd4ddbd7823479c4ef83 0.0s [+] Running 2/2o docker.io/library/cray-vllm 0.0s \u2714 Service vllm Built 217.1s \u2714 Container cray-vllm-1 Recreated 0.2s Attaching to vllm-1 vllm-1 | +++ dirname /app/cray/scripts/start_one_server.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + /app/cray/scripts/start_slurm.sh vllm-1 | +++ dirname /app/cray/scripts/start_slurm.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + python /app/cray/scripts/../infra/cray_infra/slurm/discovery/discover_clusters.py vllm-1 | + slurmctld vllm-1 | + slurmd vllm-1 | + python -m cray_infra.one_server.main vllm-1 | INFO 01-09 18:47:16 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | INFO: Will watch for changes in these directories: ['/app/cray/infra/cray_infra'] vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | INFO: Started reloader process [38] using WatchFiles vllm-1 | INFO 01-09 18:47:19 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | DEBUG:asyncio:Using selector: EpollSelector vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting servers: ['api'] vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting API server vllm-1 | INFO:persistqueue.serializers.pickle:Selected pickle protocol: '4' vllm-1 | INFO:persistqueue:DBUtils may not be installed, install via 'pip install persist-queue[extra]' vllm-1 | INFO: Started server process [51] vllm-1 | INFO: Waiting for application startup. vllm-1 | INFO:cray_infra.training.register_megatron_models:Registering Megatron models vllm-1 | INFO: Application startup complete. vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | ERROR:cray_infra.one_server.wait_for_vllm:Error getting health: Cannot connect to host localhost:8001 ssl:default [Connect call failed ('127.0.0.1', 8001)] vllm-1 | INFO:cray_infra.training.register_megatron_models:VLLM is not ready. Skipping model registration vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Restarting Megatron jobs vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Slurm jobs running: [] vllm-1 | DEBUG:persistqueue.sqlbase:Initializing Sqlite3 Queue with path /app/cray/inference_work_queue.sqlite vllm-1 | INFO:cray_infra.generate.clear_acked_requests_from_queue:Cleared 0 acked requests from the queue.","title":"Laptop"},{"location":"docs/deployment/laptop/#laptop","text":"ScalarLM can be run on your laptop for development purposes. It requires Docker. Clone the ScalarLM repository and start the server. git clone git@github.com:tensorwavelm/scalarlm.git cd scalarlm ./cray up You should see the server come up. (environment) gregorydiamos@Air-Gregory cray % ./cray up +++ dirname ./cray ++ cd . ++ pwd + LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray + /Users/gregorydiamos/checkout/cray/cmd/bashly.sh generate ++++ dirname /Users/gregorydiamos/checkout/cray/cmd/bashly.sh +++ cd /Users/gregorydiamos/checkout/cray/cmd +++ pwd ++ LOCAL_DIRECTORY=/Users/gregorydiamos/checkout/cray/cmd +++ id -u +++ id -g ++ docker run --rm -it --user 501:20 --volume /Users/gregorydiamos/checkout/cray/cmd:/app/cmd --volume /Users/gregorydiamos/checkout/cray/cmd/../scripts:/app/scripts --volume /Users/gregorydiamos/checkout/cray/cmd/bashly-settings.yml:/app/bashly-settings.yml dannyben/bashly generate creating user files in cmd skipped cmd/build_image_command.sh (exists) skipped cmd/depot_build_command.sh (exists) skipped cmd/up_command.sh (exists) skipped cmd/test_command.sh (exists) skipped cmd/deploy_command.sh (exists) skipped cmd/serve_command.sh (exists) skipped cmd/llm_plot_command.sh (exists) skipped cmd/llm_logs_command.sh (exists) skipped cmd/llm_ls_command.sh (exists) skipped cmd/llm_squeue_command.sh (exists) skipped cmd/diffusion_command.sh (exists) created /app/scripts/cray run /app/scripts/cray --help to test your bash script + /Users/gregorydiamos/checkout/cray/scripts/cray up [+] Running 0/14.2s (10/37) docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s [+] Building 217.0s (39/39) FINISHED docker:desktop-linux => [vllm internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 4.35kB 0.0s => [vllm internal] load metadata for docker.io/library/ubuntu:24.04 0.3s => [vllm internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => CACHED [vllm cpu 1/6] FROM docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => => resolve docker.io/library/ubuntu:24.04@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab 0.0s => [vllm internal] load build context 0.2s => => transferring context: 723.40kB 0.2s => [vllm cpu 2/6] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y python3 python3-pip python3-venv openmpi-bin libopenmpi-dev libpmix-dev 60.7s => [vllm cpu 3/6] RUN python3 -m venv /app/.venv 2.6s => [vllm cpu 4/6] RUN . /app/.venv/bin/activate 0.1s => [vllm cpu 5/6] RUN pip install uv 1.4s => [vllm cpu 6/6] RUN uv pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cpu 6.3s => [vllm vllm 1/17] RUN --mount=type=cache,target=/var/cache/apt apt-get update -y && apt-get install -y curl ccache git vim numactl gcc-12 g++-12 libomp-dev libnuma-dev && apt-get ins 74.9s => [vllm vllm 2/17] COPY ./requirements.txt /app/cray/requirements.txt 0.1s => [vllm vllm 3/17] COPY ./test/requirements-pytest.txt /app/cray/requirements-pytest.txt 0.0s => [vllm vllm 4/17] COPY ./infra/requirements-vllm-build.txt /app/cray/requirements-vllm-build.txt 0.0s => [vllm vllm 5/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements.txt 8.6s => [vllm vllm 6/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-vllm-build.txt 1.6s => [vllm vllm 7/17] RUN uv pip install --no-compile --no-cache-dir -r /app/cray/requirements-pytest.txt 0.5s => [vllm vllm 8/17] WORKDIR /app/cray 0.0s => [vllm vllm 9/17] COPY ./infra/cray_infra/vllm /app/cray/infra/cray_infra/vllm 0.1s => [vllm vllm 10/17] COPY ./infra/setup.py /app/cray/infra/cray_infra/setup.py 0.0s => [vllm vllm 11/17] COPY ./infra/CMakeLists.txt /app/cray/infra/cray_infra/CMakeLists.txt 0.0s => [vllm vllm 12/17] COPY ./infra/cmake /app/cray/infra/cray_infra/cmake 0.0s => [vllm vllm 13/17] COPY ./infra/csrc /app/cray/infra/cray_infra/csrc 0.0s => [vllm vllm 14/17] COPY ./infra/requirements-vllm.txt /app/cray/infra/cray_infra/requirements.txt 0.0s => [vllm vllm 15/17] WORKDIR /app/cray/infra/cray_infra 0.0s => [vllm vllm 16/17] RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.cache/ccache MAX_JOBS=8 TORCH_CUDA_ARCH_LIST=\"7.5 8.6\" VLLM_TARGET_DEVICE=cpu python 39.0s => [vllm vllm 17/17] WORKDIR /app/cray 0.0s => [vllm infra 1/10] RUN apt-get update -y && apt-get install -y slurm-wlm libslurm-dev build-essential less curl wget net-tools vim iputils-ping && rm -rf /var/lib/apt/lists/* 15.0s => [vllm infra 2/10] COPY ./infra/slurm_src /app/cray/infra/slurm_src 0.0s => [vllm infra 3/10] RUN /app/cray/infra/slurm_src/compile.sh 0.2s => [vllm infra 4/10] RUN mkdir -p /app/cray/jobs 0.1s => [vllm infra 5/10] COPY ./infra /app/cray/infra 0.9s => [vllm infra 6/10] COPY ./sdk /app/cray/sdk 0.0s => [vllm infra 7/10] COPY ./test /app/cray/test 0.0s => [vllm infra 8/10] COPY ./cray /app/cray/cray 0.0s => [vllm infra 9/10] COPY ./ml /app/cray/ml 0.0s => [vllm infra 10/10] COPY ./scripts /app/cray/scripts 0.0s => [vllm] exporting to image 4.0s => => exporting layers 4.0s => => writing image sha256:2e9c8cea0daed2da4c4bd5bec4c875c1e4a773395b95cd4ddbd7823479c4ef83 0.0s [+] Running 2/2o docker.io/library/cray-vllm 0.0s \u2714 Service vllm Built 217.1s \u2714 Container cray-vllm-1 Recreated 0.2s Attaching to vllm-1 vllm-1 | +++ dirname /app/cray/scripts/start_one_server.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + /app/cray/scripts/start_slurm.sh vllm-1 | +++ dirname /app/cray/scripts/start_slurm.sh vllm-1 | ++ cd /app/cray/scripts vllm-1 | ++ pwd vllm-1 | + LOCAL_DIRECTORY=/app/cray/scripts vllm-1 | + python /app/cray/scripts/../infra/cray_infra/slurm/discovery/discover_clusters.py vllm-1 | + slurmctld vllm-1 | + slurmd vllm-1 | + python -m cray_infra.one_server.main vllm-1 | INFO 01-09 18:47:16 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | INFO: Will watch for changes in these directories: ['/app/cray/infra/cray_infra'] vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | INFO: Started reloader process [38] using WatchFiles vllm-1 | INFO 01-09 18:47:19 importing.py:10] Triton not installed; certain GPU-related functions will not be available. vllm-1 | DEBUG:asyncio:Using selector: EpollSelector vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting servers: ['api'] vllm-1 | DEBUG:cray_infra.one_server.start_cray_server:Starting API server vllm-1 | INFO:persistqueue.serializers.pickle:Selected pickle protocol: '4' vllm-1 | INFO:persistqueue:DBUtils may not be installed, install via 'pip install persist-queue[extra]' vllm-1 | INFO: Started server process [51] vllm-1 | INFO: Waiting for application startup. vllm-1 | INFO:cray_infra.training.register_megatron_models:Registering Megatron models vllm-1 | INFO: Application startup complete. vllm-1 | INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit) vllm-1 | ERROR:cray_infra.one_server.wait_for_vllm:Error getting health: Cannot connect to host localhost:8001 ssl:default [Connect call failed ('127.0.0.1', 8001)] vllm-1 | INFO:cray_infra.training.register_megatron_models:VLLM is not ready. Skipping model registration vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Restarting Megatron jobs vllm-1 | INFO:cray_infra.training.restart_megatron_jobs:Slurm jobs running: [] vllm-1 | DEBUG:persistqueue.sqlbase:Initializing Sqlite3 Queue with path /app/cray/inference_work_queue.sqlite vllm-1 | INFO:cray_infra.generate.clear_acked_requests_from_queue:Cleared 0 acked requests from the queue.","title":"Laptop"},{"location":"docs/deployment/modal-details/","text":"SMI Platform Deployment Guide Prerequisites Docker Dockerhub account depot.dev account Modal account 1. Build Docker Image with depot.dev Create depot.dev Account Visit https://depot.dev/ and create an account Build and Push Docker Image depot build --platform linux/amd64 \\ --build-arg BASE_NAME=cpu \\ --build-arg VLLM_TARGET_DEVICE=cpu \\ -t your-dockerhub/smi-platform:latest \\ --shm-size=8g . --push Authorization When prompted, click the authorization link (e.g., https://depot.dev/orgs/qmkv-blah-blah ) 2. Deploy to Modal Set Up Modal Create an account at https://modal.com Join the smi-workspace Install Modal Python package bash pip install modal Authenticate Modal bash modal setup This will open a web browser for authentication If not, manually copy the provided URL Configure Deployment Update Docker Image Credentials In deployment/modal/staging/cpu/cray.py , update the image configuration: cray_image = ( modal.Image.from_registry( \"your-dockerhub/image-tag\", secret=modal.Secret.from_dict( { \"REGISTRY_USERNAME\": \"your-username\", \"REGISTRY_PASSWORD\": \"your-dockerhub-passwd\", } ), ) .pip_install(\"fastapi >= 0.107.0\", \"pydantic >= 2.9\") .copy_local_file( local_path=local_config_path, remote_path=\"/app/cray/cray-config.yaml\" ) ) Serve Deployment modal serve deployment/modal/staging/cpu/deploy.py Expected Output Two web function URLs will be generated: FastAPI App URL VLLM App URL Update Deployment Configuration Stop the previous modal serve command Update deployment/modal/staging/cpu/cpu-deployment.yaml Replace api_url with FastAPI App URL Replace vllm_api_url with VLLM App URL Rerun Deployment modal serve deployment/modal/staging/cpu/cray.py 3. Testing Deployment Health Check PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/health.py {'api': 'up', 'vllm': 'up', 'all': 'up'} Expected output: {'api': 'up', 'vllm': 'up', 'all': 'up'} Generate Test PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/generate.py {'responses': [' 0 + 0 = 0\\nWhat is 0 + 0', ' 2. What is 1 + 1? 2. What is', ' What is 2 + 2? What is 2 + 2?', ' 6\\nWhat is 3 + 3? 6\\nWhat is']} Verifies text generation functionality Training Job Test PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': '800fc373a8befb18cff123cca003c10b2744ca37b488541a751bbb026063072c', 'job_directory': '/app/cray/jobs/77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37', 'model_name': '77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37'} Launches and verifies a training job Troubleshooting Ensure all credentials and URLs are correctly configured Check network connectivity Verify Docker and Modal authentication Notes Replace placeholders like your-dockerhub , your-username , and paths with your actual values Keep credentials secure and do not commit them to version control","title":"SMI Platform Deployment Guide"},{"location":"docs/deployment/modal-details/#smi-platform-deployment-guide","text":"","title":"SMI Platform Deployment Guide"},{"location":"docs/deployment/modal-details/#prerequisites","text":"Docker Dockerhub account depot.dev account Modal account","title":"Prerequisites"},{"location":"docs/deployment/modal-details/#1-build-docker-image-with-depotdev","text":"","title":"1. Build Docker Image with depot.dev"},{"location":"docs/deployment/modal-details/#create-depotdev-account","text":"Visit https://depot.dev/ and create an account","title":"Create depot.dev Account"},{"location":"docs/deployment/modal-details/#build-and-push-docker-image","text":"depot build --platform linux/amd64 \\ --build-arg BASE_NAME=cpu \\ --build-arg VLLM_TARGET_DEVICE=cpu \\ -t your-dockerhub/smi-platform:latest \\ --shm-size=8g . --push","title":"Build and Push Docker Image"},{"location":"docs/deployment/modal-details/#authorization","text":"When prompted, click the authorization link (e.g., https://depot.dev/orgs/qmkv-blah-blah )","title":"Authorization"},{"location":"docs/deployment/modal-details/#2-deploy-to-modal","text":"","title":"2. Deploy to Modal"},{"location":"docs/deployment/modal-details/#set-up-modal","text":"Create an account at https://modal.com Join the smi-workspace Install Modal Python package bash pip install modal Authenticate Modal bash modal setup This will open a web browser for authentication If not, manually copy the provided URL","title":"Set Up Modal"},{"location":"docs/deployment/modal-details/#configure-deployment","text":"","title":"Configure Deployment"},{"location":"docs/deployment/modal-details/#update-docker-image-credentials","text":"In deployment/modal/staging/cpu/cray.py , update the image configuration: cray_image = ( modal.Image.from_registry( \"your-dockerhub/image-tag\", secret=modal.Secret.from_dict( { \"REGISTRY_USERNAME\": \"your-username\", \"REGISTRY_PASSWORD\": \"your-dockerhub-passwd\", } ), ) .pip_install(\"fastapi >= 0.107.0\", \"pydantic >= 2.9\") .copy_local_file( local_path=local_config_path, remote_path=\"/app/cray/cray-config.yaml\" ) )","title":"Update Docker Image Credentials"},{"location":"docs/deployment/modal-details/#serve-deployment","text":"modal serve deployment/modal/staging/cpu/deploy.py","title":"Serve Deployment"},{"location":"docs/deployment/modal-details/#expected-output","text":"Two web function URLs will be generated: FastAPI App URL VLLM App URL","title":"Expected Output"},{"location":"docs/deployment/modal-details/#update-deployment-configuration","text":"Stop the previous modal serve command Update deployment/modal/staging/cpu/cpu-deployment.yaml Replace api_url with FastAPI App URL Replace vllm_api_url with VLLM App URL","title":"Update Deployment Configuration"},{"location":"docs/deployment/modal-details/#rerun-deployment","text":"modal serve deployment/modal/staging/cpu/cray.py","title":"Rerun Deployment"},{"location":"docs/deployment/modal-details/#3-testing-deployment","text":"","title":"3. Testing Deployment"},{"location":"docs/deployment/modal-details/#health-check","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/health.py {'api': 'up', 'vllm': 'up', 'all': 'up'} Expected output: {'api': 'up', 'vllm': 'up', 'all': 'up'}","title":"Health Check"},{"location":"docs/deployment/modal-details/#generate-test","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/generate.py {'responses': [' 0 + 0 = 0\\nWhat is 0 + 0', ' 2. What is 1 + 1? 2. What is', ' What is 2 + 2? What is 2 + 2?', ' 6\\nWhat is 3 + 3? 6\\nWhat is']} Verifies text generation functionality","title":"Generate Test"},{"location":"docs/deployment/modal-details/#training-job-test","text":"PYTHONPATH=/path/to/smi-platform/sdk python test/deployment/train.py {'job_id': '1', 'status': 'QUEUED', 'message': 'Training job launched', 'dataset_id': '800fc373a8befb18cff123cca003c10b2744ca37b488541a751bbb026063072c', 'job_directory': '/app/cray/jobs/77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37', 'model_name': '77607eb0e1c248bc36048e6c60023f46a50cbd895149adb17dc76edc33511d37'} Launches and verifies a training job","title":"Training Job Test"},{"location":"docs/deployment/modal-details/#troubleshooting","text":"Ensure all credentials and URLs are correctly configured Check network connectivity Verify Docker and Modal authentication","title":"Troubleshooting"},{"location":"docs/deployment/modal-details/#notes","text":"Replace placeholders like your-dockerhub , your-username , and paths with your actual values Keep credentials secure and do not commit them to version control","title":"Notes"},{"location":"docs/deployment/modal/","text":"Modal ScalarLM can be deployed on Modal for easy access to GPUs. Clone the ScalarLM repository and start the server. git clone git@github.com:tensorwavecloud/scalarlm.git cd cray ./cray deploy Modal should give you an endpoint you can start using.","title":"Modal"},{"location":"docs/deployment/modal/#modal","text":"ScalarLM can be deployed on Modal for easy access to GPUs. Clone the ScalarLM repository and start the server. git clone git@github.com:tensorwavecloud/scalarlm.git cd cray ./cray deploy Modal should give you an endpoint you can start using.","title":"Modal"}]}